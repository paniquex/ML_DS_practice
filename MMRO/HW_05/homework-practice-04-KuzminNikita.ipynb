{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ММП ВМК МГУ\n",
    "\n",
    "## Практическое задание 4. Разложение ошибки на смещение и разброс. Градиентный бустинг ~~своими руками~~\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 09.12.2019\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 22.12.2019\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 29.12.2019\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-06-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston. \n",
    "Также в задании вам будет предложено пообучать готовые модели градиентного бустинга и CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление bias и variance с помощью бутстрапа\n",
    "На лекции была выведено следующая формула, показывающая, как можно представить ошибку алгоритма регрессии в виде суммы трех компонент:\n",
    "$$\n",
    "L(\\mu) = \n",
    "    \\mathbb{E}_{x, y}\\bigl[\\mathbb{E}_{X}\\bigl[ (y - \\mu(X)(x))^2 \\bigr]\\bigr] = \n",
    "$$\n",
    "$$\n",
    "    \\underbrace{\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{шум}} + \\underbrace{\\mathbb{E}_{x}\\bigl[(\\mathbb{E}_{X}[\\mu(X)(x)] - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{смещение}} +\n",
    "    \\underbrace{\\mathbb{E}_{x}\\bigl[\\mathbb{E}_{X}\\bigl[(\\mu(X)(x) - \\mathbb{E}_{X}[\\mu(X)(x)] )^2\\bigr]\\bigr]}_{\\text{разброс}},\n",
    "$$\n",
    "* $\\mu(X)$ — алгоритм, обученный по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$;\n",
    "* $\\mu(X)(x)$ — ответ алгоритма, обученного по выборке $X$, на объекте $x$;\n",
    "* $\\mathbb{E}_{X}$ — мат. ожидание по всем возможным выборкам;\n",
    "* $\\mathbb{E}_{X}[\\mu(X)(x)]$ — \"средний\" ответ алгоритма, обученного по всем возможным выборкам $X$, на объекте $x$.\n",
    "    \n",
    "С помощью этой формулы мы можем анализировать свойства алгоритма обучения модели $\\mu$, если зададим вероятностную модель порождения пар $p(x, y)$.\n",
    "\n",
    "В реальных задачах мы, конечно же, не знаем распределение на парах объект - правильный ответ. Однако у нас есть набор семплов из этого распределения (обучающую выборка), и мы можем использовать его, чтобы оценивать математические ожидания. Для оценки мат. ожиданий по выборкам мы будем пользоваться бутстрэпом - методом генерации \"новых\" выборок из одной с помощью выбора объектов с возвращением. Разберем несколько шагов на пути к оценке смещения и разброса.\n",
    "\n",
    "#### Приближенное вычисление интегралов\n",
    "На занятиях мы разбирали примеры аналитического вычисления смещения и разброса нескольких алгоритмов обучения. Для большинства моделей данных и алгоритмов обучения аналитически рассчитать математические ожидания в формулах не удастся. Однако мат. ожидания можно оценивать приближенно. Чтобы оценить математическое ожидание $\\mathbb{E}_{\\bar z} f(\\bar z)$ функции от многомерной случайной величины $\\bar z = (z_1, \\dots, z_d)$, $\\bar z \\sim p(\\bar z)$, можно сгенерировать выборку из распределения $p(\\bar z)$ и усреднить значение функции на элементах этой выборки:\n",
    "$$\\mathbb{E}_{\\bar z} f(z) = \\int f(\\bar z) p(\\bar z) d \\bar z \\approx \\frac 1 m \\sum_{i=1}^m f(\\bar z_i), \\, \\bar z_i \\sim p(\\bar z), i = 1, \\dots, m.$$\n",
    "\n",
    "Например, оценим $\\mathbb{E}_z z^2,$ $z \\sim \\mathcal{N}(\\mu=5, \\sigma=3)$ (из теории вероятностей мы знаем, что\n",
    "$\\mathbb{E}_z z^2 = \\sigma^2 + \\mu^2 = 34$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.351699189841575"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.random.normal(loc=5, scale=3, size=1000)\n",
    "(z**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценивание $\\mathbb{E}_{x, y}$\n",
    "Оценить мат. ожидания по $x$ и по $x, y$, встречающиеся во всех трех компонентах разложения, несложно, потому что у нас есть выборка объектов из распределения данных $p(x, y)$:\n",
    "$$ \\mathbb{E}_{x} f(x) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i), \\quad\n",
    "\\mathbb{E}_{x, y} f(x, y) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i, y_i),$$\n",
    "где $N$ - число объектов в выборке, $\\{(x_i, y_i)\\}_{i=1}^N$ - сама выборка. \n",
    "\n",
    "#### Оценивание $\\mathbb{E}_X$ с помощью бутстрапа\n",
    "Чтобы оценить мат. ожидание по $X$, нам понадобится выборка из выборок:\n",
    "$$\\mathbb{E}_X f(X) \\approx \\frac 1 s \\sum_{j=1}^s f(X_j),$$\n",
    "где $X_j$ - $j$-я выборка. Чтобы их получить, мы можем воспользоваться бутстрапом - методом генерации выборок на основе выбора объектов с возвращением. Чтобы составить одну выборку, будем $N$ раз выбирать индекс объекта $i \\sim \\text{Uniform}(1 \\dots N)$ и добавлять $i$-ю пару (объект, целевая переменная) в выборку. В результате в каждой выборке могут появиться повторяющиеся объекты, а какие-то объекты могут вовсе не войти в некоторые выборки.\n",
    "\n",
    "#### Итоговый алгоритм оценки смещения и разброса алгоритма $a$\n",
    "1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n",
    "1. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n",
    "1. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$. \n",
    "\n",
    "Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$. \n",
    "\n",
    "Итоговые оценки:\n",
    "* Смещение: для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n",
    "* Разброс: для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n",
    "* Ошибка $L$: усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n",
    "\n",
    "В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!\n",
    "\n",
    "Алгоритм также вкратце описан по [ссылке](https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf) (слайды 19-21).\n",
    "\n",
    "__Задание 1. (3 балла)__\n",
    "\n",
    "Реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. Как обычно, разрешается использовать только один цикл - по выборкам (от 0 до num_runs-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "def compute_biase_variance(regressor, X, y, num_runs=100):\n",
    "    \"\"\"\n",
    "    :param regressor: sklearn estimator with fit(...) and predict(...) method\n",
    "    :param X: numpy-array representing training set ob objects, shape [n_obj, n_feat]\n",
    "    :param y: numpy-array representing target for training objects, shape [n_obj]\n",
    "    :param num_runs: int, number of samples (s in the description of the algorithm)\n",
    "    \n",
    "    :returns: bias (float), variance (float), error (float) \n",
    "    each value is computed using bootstrap\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = np.zeros((X.shape[0], num_runs))\n",
    "    predictions[:, :] = np.nan\n",
    "    error = np.zeros((X.shape[0], num_runs))\n",
    "    error[:, :] = np.nan\n",
    "    indexes_all = np.arange(X.shape[0])\n",
    "    \n",
    "    for i  in tqdm_notebook(range(num_runs)):\n",
    "        indexes_train = np.random.choice(indexes_all,\n",
    "                                      size=X.shape[0],\n",
    "                                      replace=True)\n",
    "        indexes_test = np.setdiff1d(indexes_all, indexes_train)\n",
    "        regressor.fit(X[indexes_train], y[indexes_train])\n",
    "        \n",
    "        predictions[indexes_test, i] = regressor.predict(X[indexes_test])\n",
    "        error[indexes_test, i] = ((predictions[indexes_test, i] - y[indexes_test]) ** 2)\n",
    "\n",
    "    mean_pred_obj = np.nanmean(predictions, axis=1)\n",
    "    biase = np.mean((mean_pred_obj - y) ** 2)\n",
    "    \n",
    "    variance = np.mean(np.nanvar(predictions, axis=1))\n",
    "    error = np.mean(np.nanmean(error, axis=1))\n",
    "    \n",
    "    return biase, variance, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (1 балл)**\n",
    "\n",
    "Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "dectree_reg = DecisionTreeRegressor()\n",
    "randfor_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f041b7805fde457c95115acbf738d8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для линейной регрессии: (23.674249933196624, 0.9060609193050133, 24.580310852501633)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c36608f95240ddb337a58a1cccfd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для решающего дерева: (10.264623652410439, 12.665849584271013, 22.93047323668145)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2148cf6c0443c4a4ecf9efa1a35f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для случайного леса: (10.752312336687638, 3.4254713530897534, 14.17778368977739)\n"
     ]
    }
   ],
   "source": [
    "print(f'Смещение, разброс, ошибка для линейной регрессии: {compute_biase_variance(lin_reg, X, y)}')\n",
    "print(f'Смещение, разброс, ошибка для решающего дерева: {compute_biase_variance(dectree_reg, X, y)}')\n",
    "print(f'Смещение, разброс, ошибка для случайного леса: {compute_biase_variance(randfor_reg, X, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на семинарах (с комментарием)?\n",
    "\n",
    "__Your answer here:__ из полученных результатов видно, что:\n",
    "\n",
    "1. Линейная регрессия обладает наибольшим смещением и наименьшим разбросом среди 3 выбранных алгоритмов (что является логичным, так как большое смещение и маленький разброс говорят о простоте модели).\n",
    "1. Смещения решающего дерева и случайного леса практически не отличаются, так как из лекций известно, что бэггинг не изменяет смещение.\n",
    "1. Видно, что разброс случайного леса сильно уменьшился относительно решающего дерева. Этот факт частично подтверждает теоретическую часть, рассказанную на лекциях: бэггинг уменьшает разброс в `m` раз, где `m` - количество выборок, сформированных с помощью бутстрапа. В данном случае `m = 10`, так как по умолчанию в `RandomForestRegressor` значение `n_estimators = 10`. Мне кажется, что рассхождение возможно из-за того, что в при построении деревьев в случайном лесе могут быть удалены некоторые признаки.\n",
    "\n",
    "Вспомните обсуждение с лекции о том, во сколько раз в теории бутстрап уменьшает разброс базового алгоритма. Выполняется ли это в ваших экспериментах? Если нет, поясните, почему.\n",
    "\n",
    "\n",
    "В теории бутстрап уменьшает разброс базового алгоритма в `m` раз, где `m` - количество выборок, сформированных с помощью бутстрапа.\n",
    "\n",
    "Для того, чтобы это проверить запустим функцию `compute_biase_variance` с параметром `num_runs = 50` и `num_runs = 500` для каждого из трех алгоритмов. Ожидается, разброс каждого из алгоритмов при первом запуске будет больше в 10 раз, чем их разброс при втором запуске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b805e52c4ad491f8a0b1aac1ca47d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4793bdef1e2540bbb7d84deb3c8a86ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c2099c4edf4a3cb6790dfe13970838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для линейной регрессии при num_runs = 20: 23.637  0.682 24.319\n",
      "Смещение, разброс, ошибка для решающего дерева при num_runs = 20:   11.967 12.069 24.036\n",
      "Смещение, разброс, ошибка для случайного леса при num_runs = 20:     9.980  2.609 12.589\n"
     ]
    }
   ],
   "source": [
    "ans_reg = compute_biase_variance(lin_reg, X, y, num_runs=20)\n",
    "ans_dec = compute_biase_variance(dectree_reg, X, y, num_runs=20)\n",
    "ans_for = compute_biase_variance(randfor_reg, X, y, num_runs=20)\n",
    "\n",
    "print(f'Смещение, разброс, ошибка для линейной регрессии при num_runs = 20: {ans_reg[0]:6.3f} {ans_reg[1]:6.3f} {ans_reg[2]:6.3f}')\n",
    "print(f'Смещение, разброс, ошибка для решающего дерева при num_runs = 20:   {ans_dec[0]:6.3f} {ans_dec[1]:6.3f} {ans_dec[2]:6.3f}')\n",
    "print(f'Смещение, разброс, ошибка для случайного леса при num_runs = 20:    {ans_for[0]:6.3f} {ans_for[1]:6.3f} {ans_for[2]:6.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce88ba8b22464c98a465b199938d6e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для линейной регрессии при num_runs = 40: (23.583614233032854, 0.7954322593587888, 24.37904649239164)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e873ff198f37415da22299dce101f435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для решающего дерева при num_runs = 40: (10.363362967604838, 11.990421534418351, 22.353784502023192)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c61eccbdd9945a3b85e69b83d2f4a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для случайного леса при num_runs = 40: (10.44311382639265, 2.9712169983878307, 13.414330824780482)\n"
     ]
    }
   ],
   "source": [
    "print(f'Смещение, разброс, ошибка для линейной регрессии при num_runs = 40: {compute_biase_variance(lin_reg, X, y, num_runs=40)}')\n",
    "print(f'Смещение, разброс, ошибка для решающего дерева при num_runs = 40: {compute_biase_variance(dectree_reg, X, y, num_runs=40)}')\n",
    "print(f'Смещение, разброс, ошибка для случайного леса при num_runs = 40: {compute_biase_variance(randfor_reg, X, y, num_runs=40)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your answer here:__ интересно, что в данных экспериментах не выполняются теоретические результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация предсказаний базовых алгоритмов бэггинга\n",
    "\n",
    "В материалах лекций можно найти изображение, похожее на мишень - визуализация алгоритмов с разным смещением и разным разбросом. В центре \"мишени\" - правильный ответ, а \"попадания\" - предсказания алгоритмов, обученных по разным выборкам. Построим похожее изображение на наших данных для трех алгоритмов. Наши \"мишени\" будут одномерными, потому что мы решаем задачу одномерной регрессии.\n",
    "\n",
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Реализуйте фукнцию plot_predictions. Она должна выполнять следующие действия:\n",
    "1. Случайно выбрать num_test_objects пар объект-целевая переменная из выборки X, y. Получится две выборки: маленькая X_test, y_test (выбранные тестовые объекты) и X_train, y_train (остальные объекты).\n",
    "1. Сгенерировать num_runs выборок методом бутстарапа из X_train, y_train. На каждой выборке обучить алгоритм regressor и сделать предсказания для X_test.\n",
    "1. Нарисовать scatter-график. По оси абсцисс - объекты тестовой выборки (номера от 0 до num_test_objects-1), по оси ординат - предсказания. В итоге получится num_test_objects столбиков с точками. Для каждого тестового объекта надо отметить одним цветом все предсказания для него, а также черным цветом отметить правильный ответ.\n",
    "1. Подпишите оси и название графика (аргумент title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(13)\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_predictions(regressor, X, y, num_runs=1000, num_test_objects=10, title=\"\", ax=None):\n",
    "    \"\"\"\n",
    "    plot graphics described above\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=num_test_objects,\n",
    "                                                        random_state=13)\n",
    "    predictions = np.zeros((num_test_objects, num_runs))\n",
    "    all_indexes = np.arange(X_train.shape[0])\n",
    "    for i in range(num_runs):\n",
    "        indexes_bs = np.random.choice(all_indexes,\n",
    "                                      size=X_train.shape[0],\n",
    "                                      replace=True)\n",
    "        \n",
    "        regressor.fit(X_train[indexes_bs], y_train[indexes_bs])\n",
    "        predictions[:, i] = regressor.predict(X_test)\n",
    "        if ax is None:\n",
    "            plt.scatter(np.arange(X_test.shape[0]), predictions[:, i], color='black', label='y_preds')\n",
    "        else:\n",
    "            line_pred = ax.scatter(np.arange(X_test.shape[0]), predictions[:, i], color='black', label='y_preds')\n",
    "    if ax is None:\n",
    "        plt.scatter(np.arange(X_test.shape[0]), y_test, color='red', label='y_true')\n",
    "    else:\n",
    "        line_true = ax.scatter(np.arange(X_test.shape[0]), y_test, color='red', label='y_true')\n",
    "        ax.title.set_text(title)\n",
    "        ax.set_xlabel('Номер объекта из теста')\n",
    "    return line_true, line_pred\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте графики для линейной регрессии, решающего дерева и случайного леса. Нарисуйте три графика в строчку (это можно сделать с помощью plt.subplot) с одинаковой осью ординат (это важно для понимания масштаба разброса у разных алгоритмов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "dectree_reg = DecisionTreeRegressor()\n",
    "randforest_reg = RandomForestRegressor(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 10), sharey=True)\n",
    "plot_predictions(lin_reg, X, y, ax=axs[0], title='Линейная регрессия')\n",
    "plot_predictions(dectree_reg, X, y, ax=axs[1], title='Решающее дерево')\n",
    "l_true, l_pred = plot_predictions(randforest_reg, X, y, ax=axs[2], title='Случайный лес')\n",
    "axs[0].set_ylabel('Значение целевого признака')\n",
    "plt.legend([l_true, l_pred],['y_true', 'y_pred'])\n",
    "plt.title('Зависимость значений целевого признака от тестового объекта')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого графика прокомментируйте, как он характеризует смещение и разброс соответствующего алгоритма.\n",
    "\n",
    "**Your answer here:**\n",
    "по данным графикам видно, что выполняются выводы из задания номер 2:\n",
    "\n",
    "1. Линейная регрессия обладает наибольшим смещением и наименьшим разбросом среди 3 выбранных алгоритмов (что является логичным, так как большое смещение и маленький разброс говорят о простоте модели).\n",
    "1. Смещения решающего дерева и случайного леса практически не отличаются, так как из лекций известно, что бэггинг не изменяет смещение.\n",
    "1. Видно, что разброс случайного леса сильно уменьшился относительно решающего дерева. Этот факт частично подтверждает теоретическую часть, рассказанную на лекциях: бэггинг уменьшает разброс в `m` раз, где `m` - количество выборок, сформированных с помощью бутстрапа. В данном случае `m = 10`, так как по умолчанию в `RandomForestRegressor` значение `n_estimators = 10`. Мне кажется, что рассхождение возможно из-за того, что в при построении деревьев в случайном лесе могут быть удалены некоторые признаки.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (1 балл)**\n",
    "\n",
    "Мы будем использовать данные из [соревнования](https://www.kaggle.com/t/b710e05dc0bd424995ca94da5b639869). \n",
    "* Загрузите таблицу application_train.csv;\n",
    "* Запишите в Y столбец с целевой переменной (TARGET);\n",
    "* Удалите ненужные столбцы (для этого воспользуйтесь описанием);\n",
    "* Определите тип столбцов и заполните пропуски - стратегия произвольная;\n",
    "* Разбейте выборку в соотношении 70:30 с random_state=0.\n",
    "\n",
    "Так как в данных имеется значительный дисбаланс классов, в качестве метрики качества везде будем использовать площадь под precision-recall кривой (AUC-PR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/application_train.csv')\n",
    "\n",
    "Y = train_data['TARGET']\n",
    "train_data.drop(columns='TARGET', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Какие признаки можно удалить?\n",
    " 1. Удалим признак `SK_ID_CURR`, так уникальный идентификатор не несет никакой информации о целевом признаке\n",
    " 1. Удалим признаки `WEEKDAY_APPR_PROCESS_START` и `HOUR_APPR_PROCESS_START`, так как они отвечают за день недели и время подачи заявки на кредит. \n",
    " 1. Удалим все признаки, в которых $количество\\spaceпропусков >= 0.4 * (количество\\spaceвсех\\spaceзначений)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codeee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Будем считать, что признак категориальный, если количество уникальных значений 2 <= n <= 30~~\n",
    "\n",
    "Будем считать, что признак категориальный, если его тип = 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_uniq = 30\n",
    "#cat_features = []\n",
    "\n",
    "\n",
    "#for col in train_data.columns:\n",
    "#    uniq_amount = len(train_data[col].unique())\n",
    "#    if (uniq_amount <= n_uniq) & (uniq_amount >= 2):\n",
    "#        cat_features.append(col)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.26 ms, sys: 0 ns, total: 5.26 ms\n",
      "Wall time: 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        cat_features.append(col)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных признаков заполнинм пропуски самым популярным значением, а для вещественных - средним по данному признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_features:\n",
    "    nan_mask = train_data[cat_col].isna()\n",
    "    train_data.loc[nan_mask, cat_col] = train_data[cat_col].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = set(train_data.columns) - set(cat_features)\n",
    "\n",
    "\n",
    "for numerical_col in numerical_features:\n",
    "    mean_col = np.mean(train_data[numerical_col])\n",
    "    train_data[numerical_col].fillna(mean_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем категориальные признаки с помощью one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, cat_columns):\n",
    "    data_ohe = data.copy()\n",
    "    for cat_column in cat_columns:\n",
    "        unique_values = data_ohe[cat_column].unique()\n",
    "        for unique_value in unique_values:\n",
    "            data_ohe[cat_column + '_' + str(unique_value)] = data_ohe[cat_column] == unique_value\n",
    "            data_ohe[cat_column + '_' + str(unique_value)] =\\\n",
    "                data_ohe[cat_column + '_' + str(unique_value)].map({True: 1, False: 0})\n",
    "    return data_ohe.drop(columns=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_ohe = one_hot_encoding(train_data, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку в соотношении 70:30 с random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите реализации градиентного бустинга LightGBM и Catboost на вещественных признаках без подбора параметров. **Почему получилась заметная разница в качестве?**\n",
    "\n",
    "В этом и последующих экспериментах необходимо измерять время обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 374 ms, total: 19.4 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(X_train[numerical_features], y_train)\n",
    "lgbm_preds = lgbm_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 56s, sys: 18.2 s, total: 7min 14s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "catboost_model.fit(X_train[numerical_features], y_train)\n",
    "catboost_preds = catboost_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM PR-AUC: 0.23839790562929922\n",
      "CatBoost PR-AUC: 0.23594506243030683\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM PR-AUC: {average_precision_score(y_test, lgbm_preds)}')\n",
    "print(f'CatBoost PR-AUC: {average_precision_score(y_test, catboost_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** Разница получилась совсем незначительной, хоть и Catboost обучался почти в 21 раз дольше.. LGBM показал качество лучше, так как, возможно, для этих данных \"жадный алгоритм\", встроенный в реализации LGBM, построения композиции дает лучший результат. Еще одна причина: мы совсем не использовали категориальные признаки, а они как раз являются ключевой особенностью библиотеки Catboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (2 балла)__\n",
    "\n",
    "Подберите оптимальные с точки зрения метрики качества параметры алгоритмов, изменяя:\n",
    "\n",
    "* глубину деревьев;\n",
    "* количество деревьев;\n",
    "* темп обучения;\n",
    "* оптимизируемый функционал.\n",
    "\n",
    "Масштаб значений предлагается посмотреть в [семинаре](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/seminars/sem10-gbm.ipynb) про библиотеки.\n",
    "\n",
    "**Проанализируйте соотношения глубины и количества деревьев в зависимости от алгоритма.** \n",
    "\n",
    "**Если на перебор гиперпараметров уходит много времени, то переберите значениях каких-нибудь 1-2 гиперпараметров, а не всех предложенных 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f38c5bf2ce4c3fb29128f25ede572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "max_depth_list = list(range(1, 15, 3))\n",
    "tree_amount_list = [1, 5, 10, 100, 300, 500, 700]\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1, 1]\n",
    "loss_func_list = ['Logloss']\n",
    "\n",
    "catboost_logger = {'max_depth_list': [],\n",
    "                   'tree_amount_list': [],\n",
    "                   'learning_rate_list': [],\n",
    "                   'loss_func_list': [],\n",
    "                   'AUC-PR_list': [],\n",
    "                   'estimated_time': []\n",
    "                  }\n",
    "\n",
    "i = 0\n",
    "\n",
    "for max_depth in tqdm_notebook(max_depth_list):\n",
    "    for tree_amount in tree_amount_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for loss_func in loss_func_list:\n",
    "                start_time = time.time()\n",
    "                catboost_model = CatBoostClassifier(max_depth=max_depth, n_estimators=tree_amount,\n",
    "                                            learning_rate=lr, objective=loss_func,\n",
    "                                             task_type='GPU', verbose=0)\n",
    "                \n",
    "                catboost_model.fit(X_train[numerical_features], y_train)\n",
    "                preds = catboost_model.predict_proba(X_test[numerical_features])[:, 1]\n",
    "                catboost_logger['AUC-PR_list'].append(average_precision_score(y_test, preds))\n",
    "                catboost_logger['max_depth_list'].append(max_depth)\n",
    "                catboost_logger['tree_amount_list'].append(tree_amount)\n",
    "                catboost_logger['learning_rate_list'].append(lr)\n",
    "                catboost_logger['loss_func_list'].append(loss_func)\n",
    "                catboost_logger['estimated_time'].append(time.time() - start_time)\n",
    "                \n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('catboost_logger.pkl', 'wb') as file:\n",
    "    pickle.dump(catboost_logger, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "max_depth_list = list(range(1, 15, 3))\n",
    "tree_amount_list = [1, 5, 10, 100, 300, 500, 700]\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1, 1]\n",
    "loss_func_list = ['binary']\n",
    "\n",
    "lgbm_logger = {'max_depth_list': [],\n",
    "                   'tree_amount_list': [],\n",
    "                   'learning_rate_list': [],\n",
    "                   'loss_func_list': [],\n",
    "                   'AUC-PR_list': [],\n",
    "                   'estimated_time': []\n",
    "                  }\n",
    "\n",
    "i = 0\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for tree_amount in tree_amount_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for loss_func in loss_func_list:\n",
    "                lgbm_model = LGBMClassifier(max_depth=max_depth, n_estimators=tree_amount,\n",
    "                                            learning_rate=lr, objective=loss_func,\n",
    "                                             n_jobs=-1)\n",
    "                \n",
    "                lgbm_model.fit(X_train[numerical_features], y_train)\n",
    "                preds = lgbm_model.predict_proba(X_test[numerical_features])[:, 1]\n",
    "                lgbm_logger['AUC-PR_list'].append(average_precision_score(y_test, preds))\n",
    "                lgbm_logger['max_depth_list'].append(max_depth)\n",
    "                lgbm_logger['tree_amount_list'].append(tree_amount)\n",
    "                lgbm_logger['learning_rate_list'].append(lr)\n",
    "                lgbm_logger['loss_func_list'].append(loss_func)\n",
    "                lgbm_logger['estimated_time'].append(time.time() - start_time)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('lgbm_logger.pkl', 'wb') as file:\n",
    "    pickle.dump(, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
