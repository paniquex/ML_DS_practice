{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ММП ВМК МГУ\n",
    "\n",
    "## Практическое задание 4. Разложение ошибки на смещение и разброс. Градиентный бустинг ~~своими руками~~\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 09.12.2019\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 22.12.2019\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 29.12.2019\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-06-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит воспользоваться возможностями bootstraping для оценки смещения и разброса алгоритмов машинного обучения. Делать мы это будем на данных boston. \n",
    "Также в задании вам будет предложено пообучать готовые модели градиентного бустинга и CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление bias и variance с помощью бутстрапа\n",
    "На лекции была выведено следующая формула, показывающая, как можно представить ошибку алгоритма регрессии в виде суммы трех компонент:\n",
    "$$\n",
    "L(\\mu) = \n",
    "    \\mathbb{E}_{x, y}\\bigl[\\mathbb{E}_{X}\\bigl[ (y - \\mu(X)(x))^2 \\bigr]\\bigr] = \n",
    "$$\n",
    "$$\n",
    "    \\underbrace{\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{шум}} + \\underbrace{\\mathbb{E}_{x}\\bigl[(\\mathbb{E}_{X}[\\mu(X)(x)] - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{смещение}} +\n",
    "    \\underbrace{\\mathbb{E}_{x}\\bigl[\\mathbb{E}_{X}\\bigl[(\\mu(X)(x) - \\mathbb{E}_{X}[\\mu(X)(x)] )^2\\bigr]\\bigr]}_{\\text{разброс}},\n",
    "$$\n",
    "* $\\mu(X)$ — алгоритм, обученный по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$;\n",
    "* $\\mu(X)(x)$ — ответ алгоритма, обученного по выборке $X$, на объекте $x$;\n",
    "* $\\mathbb{E}_{X}$ — мат. ожидание по всем возможным выборкам;\n",
    "* $\\mathbb{E}_{X}[\\mu(X)(x)]$ — \"средний\" ответ алгоритма, обученного по всем возможным выборкам $X$, на объекте $x$.\n",
    "    \n",
    "С помощью этой формулы мы можем анализировать свойства алгоритма обучения модели $\\mu$, если зададим вероятностную модель порождения пар $p(x, y)$.\n",
    "\n",
    "В реальных задачах мы, конечно же, не знаем распределение на парах объект - правильный ответ. Однако у нас есть набор семплов из этого распределения (обучающую выборка), и мы можем использовать его, чтобы оценивать математические ожидания. Для оценки мат. ожиданий по выборкам мы будем пользоваться бутстрэпом - методом генерации \"новых\" выборок из одной с помощью выбора объектов с возвращением. Разберем несколько шагов на пути к оценке смещения и разброса.\n",
    "\n",
    "#### Приближенное вычисление интегралов\n",
    "На занятиях мы разбирали примеры аналитического вычисления смещения и разброса нескольких алгоритмов обучения. Для большинства моделей данных и алгоритмов обучения аналитически рассчитать математические ожидания в формулах не удастся. Однако мат. ожидания можно оценивать приближенно. Чтобы оценить математическое ожидание $\\mathbb{E}_{\\bar z} f(\\bar z)$ функции от многомерной случайной величины $\\bar z = (z_1, \\dots, z_d)$, $\\bar z \\sim p(\\bar z)$, можно сгенерировать выборку из распределения $p(\\bar z)$ и усреднить значение функции на элементах этой выборки:\n",
    "$$\\mathbb{E}_{\\bar z} f(z) = \\int f(\\bar z) p(\\bar z) d \\bar z \\approx \\frac 1 m \\sum_{i=1}^m f(\\bar z_i), \\, \\bar z_i \\sim p(\\bar z), i = 1, \\dots, m.$$\n",
    "\n",
    "Например, оценим $\\mathbb{E}_z z^2,$ $z \\sim \\mathcal{N}(\\mu=5, \\sigma=3)$ (из теории вероятностей мы знаем, что\n",
    "$\\mathbb{E}_z z^2 = \\sigma^2 + \\mu^2 = 34$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.24729834112394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.random.normal(loc=5, scale=3, size=1000)\n",
    "(z**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценивание $\\mathbb{E}_{x, y}$\n",
    "Оценить мат. ожидания по $x$ и по $x, y$, встречающиеся во всех трех компонентах разложения, несложно, потому что у нас есть выборка объектов из распределения данных $p(x, y)$:\n",
    "$$ \\mathbb{E}_{x} f(x) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i), \\quad\n",
    "\\mathbb{E}_{x, y} f(x, y) \\approx \\frac 1 N \\sum_{i=1}^N f(x_i, y_i),$$\n",
    "где $N$ - число объектов в выборке, $\\{(x_i, y_i)\\}_{i=1}^N$ - сама выборка. \n",
    "\n",
    "#### Оценивание $\\mathbb{E}_X$ с помощью бутстрапа\n",
    "Чтобы оценить мат. ожидание по $X$, нам понадобится выборка из выборок:\n",
    "$$\\mathbb{E}_X f(X) \\approx \\frac 1 s \\sum_{j=1}^s f(X_j),$$\n",
    "где $X_j$ - $j$-я выборка. Чтобы их получить, мы можем воспользоваться бутстрапом - методом генерации выборок на основе выбора объектов с возвращением. Чтобы составить одну выборку, будем $N$ раз выбирать индекс объекта $i \\sim \\text{Uniform}(1 \\dots N)$ и добавлять $i$-ю пару (объект, целевая переменная) в выборку. В результате в каждой выборке могут появиться повторяющиеся объекты, а какие-то объекты могут вовсе не войти в некоторые выборки.\n",
    "\n",
    "#### Итоговый алгоритм оценки смещения и разброса алгоритма $a$\n",
    "1. Сгенерировать $s$ выборок $X_j$ методом бутстрапа.\n",
    "1. На каждой выборке $X_j$ обучить алгоритм $a_j$.\n",
    "1. Для каждой выборки $X_j$ определить множество объектов $T_j$, не вошедших в нее (out-of-bag). Вычислить предсказания алгоритма $a_j$ на объектах $T_j$. \n",
    "\n",
    "Поскольку у нас есть только один ответ для каждого объекта, мы будем считать шум равным 0, а $\\mathbb{E}[y|x]$ равным имеющемуся правильному ответу для объекта $x$. \n",
    "\n",
    "Итоговые оценки:\n",
    "* Смещение: для одного объекта - квадрат разности среднего предсказания и правильного ответа. Среднее предсказание берется только по тем алгоритмам $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего смещения выполнить усреденение смещений по объектам.\n",
    "* Разброс: для одного объекта - выборочная дисперсия предсказаний алгоритмов $a_j$, для которых этот объект входил в out-of-bag выборку $T_j$. Для получения общего разброса выполнить усреденение разбросов по объектам.\n",
    "* Ошибка $L$: усреднить квадраты разностей предсказания и правильного ответа по всем выполненным предсказаниям для всех объектов.\n",
    "\n",
    "В результате должно получиться, что ошибка приблизительно равна сумме смещения и разброса!\n",
    "\n",
    "Алгоритм также вкратце описан по [ссылке](https://web.engr.oregonstate.edu/~tgd/classes/534/slides/part9.pdf) (слайды 19-21).\n",
    "\n",
    "__Задание 1. (3 балла)__\n",
    "\n",
    "Реализуйте описанный алгоритм. Обратите внимание, что если объект не вошел ни в одну из out-of-bag выборок, учитывать его в вычислении итоговых величин не нужно. Как обычно, разрешается использовать только один цикл - по выборкам (от 0 до num_runs-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "def compute_biase_variance(regressor, X, y, num_runs=100):\n",
    "    \"\"\"\n",
    "    :param regressor: sklearn estimator with fit(...) and predict(...) method\n",
    "    :param X: numpy-array representing training set ob objects, shape [n_obj, n_feat]\n",
    "    :param y: numpy-array representing target for training objects, shape [n_obj]\n",
    "    :param num_runs: int, number of samples (s in the description of the algorithm)\n",
    "    \n",
    "    :returns: bias (float), variance (float), error (float) \n",
    "    each value is computed using bootstrap\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = np.zeros((X.shape[0], num_runs))\n",
    "    predictions[:, :] = np.nan\n",
    "    error = np.zeros((X.shape[0], num_runs))\n",
    "    error[:, :] = np.nan\n",
    "    indexes_all = np.arange(X.shape[0])\n",
    "    \n",
    "    for i  in tqdm_notebook(range(num_runs)):\n",
    "        indexes_train = np.random.choice(indexes_all,\n",
    "                                      size=X.shape[0],\n",
    "                                      replace=True)\n",
    "        indexes_test = np.setdiff1d(indexes_all, indexes_train)\n",
    "        regressor.fit(X[indexes_train], y[indexes_train])\n",
    "        \n",
    "        predictions[indexes_test, i] = regressor.predict(X[indexes_test])\n",
    "        error[indexes_test, i] = ((predictions[indexes_test, i] - y[indexes_test]) ** 2)\n",
    "\n",
    "    mean_pred_obj = np.nanmean(predictions, axis=1)\n",
    "    biase = np.mean((mean_pred_obj - y) ** 2)\n",
    "    \n",
    "    variance = np.mean(np.nanvar(predictions, axis=1))\n",
    "    error = np.mean(np.nanmean(error, axis=1))\n",
    "    \n",
    "    return biase, variance, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2. (1 балл)**\n",
    "\n",
    "Оцените смещение, разброс и ошибку для трех алгоритмов с гиперпараметрами по умолчанию: линейная регрессия, решающее дерево, случайный лес.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "dectree_reg = DecisionTreeRegressor()\n",
    "randfor_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d36e0383d44a209c5611aa74fe20da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66773b5f5bc7468aa4b29b0a03fc35c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c612bf462e54ae1be063d204b01e64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Смещение, разброс, ошибка для линейной регрессии: 23.802  0.920 24.722\n",
      "Смещение, разброс, ошибка для решающего дерева:   10.364 12.502 22.866\n",
      "Смещение, разброс, ошибка для случайного леса:    10.823  3.291 14.114\n"
     ]
    }
   ],
   "source": [
    "ans_reg = compute_biase_variance(lin_reg, X, y)\n",
    "ans_dec = compute_biase_variance(dectree_reg, X, y)\n",
    "ans_for = compute_biase_variance(randfor_reg, X, y)\n",
    "\n",
    "print(f'Смещение, разброс, ошибка для линейной регрессии: {ans_reg[0]:6.3f} {ans_reg[1]:6.3f} {ans_reg[2]:6.3f}')\n",
    "print(f'Смещение, разброс, ошибка для решающего дерева:   {ans_dec[0]:6.3f} {ans_dec[1]:6.3f} {ans_dec[2]:6.3f}')\n",
    "print(f'Смещение, разброс, ошибка для случайного леса:    {ans_for[0]:6.3f} {ans_for[1]:6.3f} {ans_for[2]:6.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте полученный результат. Согласуются ли полученные результаты с теми, что мы обсуждали на семинарах (с комментарием)?\n",
    "\n",
    "Вспомните обсуждение с лекции о том, во сколько раз в теории бутстрап уменьшает разброс базового алгоритма. Выполняется ли это в ваших экспериментах? Если нет, поясните, почему.\n",
    "\n",
    "На лекции обсуждалось то, что **бэггинг** в теории уменьшает разброс базового алгоритма в `m` раз (при условии, что алгоритмы мало скоррелированы между собой), где `m` - количество выборок, сформированных с помощью **бутстрапа**.\n",
    "\n",
    "__Your answer here:__ из полученных результатов видно, что:\n",
    "\n",
    "1. Линейная регрессия обладает наибольшим смещением и наименьшим разбросом среди 3 выбранных алгоритмов (что является логичным, так как большое смещение и маленький разброс говорят о простоте модели).\n",
    "1. Смещения решающего дерева и случайного леса практически не отличаются, так как из лекций известно, что бэггинг не изменяет смещение.\n",
    "1. Видно, что разброс случайного леса сильно уменьшился относительно решающего дерева. Этот факт частично подтверждает теоретическую часть, рассказанную на лекциях: бэггинг уменьшает разброс в `m` раз (при условии, что алгоритмы очень слабо скоррелированы между собой), где `m` - количество выборок, сформированных с помощью бутстрапа. В данном случае `m = 10`, так как по умолчанию в `RandomForestRegressor` значение `n_estimators = 10`. Мне кажется, что рассхождение возможно из-за того, что в при построении деревьев в случайном лесе деревья оказываются скоррелированы между собой.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация предсказаний базовых алгоритмов бэггинга\n",
    "\n",
    "В материалах лекций можно найти изображение, похожее на мишень - визуализация алгоритмов с разным смещением и разным разбросом. В центре \"мишени\" - правильный ответ, а \"попадания\" - предсказания алгоритмов, обученных по разным выборкам. Построим похожее изображение на наших данных для трех алгоритмов. Наши \"мишени\" будут одномерными, потому что мы решаем задачу одномерной регрессии.\n",
    "\n",
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Реализуйте фукнцию plot_predictions. Она должна выполнять следующие действия:\n",
    "1. Случайно выбрать num_test_objects пар объект-целевая переменная из выборки X, y. Получится две выборки: маленькая X_test, y_test (выбранные тестовые объекты) и X_train, y_train (остальные объекты).\n",
    "1. Сгенерировать num_runs выборок методом бутстарапа из X_train, y_train. На каждой выборке обучить алгоритм regressor и сделать предсказания для X_test.\n",
    "1. Нарисовать scatter-график. По оси абсцисс - объекты тестовой выборки (номера от 0 до num_test_objects-1), по оси ординат - предсказания. В итоге получится num_test_objects столбиков с точками. Для каждого тестового объекта надо отметить одним цветом все предсказания для него, а также черным цветом отметить правильный ответ.\n",
    "1. Подпишите оси и название графика (аргумент title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(13)\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_predictions(regressor, X, y, num_runs=5000, num_test_objects=15, title=\"\", ax=None):\n",
    "    \"\"\"\n",
    "    plot graphics described above\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=num_test_objects,\n",
    "                                                        random_state=13)\n",
    "    predictions = np.zeros((num_test_objects, num_runs))\n",
    "    all_indexes = np.arange(X_train.shape[0])\n",
    "    for i in range(num_runs):\n",
    "        indexes_bs = np.random.choice(all_indexes,\n",
    "                                      size=X_train.shape[0],\n",
    "                                      replace=True)\n",
    "        \n",
    "        regressor.fit(X_train[indexes_bs], y_train[indexes_bs])\n",
    "        predictions[:, i] = regressor.predict(X_test)\n",
    "        if ax is None:\n",
    "            plt.scatter(np.arange(X_test.shape[0]), predictions[:, i], color='black', label='y_preds')\n",
    "        else:\n",
    "            line_pred = ax.scatter(np.arange(X_test.shape[0]), predictions[:, i], color='black', label='y_preds')\n",
    "    if ax is None:\n",
    "        plt.scatter(np.arange(X_test.shape[0]), y_test, color='red', label='y_true')\n",
    "    else:\n",
    "        line_true = ax.scatter(np.arange(X_test.shape[0]), y_test, color='red', label='y_true')\n",
    "        ax.title.set_text(title)\n",
    "        ax.set_xticks(np.arange(num_test_objects))\n",
    "        ax.set_xlabel('Номер объекта из теста')\n",
    "    return line_true, line_pred\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте графики для линейной регрессии, решающего дерева и случайного леса. Нарисуйте три графика в строчку (это можно сделать с помощью plt.subplot) с одинаковой осью ординат (это важно для понимания масштаба разброса у разных алгоритмов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "dectree_reg = DecisionTreeRegressor()\n",
    "randforest_reg = RandomForestRegressor(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 10), sharey=True)\n",
    "plot_predictions(lin_reg, X, y, ax=axs[0], title='Линейная регрессия')\n",
    "plot_predictions(dectree_reg, X, y, ax=axs[1], title='Решающее дерево')\n",
    "l_true, l_pred = plot_predictions(randforest_reg, X, y, ax=axs[2], title='Случайный лес')\n",
    "axs[0].set_ylabel('Значение целевого признака')\n",
    "\n",
    "fig.suptitle('Зависимость значений целевого признака от тестового объекта', fontsize=20)\n",
    "plt.legend([l_true, l_pred],['y_true', 'y_pred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого графика прокомментируйте, как он характеризует смещение и разброс соответствующего алгоритма.\n",
    "\n",
    "**Your answer here:**\n",
    "по данным графикам видно, что выполняются выводы из задания номер 2:\n",
    "\n",
    "1. Линейная регрессия обладает наибольшим смещением и наименьшим разбросом среди 3 выбранных алгоритмов (что является логичным, так как большое смещение и маленький разброс говорят о простоте модели).\n",
    "1. Рещающее дерево обладает достаточно большим разбросом, так как эта модель очень склонна к переобучению (`max_depth = None` по умолчанию, что говорит о неограниченности глубины дерева).\n",
    "1. Смещения решающего дерева и случайного леса практически не отличаются, так как из лекций известно, что бэггинг не изменяет смещение.\n",
    "1. Видно, что разброс случайного леса сильно уменьшился относительно решающего дерева. Этот факт частично подтверждает теоретическую часть, рассказанную на лекциях: бэггинг уменьшает разброс в `m` раз (при условии, что алгоритмы очень слабо скоррелированы между собой), где `m` - количество выборок, сформированных с помощью бутстрапа. В данном случае `m = 10`, так как по умолчанию в `RandomForestRegressor` значение `n_estimators = 10`. Мне кажется, что рассхождение возможно из-за того, что в при построении деревьев в случайном лесе деревья оказываются скоррелированы между собой.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (1 балл)**\n",
    "\n",
    "Мы будем использовать данные из [соревнования](https://www.kaggle.com/t/b710e05dc0bd424995ca94da5b639869). \n",
    "* Загрузите таблицу application_train.csv;\n",
    "* Запишите в Y столбец с целевой переменной (TARGET);\n",
    "* Удалите ненужные столбцы (для этого воспользуйтесь описанием);\n",
    "* Определите тип столбцов и заполните пропуски - стратегия произвольная;\n",
    "* Разбейте выборку в соотношении 70:30 с random_state=0.\n",
    "\n",
    "Так как в данных имеется значительный дисбаланс классов, в качестве метрики качества везде будем использовать площадь под precision-recall кривой (AUC-PR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/application_train.csv')\n",
    "\n",
    "Y = train_data['TARGET']\n",
    "train_data.drop(columns='TARGET', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Какие признаки можно удалить?\n",
    " 1. Удалим признак `SK_ID_CURR`, так уникальный идентификатор не несет никакой информации о целевом признаке\n",
    " 1. Удалим признаки `WEEKDAY_APPR_PROCESS_START` и `HOUR_APPR_PROCESS_START`, так как они отвечают за день недели и время подачи заявки на кредит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['SK_ID_CURR',\n",
    "                         'WEEKDAY_APPR_PROCESS_START',\n",
    "                         'HOUR_APPR_PROCESS_START'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215257, 118)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Будем считать, что признак категориальный, если количество уникальных значений 2 <= n <= 30~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_uniq = 30\n",
    "#cat_features = []\n",
    "\n",
    "\n",
    "#for col in train_data.columns:\n",
    "#    uniq_amount = len(train_data[col].unique())\n",
    "#    if (uniq_amount <= n_uniq) & (uniq_amount >= 2):\n",
    "#        cat_features.append(col)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что признак категориальный, если его тип = 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.53 ms, sys: 0 ns, total: 3.53 ms\n",
      "Wall time: 3.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_features = []\n",
    "\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        cat_features.append(col)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вещественных признаков заполним пропуски средним по данному признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = set(train_data.columns) - set(cat_features)\n",
    "\n",
    "\n",
    "for numerical_col in numerical_features:\n",
    "    mean_col = np.mean(train_data[numerical_col])\n",
    "    train_data[numerical_col].fillna(mean_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку в соотношении 70:30 с random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите реализации градиентного бустинга LightGBM и Catboost на вещественных признаках без подбора параметров. **Почему получилась заметная разница в качестве?**\n",
    "\n",
    "В этом и последующих экспериментах необходимо измерять время обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 s, sys: 869 ms, total: 31.5 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_jobs=-1)\n",
    "lgbm_model.fit(X_train[numerical_features], y_train)\n",
    "lgbm_preds = lgbm_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 49s, sys: 6.25 s, total: 5min 55s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0, thread_count=16)\n",
    "catboost_model.fit(X_train[numerical_features], y_train)\n",
    "catboost_preds = catboost_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM PR-AUC: 0.2397493585281123\n",
      "CatBoost PR-AUC: 0.23844508531957803\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM PR-AUC: {average_precision_score(y_test, lgbm_preds)}')\n",
    "print(f'CatBoost PR-AUC: {average_precision_score(y_test, catboost_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** Разница получилась совсем незначительной, хоть и Catboost обучался почти в 21 раз дольше.. LGBM показал качество хуже, так как, возможно, для этих данных \"жадный алгоритм\", встроенный в реализации LGBM, построения композиции дает не самый лучший результат. Еще одна причина: мы совсем не использовали категориальные признаки, а они как раз являются ключевой особенностью библиотеки Catboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем ещё немного предобработки: \n",
    "1. Удалим все признаки, в которых $количество\\spaceпропусков >= 0.6 * (количество\\spaceвсех\\spaceзначений)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/application_train.csv')\n",
    "\n",
    "Y = train_data['TARGET']\n",
    "train_data.drop(columns='TARGET', inplace=True)\n",
    "\n",
    "train_data.drop(columns=['SK_ID_CURR',\n",
    "                         'WEEKDAY_APPR_PROCESS_START',\n",
    "                         'HOUR_APPR_PROCESS_START'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки, которые содержат более 60% nan-значений:\n",
      "OWN_CAR_AGE , Процент nan-значений: 65.89%\n",
      "YEARS_BUILD_AVG , Процент nan-значений: 66.50%\n",
      "COMMONAREA_AVG , Процент nan-значений: 69.86%\n",
      "FLOORSMIN_AVG , Процент nan-значений: 67.82%\n",
      "LIVINGAPARTMENTS_AVG , Процент nan-значений: 68.33%\n",
      "NONLIVINGAPARTMENTS_AVG , Процент nan-значений: 69.41%\n",
      "YEARS_BUILD_MODE , Процент nan-значений: 66.50%\n",
      "COMMONAREA_MODE , Процент nan-значений: 69.86%\n",
      "FLOORSMIN_MODE , Процент nan-значений: 67.82%\n",
      "LIVINGAPARTMENTS_MODE , Процент nan-значений: 68.33%\n",
      "NONLIVINGAPARTMENTS_MODE , Процент nan-значений: 69.41%\n",
      "YEARS_BUILD_MEDI , Процент nan-значений: 66.50%\n",
      "COMMONAREA_MEDI , Процент nan-значений: 69.86%\n",
      "FLOORSMIN_MEDI , Процент nan-значений: 67.82%\n",
      "LIVINGAPARTMENTS_MEDI , Процент nan-значений: 68.33%\n",
      "NONLIVINGAPARTMENTS_MEDI , Процент nan-значений: 69.41%\n",
      "FONDKAPREMONT_MODE , Процент nan-значений: 68.38%\n"
     ]
    }
   ],
   "source": [
    "print('Признаки, которые содержат более 60% nan-значений:')\n",
    "for col in train_data.columns:\n",
    "    if (np.sum(train_data.isna()[col]) / len(train_data)) >= 0.6:\n",
    "        print(col, f', Процент nan-значений: {100 * np.sum(train_data.isna()[col]) / len(train_data):.2f}%')\n",
    "        train_data.drop(columns=col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 ms, sys: 523 µs, total: 32 ms\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        cat_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = set(train_data.columns) - set(cat_features)\n",
    "\n",
    "\n",
    "for numerical_col in numerical_features:\n",
    "    mean_col = np.mean(train_data[numerical_col])\n",
    "    train_data[numerical_col].fillna(mean_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели только на вещественных признаках и посмотрим на результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 675 ms, total: 27.4 s\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_jobs=-1)\n",
    "lgbm_model.fit(X_train[numerical_features], y_train)\n",
    "lgbm_preds = lgbm_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 24s, sys: 5.5 s, total: 5min 29s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0, thread_count=16)\n",
    "catboost_model.fit(X_train[numerical_features], y_train)\n",
    "catboost_preds = catboost_model.predict_proba(X_test[numerical_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM PR-AUC: 0.23529529795703574\n",
      "CatBoost PR-AUC: 0.23618625167132357\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM PR-AUC: {average_precision_score(y_test, lgbm_preds)}')\n",
    "print(f'CatBoost PR-AUC: {average_precision_score(y_test, catboost_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь `CatBoostClassifier` стал лучше, чем `LGBMClassifier`. Интересно, что выбрасывание столбцов с большим количеством nan-значений сильнее ухудшило результат `LGBMClassifier`, чем `CatBoostClassifier`. Это говорит о стабильности алгоритма `CatBoostClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ради эксперимента попробуем использовать еще и категориальные признаки вместе с вещественными:\n",
    " 1. Сначала попробуем самостоятельно закодировать их с помощью one-hot кодирования.\n",
    " 1. Затем воспользуемся встроенными методами обработки категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, cat_columns):\n",
    "    data_ohe = data.copy()\n",
    "    for cat_column in cat_columns:\n",
    "        unique_values = data_ohe[cat_column].unique()\n",
    "        for unique_value in unique_values:\n",
    "            data_ohe[cat_column + '_' + str(unique_value)] = data_ohe[cat_column] == unique_value\n",
    "            data_ohe[cat_column + '_' + str(unique_value)] =\\\n",
    "                data_ohe[cat_column + '_' + str(unique_value)].map({True: 1, False: 0})\n",
    "    return data_ohe.drop(columns=cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных признаков заполним пропуски самым популярным значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_features:\n",
    "    nan_mask = train_data[cat_col].isna()\n",
    "    train_data.loc[nan_mask, cat_col] = train_data[cat_col].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 915 ms, total: 11.6 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_ohe = one_hot_encoding(train_data, cat_features)\n",
    "train_data_ohe.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_data_ohe.columns]\n",
    "## чтобы LGBM не ругался на название признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку в соотношении 70:30 с random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_ohe, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 1.51 s, total: 36 s\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_jobs=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_preds = lgbm_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 36s, sys: 6.02 s, total: 5min 42s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0, thread_count=16)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_preds = catboost_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM PR-AUC: 0.24238566035191744\n",
      "CatBoost PR-AUC: 0.24762594465394733\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM PR-AUC: {average_precision_score(y_test, lgbm_preds)}')\n",
    "print(f'CatBoost PR-AUC: {average_precision_score(y_test, catboost_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CatBoostClassifier` стал превосходить по качеству `LGBMClassifier`. Это и ожидалось. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим качество при встроенной обработке категориальных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Опять же для того, чтобы LGBMClassifier заработал\n",
    "\n",
    "train_data_cat = train_data.copy()\n",
    "for c in train_data_cat.columns:\n",
    "    col_type = train_data_cat[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        train_data_cat[c] = train_data_cat[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_cat, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 1.03 s, total: 31.2 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_jobs=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_preds = lgbm_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Change of combinations ctrs will not affect simple ctrs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 3s, sys: 36.8 s, total: 13min 40s\n",
      "Wall time: 52.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0, thread_count=16, cat_features=cat_features,\n",
    "                                   model_size_reg=0,\n",
    "                                   combinations_ctr='Borders:TargetBorderType=GreedyLogSum')\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_preds = catboost_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM PR-AUC: 0.24300801616126183\n",
      "CatBoost PR-AUC: 0.24803399121177794\n"
     ]
    }
   ],
   "source": [
    "print(f'LGBM PR-AUC: {average_precision_score(y_test, lgbm_preds)}')\n",
    "print(f'CatBoost PR-AUC: {average_precision_score(y_test, catboost_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что встроенная обработка категориальных признаков работает лучше, чем обычное one-hot кодирование (что неудивительно). При этом прирост качества у `CatBoostClassifier` больше (относительно one-hot кодирования), чем у `LGBMClassifier`, но не стоит забывать и о времени работы: время работы `CatBoostClassifier` увеличилось почти в **3 раза**, а у `LGBMClassifier` практически не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (2 балла)__\n",
    "\n",
    "Подберите оптимальные с точки зрения метрики качества параметры алгоритмов, изменяя:\n",
    "\n",
    "* глубину деревьев;\n",
    "* количество деревьев;\n",
    "* темп обучения;\n",
    "* оптимизируемый функционал.\n",
    "\n",
    "Масштаб значений предлагается посмотреть в [семинаре](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/seminars/sem10-gbm.ipynb) про библиотеки.\n",
    "\n",
    "**Проанализируйте соотношения глубины и количества деревьев в зависимости от алгоритма.** \n",
    "\n",
    "**Если на перебор гиперпараметров уходит много времени, то переберите значениях каких-нибудь 1-2 гиперпараметров, а не всех предложенных 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем аналогичную предобработку, которая раньше давала качество:\n",
    "1. CatBoost PR-AUC: 0.2384\n",
    "1. LGBM PR-AUC: 0.2396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/application_train.csv')\n",
    "\n",
    "Y = train_data['TARGET']\n",
    "train_data.drop(columns='TARGET', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Какие признаки можно удалить?\n",
    " 1. Удалим признак `SK_ID_CURR`, так уникальный идентификатор не несет никакой информации о целевом признаке\n",
    " 1. Удалим признаки `WEEKDAY_APPR_PROCESS_START` и `HOUR_APPR_PROCESS_START`, так как они отвечают за день недели и время подачи заявки на кредит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['SK_ID_CURR',\n",
    "                         'WEEKDAY_APPR_PROCESS_START',\n",
    "                         'HOUR_APPR_PROCESS_START'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215257, 118)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Будем считать, что признак категориальный, если количество уникальных значений 2 <= n <= 30~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_uniq = 30\n",
    "#cat_features = []\n",
    "\n",
    "\n",
    "#for col in train_data.columns:\n",
    "#    uniq_amount = len(train_data[col].unique())\n",
    "#    if (uniq_amount <= n_uniq) & (uniq_amount >= 2):\n",
    "#        cat_features.append(col)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что признак категориальный, если его тип = 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.11 ms, sys: 3 µs, total: 4.11 ms\n",
      "Wall time: 4.12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_features = []\n",
    "\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        cat_features.append(col)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вещественных признаков заполним пропуски средним по данному признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = set(train_data.columns) - set(cat_features)\n",
    "\n",
    "\n",
    "for numerical_col in numerical_features:\n",
    "    mean_col = np.mean(train_data[numerical_col])\n",
    "    train_data[numerical_col].fillna(mean_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку в соотношении 70:30 с random_state=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799083c90a424972a4369d9f5e09ce88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1h 11s, sys: 21min 4s, total: 1h 21min 16s\n",
      "Wall time: 34min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "max_depth_list = list(range(1, 10, 1)) + list(range(10, 16, 2))\n",
    "tree_amount_list = [1, 5, 10, 100, 300, 500, 700]\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1, 1]\n",
    "loss_func_list = ['Logloss'] # Так как это задача бинарной классификации,\n",
    "                             # то обе библиотеки предоставляют единственный вариант\n",
    "\n",
    "catboost_logger = {'max_depth_list': [],\n",
    "                   'tree_amount_list': [],\n",
    "                   'learning_rate_list': [],\n",
    "                   'loss_func_list': [],\n",
    "                   'AUC-PR_list': [],\n",
    "                   'estimated_time': []\n",
    "                  }\n",
    "\n",
    "i = 0\n",
    "\n",
    "for max_depth in tqdm_notebook(max_depth_list):\n",
    "    for tree_amount in tree_amount_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for loss_func in loss_func_list:\n",
    "                start_time = time.time()\n",
    "                catboost_model = CatBoostClassifier(max_depth=max_depth, n_estimators=tree_amount,\n",
    "                                            learning_rate=lr, objective=loss_func,\n",
    "                                             task_type='GPU', verbose=0, thread_count=-1)\n",
    "                \n",
    "                catboost_model.fit(X_train[numerical_features], y_train)\n",
    "                preds = catboost_model.predict_proba(X_test[numerical_features])[:, 1]\n",
    "                catboost_logger['AUC-PR_list'].append(average_precision_score(y_test, preds))\n",
    "                catboost_logger['max_depth_list'].append(max_depth)\n",
    "                catboost_logger['tree_amount_list'].append(tree_amount)\n",
    "                catboost_logger['learning_rate_list'].append(lr)\n",
    "                catboost_logger['loss_func_list'].append(loss_func)\n",
    "                catboost_logger['estimated_time'].append(time.time() - start_time)\n",
    "                \n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('catboost_logger.pkl', 'wb') as file:\n",
    "    pickle.dump(catboost_logger, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paniquex/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3c07a7934d4d3988fd4c4379f65876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5h 33min 32s, sys: 7min 26s, total: 5h 40min 58s\n",
      "Wall time: 10min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "max_depth_list = list(range(1, 10, 1)) + list(range(10, 20, 2))\n",
    "tree_amount_list = [1, 5, 10, 100, 300, 500, 700]\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1, 1]\n",
    "loss_func_list = ['binary'] # Так как это задача бинарной классификации,\n",
    "                             # то обе библиотеки предоставляют единственный вариант\n",
    "\n",
    "lgbm_logger = {'max_depth_list': [],\n",
    "                   'tree_amount_list': [],\n",
    "                   'learning_rate_list': [],\n",
    "                   'loss_func_list': [],\n",
    "                   'AUC-PR_list': [],\n",
    "                   'estimated_time': []\n",
    "                  }\n",
    "\n",
    "i = 0\n",
    "\n",
    "for max_depth in tqdm_notebook(max_depth_list):\n",
    "    for tree_amount in tree_amount_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for loss_func in loss_func_list:\n",
    "                start_time = time.time()\n",
    "                lgbm_model = LGBMClassifier(max_depth=max_depth, n_estimators=tree_amount,\n",
    "                                            learning_rate=lr, objective=loss_func,\n",
    "                                             n_jobs=-1, device='CPU')\n",
    "                \n",
    "                lgbm_model.fit(X_train[numerical_features], y_train)\n",
    "                preds = lgbm_model.predict_proba(X_test[numerical_features])[:, 1]\n",
    "                lgbm_logger['AUC-PR_list'].append(average_precision_score(y_test, preds))\n",
    "                lgbm_logger['max_depth_list'].append(max_depth)\n",
    "                lgbm_logger['tree_amount_list'].append(tree_amount)\n",
    "                lgbm_logger['learning_rate_list'].append(lr)\n",
    "                lgbm_logger['loss_func_list'].append(loss_func)\n",
    "                lgbm_logger['estimated_time'].append(time.time() - start_time)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('lgbm_logger.pkl', 'wb') as file:\n",
    "    pickle.dump(lgbm_logger, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_idx_ctb = np.argmax(catboost_logger['AUC-PR_list'])\n",
    "best_score_idx_lgb = np.argmax(lgbm_logger['AUC-PR_list'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры для CatBoostClassifier: \n",
      "      Максимальная глубина деревьев:             3\n",
      "      Количество деревьев:                     500\n",
      "      Learning rate:                           0.1\n",
      "      Затраченное время (GPU):                1.56 с.\n",
      "      Значение метрики:                    0.24370\n"
     ]
    }
   ],
   "source": [
    "print(f'''Оптимальные параметры для CatBoostClassifier: \n",
    "      Максимальная глубина деревьев:        {catboost_logger['max_depth_list'][best_score_idx_ctb]:6}\n",
    "      Количество деревьев:                  {catboost_logger['tree_amount_list'][best_score_idx_ctb]:6}\n",
    "      Learning rate:                        {catboost_logger['learning_rate_list'][best_score_idx_ctb]:6}\n",
    "      Затраченное время (GPU):              {catboost_logger['estimated_time'][best_score_idx_ctb]:6.2f} с.\n",
    "      Значение метрики:                    {catboost_logger['AUC-PR_list'][best_score_idx_ctb]:5.5f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как для ускорения работы `CatBoostClassifier` обучение производилось на GPU, то время сравнивать сложно. Проведем еще раз обучение алгоритма CatBoostClassifier с лучшими параметрами и измерим время:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(max_depth=3, n_estimators=700,\n",
    "                                            learning_rate=0.1, objective='Logloss',\n",
    "                                             task_type='CPU', verbose=0, thread_count=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "catboost_model.fit(X_train[numerical_features], y_train)\n",
    "catboost_logger['estimated_time'][best_score_idx_ctb] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры для CatBoostClassifier: \n",
      "      Максимальная глубина деревьев:             3\n",
      "      Количество деревьев:                     500\n",
      "      Learning rate:                           0.1\n",
      "      Затраченное время (CPU):               12.98 с.\n",
      "      Значение метрики:                     0.24370\n"
     ]
    }
   ],
   "source": [
    "print(f'''Оптимальные параметры для CatBoostClassifier: \n",
    "      Максимальная глубина деревьев:        {catboost_logger['max_depth_list'][best_score_idx_ctb]:6}\n",
    "      Количество деревьев:                  {catboost_logger['tree_amount_list'][best_score_idx_ctb]:6}\n",
    "      Learning rate:                        {catboost_logger['learning_rate_list'][best_score_idx_ctb]:6}\n",
    "      Затраченное время (CPU):              {catboost_logger['estimated_time'][best_score_idx_ctb]:6.2f} с.\n",
    "      Значение метрики:                     {catboost_logger['AUC-PR_list'][best_score_idx_ctb]:5.5f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры для LGBMClassifier: \n",
      "      Максимальная глубина деревьев:             3\n",
      "      Количество деревьев:                     300\n",
      "      Learning rate:                           0.1\n",
      "      Затраченное время (CPU):                1.37 с.\n",
      "      Значение метрики:                    0.24335\n"
     ]
    }
   ],
   "source": [
    "print(f'''Оптимальные параметры для LGBMClassifier: \n",
    "      Максимальная глубина деревьев:        {lgbm_logger['max_depth_list'][best_score_idx_lgb]:6}\n",
    "      Количество деревьев:                  {lgbm_logger['tree_amount_list'][best_score_idx_lgb]:6}\n",
    "      Learning rate:                        {lgbm_logger['learning_rate_list'][best_score_idx_lgb]:6}\n",
    "      Затраченное время (CPU):              {lgbm_logger['estimated_time'][best_score_idx_lgb]:6.2f} с.\n",
    "      Значение метрики:                    {lgbm_logger['AUC-PR_list'][best_score_idx_lgb]:5.5f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данных результатов видно, что для `CatBoostClassifier` оптимальная глубина деревьев на 1 больше, чем оптимальная глубина для `LGBMClassifier`. При этом количество деревьев, которые нужны для оптимального качества, более чем полтора раза больше у `CatBoostClassifier`, чем у `LGBMClassifier`.\n",
    "\n",
    "Хоть и качество у `CatBoostClassifier` оказалось выше, обучался данный алгоритм почти в 10 раз дольше. На лекции говорилось, что скорость работы `LGBMClassifier` достигается за счет группировки разреженных признаков с маленьким пересечением ненулевых значений в один признак и за счет акцентирования основного внимания на объектах, имеющих большие градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ясно, что простой перебор по сетке значений параметров занимает огромное количество времени, поэтому воспользуемся библиотекой `bayes_opt`, рассмотренную на одном из семинаров по практикуму, для ускорения поиска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_bayesian(max_depth,\n",
    "                      n_estimators,\n",
    "                      lr,\n",
    "                      ):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    model = CatBoostClassifier(max_depth=max_depth, n_estimators=n_estimators,\n",
    "                               learning_rate=lr, objective='Logloss',\n",
    "                               task_type='GPU', verbose=0, thread_count=16)\n",
    "    model.fit(X_train[numerical_features], y_train)\n",
    "\n",
    "    return average_precision_score(y_test, model.predict_proba(X_test[numerical_features])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_cat = {\n",
    "    'max_depth': (1, 16),\n",
    "    'n_estimators': (1, 1000),\n",
    "    'lr': (1e-5, 1),\n",
    "}\n",
    "\n",
    "cat_BO = BayesianOptimization(catboost_bayesian, bounds_cat, random_state=13 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.1858  \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m 8.791   \u001b[0m | \u001b[0m 768.5   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1524  \u001b[0m | \u001b[0m 0.7892  \u001b[0m | \u001b[0m 14.06   \u001b[0m | \u001b[0m 188.7   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.1936  \u001b[0m | \u001b[95m 0.2695  \u001b[0m | \u001b[95m 8.443   \u001b[0m | \u001b[95m 739.4   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.2424  \u001b[0m | \u001b[95m 0.195   \u001b[0m | \u001b[95m 3.696   \u001b[0m | \u001b[95m 539.3   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1764  \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 270.4   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1837  \u001b[0m | \u001b[0m 0.2935  \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 913.3   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1655  \u001b[0m | \u001b[0m 0.5682  \u001b[0m | \u001b[0m 8.282   \u001b[0m | \u001b[0m 654.1   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.1593  \u001b[0m | \u001b[0m 0.5366  \u001b[0m | \u001b[0m 15.94   \u001b[0m | \u001b[0m 142.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1509  \u001b[0m | \u001b[0m 0.9753  \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 720.8   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.1779  \u001b[0m | \u001b[0m 0.2951  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 750.9   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.08166 \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1824  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e+03   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.1807  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 408.4   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.182   \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 876.3   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.2383  \u001b[0m | \u001b[0m 0.3367  \u001b[0m | \u001b[0m 1.078   \u001b[0m | \u001b[0m 591.1   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.2385  \u001b[0m | \u001b[0m 0.2002  \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 479.2   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.1824  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 85.93   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.2405  \u001b[0m | \u001b[0m 0.6957  \u001b[0m | \u001b[0m 1.092   \u001b[0m | \u001b[0m 945.8   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.2384  \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 322.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 0.03144 \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 257.4   \u001b[0m |\n",
      "=============================================================\n",
      "CPU times: user 9min 27s, sys: 4min 21s, total: 13min 48s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    cat_BO.maximize(init_points=10, n_iter=10, acq='ucb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_bayesian(max_depth,\n",
    "                      n_estimators,\n",
    "                      lr,\n",
    "                      ):\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    model = LGBMClassifier(max_depth=max_depth, n_estimators=n_estimators,\n",
    "                           learning_rate=lr, objective=loss_func,\n",
    "                           n_jobs=16, device='CPU')\n",
    "    model.fit(X_train[numerical_features], y_train)\n",
    "\n",
    "    return average_precision_score(y_test, model.predict_proba(X_test[numerical_features])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_lgbm = {\n",
    "    'max_depth': (1, 16),\n",
    "    'n_estimators': (1, 1000),\n",
    "    'lr': (1e-5, 1),\n",
    "}\n",
    "\n",
    "\n",
    "lgbm_BO = BayesianOptimization(lgb_bayesian, bounds_lgbm, random_state=13 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.1864  \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m 8.791   \u001b[0m | \u001b[0m 768.5   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1651  \u001b[0m | \u001b[0m 0.7892  \u001b[0m | \u001b[0m 14.06   \u001b[0m | \u001b[0m 188.7   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.2006  \u001b[0m | \u001b[95m 0.2695  \u001b[0m | \u001b[95m 8.443   \u001b[0m | \u001b[95m 739.4   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.2327  \u001b[0m | \u001b[95m 0.195   \u001b[0m | \u001b[95m 3.696   \u001b[0m | \u001b[95m 539.3   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1959  \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 270.4   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1845  \u001b[0m | \u001b[0m 0.2935  \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 913.3   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1468  \u001b[0m | \u001b[0m 0.5682  \u001b[0m | \u001b[0m 8.282   \u001b[0m | \u001b[0m 654.1   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.165   \u001b[0m | \u001b[0m 0.5366  \u001b[0m | \u001b[0m 15.94   \u001b[0m | \u001b[0m 142.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1401  \u001b[0m | \u001b[0m 0.9753  \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 720.8   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.1836  \u001b[0m | \u001b[0m 0.2951  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 750.9   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.1461  \u001b[0m | \u001b[0m 0.6414  \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 888.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1563  \u001b[0m | \u001b[0m 0.6447  \u001b[0m | \u001b[0m 5.435   \u001b[0m | \u001b[0m 682.9   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.2377  \u001b[0m | \u001b[95m 0.277   \u001b[0m | \u001b[95m 2.896   \u001b[0m | \u001b[95m 570.3   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1705  \u001b[0m | \u001b[0m 0.4091  \u001b[0m | \u001b[0m 9.406   \u001b[0m | \u001b[0m 854.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.2254  \u001b[0m | \u001b[0m 0.09673 \u001b[0m | \u001b[0m 6.315   \u001b[0m | \u001b[0m 973.6   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.1757  \u001b[0m | \u001b[0m 0.922   \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 51.91   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.1652  \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 12.55   \u001b[0m | \u001b[0m 240.4   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.242   \u001b[0m | \u001b[95m 0.1038  \u001b[0m | \u001b[95m 3.794   \u001b[0m | \u001b[95m 753.0   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.1652  \u001b[0m | \u001b[0m 0.9529  \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 187.4   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.2268  \u001b[0m | \u001b[0m 0.5121  \u001b[0m | \u001b[0m 2.222   \u001b[0m | \u001b[0m 523.7   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.1865  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 392.6   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.1084  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.2384  \u001b[0m | \u001b[0m 0.4705  \u001b[0m | \u001b[0m 1.019   \u001b[0m | \u001b[0m 342.8   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.1126  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 1e+03   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.2399  \u001b[0m | \u001b[0m 0.3089  \u001b[0m | \u001b[0m 1.013   \u001b[0m | \u001b[0m 925.8   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.2388  \u001b[0m | \u001b[0m 0.1515  \u001b[0m | \u001b[0m 1.05    \u001b[0m | \u001b[0m 435.2   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.181   \u001b[0m | \u001b[0m 0.01552 \u001b[0m | \u001b[0m 1.026   \u001b[0m | \u001b[0m 84.31   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.242   \u001b[0m | \u001b[0m 0.02768 \u001b[0m | \u001b[0m 15.89   \u001b[0m | \u001b[0m 465.2   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.1567  \u001b[0m | \u001b[0m 0.6551  \u001b[0m | \u001b[0m 15.98   \u001b[0m | \u001b[0m 320.7   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.2355  \u001b[0m | \u001b[0m 0.1477  \u001b[0m | \u001b[0m 1.024   \u001b[0m | \u001b[0m 296.7   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.2374  \u001b[0m | \u001b[0m 0.09299 \u001b[0m | \u001b[0m 1.089   \u001b[0m | \u001b[0m 610.7   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.2273  \u001b[0m | \u001b[0m 0.02599 \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 811.8   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.236   \u001b[0m | \u001b[0m 0.07919 \u001b[0m | \u001b[0m 15.9    \u001b[0m | \u001b[0m 519.9   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.1084  \u001b[0m | \u001b[0m 1.087e-0\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 733.0   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.1516  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 600.3   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.1745  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 98.88   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.2379  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e+03   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.1844  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.1084  \u001b[0m | \u001b[0m 1e-05   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 479.6   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.1592  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 428.8   \u001b[0m |\n",
      "=============================================================\n",
      "CPU times: user 28min 51s, sys: 35.5 s, total: 29min 26s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    lgbm_BO.maximize(init_points=20, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры для CatBoostClassifier: \n",
      "      Максимальная глубина деревьев:             3\n",
      "      Количество деревьев:                     539\n",
      "      Learning rate:                        0.19496\n",
      "      Значение метрики:                     0.24244\n"
     ]
    }
   ],
   "source": [
    "print(f'''Оптимальные параметры для CatBoostClassifier: \n",
    "      Максимальная глубина деревьев:        {int(cat_BO.max['params']['max_depth']):6}\n",
    "      Количество деревьев:                  {int(cat_BO.max['params']['n_estimators']):6}\n",
    "      Learning rate:                        {cat_BO.max['params']['lr']:1.5f}\n",
    "      Значение метрики:                     {cat_BO.max['target']:2.5f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры для LGBMClassifier: \n",
      "      Максимальная глубина деревьев:             3\n",
      "      Количество деревьев:                     752\n",
      "      Learning rate:                        0.10382\n",
      "      Значение метрики:                     0.24203\n"
     ]
    }
   ],
   "source": [
    "print(f'''Оптимальные параметры для LGBMClassifier: \n",
    "      Максимальная глубина деревьев:        {int(lgbm_BO.max['params']['max_depth']):6}\n",
    "      Количество деревьев:                  {int(lgbm_BO.max['params']['n_estimators']):6}\n",
    "      Learning rate:                        {lgbm_BO.max['params']['lr']:1.5f}\n",
    "      Значение метрики:                     {lgbm_BO.max['target']:2.5f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из результатов видно, что качество немного ухудшилось, зато скорость перебора параметров повысилась:\n",
    "1. Для `CatBoostClassifier` более, чем в 3 раза.\n",
    "1. Для `LGBMClassifier` более, чем в 4 раза!\n",
    "\n",
    "При этом соотношение максимальной глубины и количества деревьев алгоритма `LGBMClassifier` изменилось: \n",
    "1. Количество деревьев, нужных для достижения оптимального качества стало превосходить более, чем в 2 раза предыдущее значение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
