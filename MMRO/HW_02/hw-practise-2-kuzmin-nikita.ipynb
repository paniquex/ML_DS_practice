{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 9 октября 2019\n",
    "\n",
    "Максимальная оценка: 10 баллов + 1 бонусный балл\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 23 октября (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 30 октября."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- Познакомитесь с методом решения задачи регрессии на основе метода ближайших соседей.\n",
    "- Реализуете алгоритм kNN для задачи регрессии.\n",
    "- Изучите методы работы с категориальными и текстовыми переменными.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-02-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-02-ivanov.ipynb).\n",
    "\n",
    "Далее отправьте этот файл на anytask в соответсвующий раздел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования New York City Airbnb Open Data: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#AB_NYC_2019.csv\n",
    "\n",
    "В данной задаче предлагается предсказать цену на съем квартиры в зависимости от её параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 48895\n",
      "name 47906\n",
      "host_id 37457\n",
      "host_name 11453\n",
      "neighbourhood_group 5\n",
      "neighbourhood 221\n",
      "latitude 19048\n",
      "longitude 14718\n",
      "room_type 3\n",
      "price 674\n",
      "minimum_nights 109\n",
      "number_of_reviews 394\n",
      "last_review 1765\n",
      "reviews_per_month 938\n",
      "calculated_host_listings_count 47\n",
      "availability_365 366\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, в данных есть пропуски. Не забудьте обработать их"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в колонках **name** и **host_name** значением '-1', которое будет сигнализировать о пропуске в колонке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['name'].isna(), 'name'] = '-1'\n",
    "data.loc[data['host_name'].isna(), 'host_name'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С колонкой $last\\_review$ поступим иначе:\n",
    "* $last\\_review$ - рассмотрим объект $x$ такой, что $x[\"last\\_review\"] = nan$ и $x[\"neighbourhood\"] = neigh$. Тогда $x[\"last\\_review\"]$ заполняем наиболее встречаемым значением в колонке $last\\_review$ среди всех объектов $x_{i}$ тренировочной выборки: $x_{i}[\"neighbourhood\"] = neigh$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 21.8 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "is_last_review_nan = data['last_review'].isna()\n",
    "for neigh in data[is_last_review_nan]['neighbourhood']:\n",
    "    is_neigh = data['neighbourhood'] == neigh\n",
    "    if data[is_neigh].shape[0] == 1:\n",
    "        data.loc[is_last_review_nan, 'last_review'] = '-1'\n",
    "    else:\n",
    "        data.loc[is_neigh & is_last_review_nan, 'last_review'] = data[is_neigh]['last_review'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А для колонки **$reviews\\_per\\_month$** возьмем не наиболее встречаемое значение, а среднее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 s, sys: 24 ms, total: 43.4 s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "is_reviews_per_month_nan = data['reviews_per_month'].isna()\n",
    "for neigh in data[is_last_review_nan]['neighbourhood']:\n",
    "    is_neigh = data['neighbourhood'] == neigh\n",
    "    if data[is_neigh].shape[0] == 1:\n",
    "        data.loc[is_reviews_per_month_nan, 'reviews_per_month'] = -1\n",
    "    else:\n",
    "        data.loc[is_neigh & is_reviews_per_month_nan, 'reviews_per_month'] = data[is_neigh]['reviews_per_month'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные на обучение и контроль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования модели без категориальных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_non_cat, X_test_non_cat, y_train_non_cat, y_test_non_cat = train_test_split(data.drop(columns=['price',\n",
    "                                                                                              'last_review',\n",
    "                                                                                              'name',\n",
    "                                                                                              'host_name',\n",
    "                                                                                              'neighbourhood_group',\n",
    "                                                                                              'neighbourhood',\n",
    "                                                                                              'room_type']),\n",
    "                                                                                    data[['price']],\n",
    "                                                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['price']),\n",
    "                                                    data[['price']],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Алгоритм kNN в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.1 (1.5 балла) </b>\n",
    "Реализуйте класс `KNNRegressor`, который используя метод k ближайших соседей решает задачу регрессии. Для решение данной задачи, необходимо найти $N_k$ - k соседей, и после использовать значения их целевых переменных для предсказания:\n",
    "\\begin{align}\n",
    "y = \\frac{1}{k}\\sum_{n \\in N_k}w_n y_n,\n",
    "\\end{align}\n",
    "\n",
    "где $w_n$ - вес каждого соседа. \n",
    "\n",
    "При этом `KNNRegressor` может работать в 2 режимах:\n",
    " - $uniform$ - ближайшие соседи учитываются с одинаковыми весами.\n",
    " - $distance$ - вес ближайших соседей зависит от расстояния\n",
    " \n",
    "Сигнатуру методов при желании можно менять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Iterable, Optional\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors: int,\n",
    "                 metric: Union[str, Callable],\n",
    "                 mode: str = 'uniform',\n",
    "                test_block_size = 10):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            n_neighbors: number of neighbors\n",
    "            metric: metric to use for distance computation\n",
    "            mode: 'uniform' or 'distance'\n",
    "            'uniform' - all points in each neighborhood are weighted equally\n",
    "            'distance' - weight points by the inverse of their distance\n",
    "            test_block_size: block size for finding neighbors and predict (for saving memory)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.metric = metric\n",
    "        self.__nn = None\n",
    "        if self.metric != 'overlap':\n",
    "            self.__nn = NearestNeighbors(n_neighbors=n_neighbors, metric=self.metric, algorithm='brute',\n",
    "                                        n_jobs=1)\n",
    "        self.__mode = mode\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.test_block_size = test_block_size\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.neigh_idxs = None\n",
    "        self.distances = None\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            y: labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.y_train = y\n",
    "        if self.__nn is None:\n",
    "            self.X_train = X\n",
    "        else:\n",
    "            self.__nn.fit(X, y)\n",
    "        self.eps = 1e-5\n",
    "        \n",
    "        \n",
    "    def find_kneighbors(self, X, return_distance):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            * X - objects sample\n",
    "            * return_distance - bool variable\n",
    "\n",
    "        return values:\n",
    "            * If return_distance == True:\n",
    "                * tuple with two numpy array with size (X.shape[0], k), where:\n",
    "                  [i, j] elem of first array must be the distance between\n",
    "                  i-th object and his j-th nearest neighbour\n",
    "                  [i, j] elem of second array must be the index of j-th nearest neighbour to i-th object\n",
    "            * If return_distance == False:\n",
    "                * only second array\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if self.__nn is not None:\n",
    "            self.distances, \\\n",
    "                self.neigh_idxs = self.__nn.kneighbors(X, n_neighbors=self.n_neighbors)\n",
    "        else:\n",
    "            if self.metric == 'overlap':\n",
    "                self.distances = overlap(X, self.X_train)\n",
    "            if return_distance:\n",
    "                self.neigh_idxs = np.argsort(self.distances,\n",
    "                                         axis=1)[:, :self.n_neighbors] \n",
    "                self.distances = self.distances[np.arange(self.distances.shape[0])[:, None],\n",
    "                                                self.neigh_idxs]\n",
    "        if return_distance:\n",
    "            return self.distances, self.neigh_idxs\n",
    "        return self.neigh_idxs\n",
    "\n",
    "    def predict(self, X: np.array, n_neighbors: Optional[int] = None) -> np.array:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            n_neighbors: number of neighbors\n",
    "        \"\"\"\n",
    "        if n_neighbors is not None:\n",
    "            n_neighbors = np.minimum(self.n_neighbors, n_neighbors)\n",
    "        else:\n",
    "            n_neighbors = self.n_neighbors\n",
    "        if self.test_block_size > X.shape[0]:\n",
    "            self.test_block_size = X.shape[0]\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        split_size = X.shape[0] // self.test_block_size + \\\n",
    "                     int(X.shape[0] % self.test_block_size != 0)\n",
    "        curr_idx = 0\n",
    "        for i, split in enumerate(np.array_split(X, split_size)):\n",
    "            self.distances, self.neigh_idxs = self.find_kneighbors(split,\n",
    "                                                                   return_distance=True\n",
    "                                                                  )\n",
    "            for j, idx in enumerate(self.neigh_idxs):\n",
    "                if self.__mode == 'distance':\n",
    "                    weights = 1 / (self.distances[j] + self.eps)\n",
    "                    pred = np.sum(self.y_train.values[idx].reshape(-1) * weights) / np.sum(weights)\n",
    "                else:\n",
    "                    pred = np.sum(self.y_train.values[idx].reshape(-1)) / n_neighbors\n",
    "                preds[j + curr_idx] = pred\n",
    "            curr_idx += split.shape[0]\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def predict_without_testblock(self, X):\n",
    "        \"\"\"\n",
    "        Similar to predict, but without memory optimization\n",
    "        params:\n",
    "            * X - test objects\n",
    "\n",
    "        return values:\n",
    "            * preds - numpy array of predictions for test\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.distances, self.neigh_idxs = self.find_kneighbors(X,\n",
    "                                                               return_distance=True\n",
    "                                                              )\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for j, idx in enumerate(self.neigh_idxs):\n",
    "            if self.__mode == 'distance':\n",
    "                weights = 1 / (self.distances[j] + self.eps)\n",
    "                pred = np.sum(self.y_train.values[idx].reshape(-1) * weights) / np.sum(weights)\n",
    "            else:\n",
    "                pred = np.sum(self.y_train.values[idx].reshape(-1)) / self.n_neighbors\n",
    "            preds[j] = pred\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def predict_opt(self, X):\n",
    "        \"\"\"\n",
    "        Optimized prediction for classification (for fast calculating score for different k)\n",
    "        params:\n",
    "            * X - test objects\n",
    "\n",
    "        return values:\n",
    "            * preds - numpy array of predictions for test\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for j, idx in enumerate(self.neigh_idxs[:, :self.n_neighbors]):\n",
    "            if self.__mode == 'distance':\n",
    "                weights = 1 / (self.distances[j, :self.n_neighbors] + self.eps)\n",
    "                counts = np.bincount(self.y_train.values[idx].reshape(-1),  weights)\n",
    "            else:\n",
    "                counts = np.bincount(self.y_train.values[idx].reshape(-1))\n",
    "            preds[j] = np.argmax(counts)\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def predict_opt_regression(self, X):\n",
    "        \"\"\"\n",
    "        Optimized prediction for regression (for fast calculating score for different k)\n",
    "        params:\n",
    "            * X - test objects\n",
    "\n",
    "        return values:\n",
    "            * preds - numpy array of predictions for test\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for j, idx in enumerate(self.neigh_idxs[:, :self.n_neighbors]):\n",
    "            if self.__mode == 'distance':\n",
    "                weights = 1 / (self.distances[j, :self.n_neighbors] + self.eps)\n",
    "                pred = np.sum(self.y_train[idx] * weights) / np.sum(weights)\n",
    "            else:\n",
    "                pred = np.sum(self.y_train[idx]) / self.n_neighbors\n",
    "            preds[j] = pred\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию rmse для подсчета метрики RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_valid):\n",
    "    return (np.sum((y_valid - y_true) ** 2) / len(y_true)) ** (1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1 (1 балл)</b>\n",
    "Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на [третьем семинаре](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf). Не забудьте, что KNNRegressor должен уметь работать с этими функциями расстояния. Как вариант, можно реализовать метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyximport; pyximport.install() Попытки переписать метрики на Cython оказались безуспешными\n",
    "# import overlap_cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим 3 категориальных признака: 'neighbourhood_group', 'neighbourhood', 'room_type'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat.drop(['id', 'name', 'host_id', 'host_name', 'latitude', 'longitude',\n",
    "              'minimum_nights', 'number_of_reviews', 'last_review', \n",
    "               'reviews_per_month', 'calculated_host_listings_count', 'availability_365'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем статистику для всех данных для ускорения работы метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for column in data_cat.columns[:-1]:\n",
    "    all_classes_in_col = data_cat[column].unique()\n",
    "    le.fit(all_classes_in_col)\n",
    "    data_cat.loc[:, column] = le.transform(data_cat.loc[:, column]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(data_cat.drop(columns=['price']),\n",
    "                                                                    data_cat[['price']],\n",
    "                                                                    test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем предпосчет статистики для ускорения работы метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 ... 2 2 2]\n",
      "[2 3 3 ... 3 3 3]\n",
      "[109  87 190 ...  14 191  52]\n",
      "[109 128  95 ...  95  96  96]\n",
      "[2 1 2 ... 1 1 2]\n",
      "[2 1 2 ... 1 3 2]\n",
      "CPU times: user 3.3 s, sys: 353 ms, total: 3.65 s\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p2_sum_stat_dict = {}\n",
    "data_cat_np = data_cat.drop('price', axis=1).to_numpy(copy=True)\n",
    "X_train_cat_np = X_train_cat.to_numpy(copy=True)\n",
    "f_stat = np.zeros((data_cat.shape[0], X_train_cat_np.shape[1]))\n",
    "\n",
    "\n",
    "for i, columns in enumerate(zip(data_cat_np.T, X_train_cat_np.T)):\n",
    "    column_data, column_train = columns\n",
    "    print(column_train)\n",
    "    print(column_data)\n",
    "    is_equal = column_data[:, None] == column_train\n",
    "    f_stat[:, i] = np.sum(is_equal, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285ceffeba794c9c91530a0c27371e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48895), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f_stat_log_dict = {}\n",
    "for i, elem in enumerate(tqdm_notebook(data_cat_np)):\n",
    "    f_stat_log_dict[tuple(elem)] = np.log(f_stat[i, :] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cb8c5a13064e5f8a9ef027fc2498de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48895), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p2_sum_arr = np.zeros(X_train_cat.shape[1])\n",
    "p2_sum_stat = np.zeros((data_cat.shape[0], X_train_cat.shape[1]))\n",
    "for i, line in enumerate(tqdm_notebook(data_cat_np)):\n",
    "    for j, x_val in enumerate(line):\n",
    "        f_x = X_train_cat.iloc[:, j].value_counts()\n",
    "        p2 = f_x\n",
    "        p2 = p2 * (p2 - 1) / (X_train_cat.shape[0] * (X_train_cat.shape[0] - 1))\n",
    "        if x_val in f_x:\n",
    "            p2_sum_arr[j] = np.sum(p2 * (f_x.values <= f_x[x_val]))\n",
    "        else:\n",
    "            p2_sum_arr[j] = np.sum(p2 * (f_x.values <= 0))\n",
    "    p2_sum_stat[i, :] = p2_sum_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeb54f984e646dbbadeb4730c1574f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48895), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p2_sum_stat_dict = {}\n",
    "for i, elem in enumerate(tqdm_notebook(data_cat_np)):\n",
    "    p2_sum_stat_dict[tuple(elem)] = p2_sum_stat[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = data_cat.copy()\n",
    "df_z = data_cat.copy()\n",
    "df = data_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(x, z):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * x - DataFrame with size n * l\n",
    "        * z - DataFrame with size m * l\n",
    "    return values:\n",
    "        n * m matrix with pairwise distances\n",
    "    \"\"\"\n",
    "    x = x.to_numpy(copy=True)\n",
    "    z = z.to_numpy(copy=True)\n",
    "    is_equal = x[:, None] != z\n",
    "    return np.sum(is_equal, axis=2)\n",
    "\n",
    "def flattened_overlap(x, z):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * x - numpy array of size d\n",
    "        * z - numpy array of size d\n",
    "    return values:\n",
    "        flattened overlap distance between x and z\n",
    "    \"\"\"\n",
    "    result = np.sum(x != z) + np.sum((x == z) * p2_sum_stat_dict[tuple(x)])\n",
    "    return result\n",
    "\n",
    "\n",
    "def log_overlap(x, z):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * x - numpy array of size d\n",
    "        * z - numpy array of size d\n",
    "    return values:\n",
    "        log overlap distance between x and z\n",
    "    \"\"\"\n",
    "    result = np.sum((x != z) * f_stat_log_dict[tuple(x)] * f_stat_log_dict[tuple(z)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2 (1 балл)</b> Найдите все категориальные признаки в данных. Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Качество измеряйте с помощью RMSE.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем расстояния и индексы соседей заранее, чтобы быстрее делать предсказания для различных k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_distances = KNNRegressor(200, metric='overlap', mode='uniform', test_block_size=1000)\n",
    "knn_with_distances.fit(X_train_cat, y_train_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.03 s, sys: 652 ms, total: 8.69 s\n",
      "Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "overlap_distances, overlap_indx = knn_with_distances.find_kneighbors(X_test_cat,\n",
    "                                                                     return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_distances = KNNRegressor(200, metric=flattened_overlap, mode='uniform', test_block_size=1000)\n",
    "knn_with_distances.fit(X_train_cat, y_train_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 49min 5s, sys: 4min 25s, total: 2h 53min 31s\n",
      "Wall time: 2h 38min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "flattened_overlap_distances, flattened_overlap_indx = knn_with_distances.find_kneighbors(X_test_cat,\n",
    "                                                                                         return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_distances = KNNRegressor(200, metric=log_overlap, mode='uniform', test_block_size=1000)\n",
    "knn_with_distances.fit(X_train_cat, y_train_cat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 48min 7s, sys: 4min 10s, total: 2h 52min 18s\n",
      "Wall time: 2h 38min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_overlap_distances, log_overlap_indx = knn_with_distances.find_kneighbors(X_test_cat,\n",
    "                                                                             return_distance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Достаточно просто изменять два аттрибута KNNRegressor: $distances$ и $neigh\\_idxs$, так как методу $predict\\_opt\\_regression$ нужны только они для предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество соседей: 10, RMSE: 227.4506863689404\n"
     ]
    }
   ],
   "source": [
    "knn_with_distances.distances = overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in [10]:\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    print(f\"Количество соседей: {k}, RMSE: {rmse_curr}\")\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество соседей: 10, RMSE: 209.48714805630325\n"
     ]
    }
   ],
   "source": [
    "knn_with_distances.distances = flattened_overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = flattened_overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in [10]:\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    print(f\"Количество соседей: {k}, RMSE: {rmse_curr}\")\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество соседей: 10, RMSE: 239.034076340855\n"
     ]
    }
   ],
   "source": [
    "knn_with_distances.distances = log_overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = log_overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in [10]:\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    print(f\"Количество соседей: {k}, RMSE: {rmse_curr}\")\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из результатов эксперимента - наилучшее качество на 10 соседях показал алгоритм с метрикой расстояния \"**сглаженный индикатор совпадения**\" (**flattened_overlap**). Так как он учитывает частоту значения признака: чем выше частота, тем больше расстояние (если оба объекта имеют значение признака, которое часто встречается, то эта информация не так важна, так как вероятность такого совпадения высока)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.3 (1 балл) бонус</b> Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какого удалось достичь уровня качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично предыдущему пункту будем изменять аттрибуты $distances$ и $neigh\\_idxs$. Дополнительно изменяем в цикле $n\\_neighbors$, с помощью которого выбор нужного числа соседей из $distances$ и $neigh\\_idxs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 207.3201331722447, 'k': 192}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_with_distances.distances = overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in range(1, 200):\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 207.49810130642814, 'k': 125}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_with_distances.distances = flattened_overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = flattened_overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in range(1, 200):\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 207.1962663210132, 'k': 193}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_with_distances.distances = log_overlap_distances[:, :]\n",
    "knn_with_distances.neigh_idxs = log_overlap_indx[:, :]\n",
    "best_params = {'rmse': 1000, 'k': 0}\n",
    "for k in range(1, 200):\n",
    "    knn_with_distances.n_neighbors = k\n",
    "    preds = knn_with_distances.predict_opt_regression(X_test)\n",
    "    rmse_curr = rmse(y_test_cat.values.reshape(-1), preds)\n",
    "    if rmse_curr < best_params['rmse']:\n",
    "        best_params['rmse'] = rmse_curr\n",
    "        best_params['k'] = k\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для **overlap** оптимальное количество соседей получилось $= 192$\n",
    "\n",
    "Для **flattened overlap** $= 125$\n",
    "\n",
    "Для **log overlap** $= 193$\n",
    "\n",
    "Удалось достичь наилучшего значения $RMSE = \\textbf{207.2}$ (при использовании **log overlap**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.4 (2.5 балла)</b> Отойдем ненадолго от задачи регрессии и перейдём к задаче классификации: будем определять, являеться ли квартира дорогой $(target = 1)$ или дешевой $(target = 0)$. Будем считать дорогими квариры, цена которых выше среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat['target'] = (data_cat.price > data_cat.price.mean()).astype(int) ## чтобы снова удалять признаки из data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data.price > data.price.mean()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте счетчики, которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, для каждого категориального признака $f_j(x)$ необходимо сделать следующее:\n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "counts_j(c) = \\sum_{i=1}^l [f_j(x_i) = c]\n",
    "\\end{align}\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "successes_j(c) = \\sum_{i=1}^l[f_j(x_i) = c][y_i = +1].\n",
    "\\end{align}\n",
    "3. Сглаженное отношение двух предыдущих величин:\n",
    "\\begin{align}\n",
    "p_j(c) = \\frac{successes_j(c) + a}{counts_j(c) + b},\n",
    "\\end{align}\n",
    "\n",
    "где $a$ и $b$ - априорные счетчики (например, a = 1, b = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(x, x_tr):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x - pandas series (one categorical feature), which we want to fill with counter\n",
    "        x_tr - pandas series (one categorical feautre), BY which we want to fill x\n",
    "    return values:\n",
    "        numpy array with counts\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.to_numpy()\n",
    "    x_tr = x_tr.to_numpy()\n",
    "    return np.sum(x[:, None] == x_tr, axis=1)\n",
    "\n",
    "\n",
    "def successes(x, x_tr, y):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x - pandas series (one categorical feature), which we want to fill with successes\n",
    "        x_tr - pandas series (one categorical feautre), BY which we want to fill x\n",
    "    return values:\n",
    "        numpy array with successes\n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.to_numpy()\n",
    "    x_tr = x_tr.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    result = np.sum((x[:, None] == x_tr) * (y == 1), axis=1)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def flattened_c_s(x, x_tr, y, a=1, b=2):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x - pandas series (one categorical feature), which we want to fill with successes\n",
    "        x_tr - pandas series (one categorical feautre), BY which we want to fill x\n",
    "    return values:\n",
    "        numpy array with flattened successes and counts\n",
    "    \"\"\"\n",
    "    \n",
    "    return (successes(x, x_tr, y) + a) / (counts(x, x_tr) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая заполняет данный DataFrame по значениям X_train с целевой перменной y (от X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counters(df_cat, X_train, y):\n",
    "    df_copy = df_cat.copy()\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column + '_counts'] = counts(df_copy[column], X_train[column])\n",
    "        df_copy[column + '_successes'] = successes(df_copy[column], X_train[column], y)\n",
    "        df_copy[column + '_flattened_c_s'] = flattened_c_s(df_copy[column], X_train[column], y)\n",
    "        df_copy.drop(column, axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(data_cat.drop(columns=['price', 'target']),\n",
    "                                                                                  data_cat[['target']],\n",
    "                                                                                  test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем с помощью $LabelEncoder$ категориальные признаки, добавив 1 к каждому столбцу признаков, так как $LabelEncoder$ кодирует с 0, то при подсчете статистик могли бы возникнуть проблемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for column in X_train_cat.columns:\n",
    "    all_classes_in_col = np.hstack([X_train_cat[column].unique(), X_test_cat[column].unique()])\n",
    "    le.fit(all_classes_in_col)\n",
    "    X_train_cat.loc[:, column] = le.transform(X_train_cat.loc[:, column]) + 1\n",
    "    X_test_cat.loc[:, column] = le.transform(X_test_cat.loc[:, column]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Достаточно взять $n = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализуем kfold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(indices, n_folds=3):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * indices - np.array of indices\n",
    "        * n_folds - folds amount\n",
    "    return values:\n",
    "        * list with size n_folds, where every element is tuple of two 1D numpy array:\n",
    "            * first array contains indices of train samples\n",
    "            * second array contains indices of validation samples\n",
    "    \"\"\"\n",
    "\n",
    "#     np.random.shuffle(indices)\n",
    "    n = len(indices)\n",
    "    size_of_one_fold = int(n / n_folds) + (n < n_folds)\n",
    "    size_with_folds = size_of_one_fold * n_folds\n",
    "    out_elements_amount = len(indices) - size_with_folds\n",
    "    train_test_idx_list = []\n",
    "    for i in range(n_folds):\n",
    "        test_idx = indices[i * size_of_one_fold:(i + 1) * size_of_one_fold]\n",
    "        if out_elements_amount > 0:\n",
    "            test_idx = np.append(test_idx, n - out_elements_amount)\n",
    "            out_elements_amount -= 1\n",
    "        train_idx = np.array(list((set(indices) - set(test_idx))))\n",
    "        train_test_idx_list.append((train_idx, test_idx))\n",
    "    return train_test_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем подсчет статистик по фолдам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_with_folds(x, n_folds=3):\n",
    "    \"\"\"\n",
    "    x - one categorical column with type - pandas series\n",
    "    n_folds - amount of folds\n",
    "    \"\"\"\n",
    "    \n",
    "    result = x.copy()\n",
    "    result.iloc[:] = 0\n",
    "    for help_indx, main_indx in kfold(x.index, n_folds):\n",
    "        unique_elems = np.unique(x[help_indx])\n",
    "        counts_per_fold = {x : 0 for x in unique_elems}\n",
    "        for unique_elem in unique_elems:\n",
    "            counts_per_fold[unique_elem] = np.sum((x[help_indx] == unique_elem))\n",
    "            result[np.array((x[main_indx] == unique_elem)[x[main_indx] == unique_elem].index)] = counts_per_fold[unique_elem]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successes_with_folds(x, y, n_folds=3):\n",
    "    \"\"\"\n",
    "    x - one categorical column with type - pandas series\n",
    "    y - target feature from df\n",
    "    n_folds - amount of folds\n",
    "    \"\"\"\n",
    "    \n",
    "    result = x.copy()\n",
    "    result.iloc[:] = 0\n",
    "    for help_indx, main_indx in kfold(x.index, n_folds):\n",
    "        unique_elems = np.unique(x[help_indx])\n",
    "        successes_per_fold = {x : 0 for x in unique_elems}\n",
    "        for unique_elem in unique_elems:\n",
    "            successes_per_fold[unique_elem] = np.sum((x[help_indx] == unique_elem) & (y[help_indx] == 1))\n",
    "            result[np.array((x[main_indx] == unique_elem)[x[main_indx] == unique_elem].index).reshape(-1)] = successes_per_fold[unique_elem]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattened_c_s_with_folds(x, y, n_folds=3, a=1, b=2):\n",
    "    \"\"\"\n",
    "    x - one categorical column with type - pandas series\n",
    "    y - target feature from df\n",
    "    n_folds - amount of folds\n",
    "    \"\"\"\n",
    "    \n",
    "    result = x.copy()\n",
    "    result.iloc[:] = 0\n",
    "    counts = result.copy()\n",
    "    successes = result.copy()\n",
    "    for help_indx, main_indx in kfold(x.index, n_folds):\n",
    "        unique_elems = np.unique(x[help_indx])\n",
    "        successes_per_fold = {x : 0 for x in unique_elems}\n",
    "        counts_per_fold = {x : 0 for x in unique_elems}\n",
    "        for unique_elem in unique_elems:\n",
    "            counts_per_fold[unique_elem] = np.sum((x[help_indx] == unique_elem))\n",
    "            counts[np.array((x[main_indx] == unique_elem)[x[main_indx] == unique_elem].index)] = counts_per_fold[unique_elem]\n",
    "            successes_per_fold[unique_elem] = np.sum((x[help_indx] == unique_elem) & (y[help_indx] == 1))\n",
    "            successes[np.array((x[main_indx] == unique_elem)[x[main_indx] == unique_elem].index)] = successes_per_fold[unique_elem]\n",
    "    result = (successes + a) / (counts + b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение DataFrame статистиками по фолдам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counters_with_folds(df_cat, y):\n",
    "    df_copy = df_cat.copy()\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column + '_counts'] = counts_with_folds(df_copy.loc[:, column])\n",
    "        df_copy[column + '_successes'] = successes_with_folds(df_copy.loc[:, column], y)\n",
    "        df_copy[column + '_flattened_c_s'] = flattened_c_s_with_folds(df_copy.loc[:, column], y)\n",
    "        df_copy.drop(column, axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Без фолдинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_without_folding = counters(X_train_cat, X_train_cat, y_train_cat['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_cat_without_folding = counters(X_test_cat, X_train_cat, y_train_cat['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = np.zeros((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, weights: uniform, roc_auc: 0.7118803376103604\n",
      "n_neighbors: 2, weights: uniform, roc_auc: 0.7310142496654174\n",
      "n_neighbors: 3, weights: uniform, roc_auc: 0.7292143529965854\n",
      "n_neighbors: 4, weights: uniform, roc_auc: 0.7384337762122508\n",
      "n_neighbors: 5, weights: uniform, roc_auc: 0.7619850417267447\n",
      "n_neighbors: 6, weights: uniform, roc_auc: 0.7647751806341901\n",
      "n_neighbors: 7, weights: uniform, roc_auc: 0.7593130472459989\n",
      "n_neighbors: 8, weights: uniform, roc_auc: 0.76366596882462\n",
      "n_neighbors: 9, weights: uniform, roc_auc: 0.7624760903306405\n",
      "n_neighbors: 10, weights: uniform, roc_auc: 0.7607568183714146\n",
      "n_neighbors: 11, weights: uniform, roc_auc: 0.762628178272686\n",
      "n_neighbors: 12, weights: uniform, roc_auc: 0.7600281879085735\n",
      "n_neighbors: 13, weights: uniform, roc_auc: 0.7657084147395725\n",
      "n_neighbors: 14, weights: uniform, roc_auc: 0.767865040151628\n"
     ]
    }
   ],
   "source": [
    "weights_list = ['uniform']\n",
    "k_max = 15\n",
    "k_list = np.arange(k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for weights in weights_list:\n",
    "    knn_regressor = KNNRegressor(k_max, metric='euclidean', mode=weights, test_block_size=10000)\n",
    "    knn_regressor.fit(X_train_cat_without_folding, y_train_cat['target'])\n",
    "    knn_regressor.find_kneighbors(X_test_cat_without_folding, return_distance=True)\n",
    "    for k in k_list[1:]:\n",
    "        knn_regressor.n_neighbors = k\n",
    "        pred = knn_regressor.predict_opt(X_test_cat_without_folding)\n",
    "        roc_auc = roc_auc_score(pred.reshape(-1), y_test_cat['target'].values.reshape(-1))\n",
    "        print(f'n_neighbors: {k}, weights: {weights}, roc_auc: {roc_auc}')\n",
    "        if best_score_param['score'] is None:\n",
    "            best_score_param['score'] = roc_auc\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)            \n",
    "        elif abs(best_score_param['score'] - 0.5) < abs(roc_auc - 0.5):\n",
    "            best_score_param['score'] = roc_auc\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k) \n",
    "        logs = np.append(logs, \n",
    "                             np.array(['Без фолдинга',\n",
    "                                        k,\n",
    "                                        weights,\n",
    "                                        roc_auc])[None, :],\n",
    "                                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.767865040151628, 'param': 'uniform_14'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## С фолдингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_with_folding = counters_with_folds(X_train_cat, y_train_cat['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights_list = ['uniform']\n",
    "k_max = 15\n",
    "k_list = np.arange(k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for weights in weights_list:\n",
    "    knn_regressor = KNNRegressor(k_max, metric='euclidean', mode=weights, test_block_size=10000)\n",
    "    knn_regressor.fit(X_train_cat_with_folding, y_train_cat['target'])\n",
    "    knn_regressor.find_kneighbors(X_test_cat_without_folding, return_distance=True)\n",
    "    for k in k_list[1:]:\n",
    "        knn_regressor.n_neighbors = k\n",
    "        pred = knn_regressor.predict_opt(X_test_cat_without_folding)\n",
    "        roc_auc = roc_auc_score(pred, y_test_cat['target'].values)\n",
    "        if best_score_param['score'] is None:\n",
    "            best_score_param['score'] = roc_auc\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)            \n",
    "        elif abs(best_score_param['score'] - 0.5) < abs(roc_auc - 0.5):\n",
    "            best_score_param['score'] = roc_auc\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)\n",
    "        logs = np.append(logs, \n",
    "                             np.array(['С фолдингом',\n",
    "                                        k,\n",
    "                                        weights,\n",
    "                                        roc_auc])[None, :],\n",
    "                                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.7527181701840073, 'param': 'uniform_5'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = pd.DataFrame(logs, columns=['Тип заполнения',\n",
    "                                        'Количество соседей',\n",
    "                                        'Веса',\n",
    "                                        'ROC_AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тип заполнения</th>\n",
       "      <th>Количество соседей</th>\n",
       "      <th>Веса</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Без фолдинга</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7118803376103604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Без фолдинга</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7310142496654174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Без фолдинга</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7292143529965854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Без фолдинга</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7384337762122508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Без фолдинга</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7619850417267447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Тип заполнения Количество соседей     Веса             ROC_AUC\n",
       "1   Без фолдинга                  1  uniform  0.7118803376103604\n",
       "2   Без фолдинга                  2  uniform  0.7310142496654174\n",
       "3   Без фолдинга                  3  uniform  0.7292143529965854\n",
       "4   Без фолдинга                  4  uniform  0.7384337762122508\n",
       "5   Без фолдинга                  5  uniform  0.7619850417267447"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_data = logs_data.drop([0], axis=0) # так как первая строка - нули\n",
    "logs_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data['ROC_AUC'] = logs_data['ROC_AUC'].astype(float)\n",
    "logs_data['Количество соседей'] = logs_data['Количество соседей'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Количество соседей',\n",
    "            y='ROC_AUC',\n",
    "            hue='Тип заполнения',\n",
    "            data=logs_data)\n",
    "plt.ylim(0.6, 0.9)\n",
    "plt.title('Зависимость метрики качества ROC_AUC от типа заполнения.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графика - заполнение признаков без фолдинга дает результат хуже, чем с фолдингом. Это можно объяснить только тем, что в признаке 'neighbourhood_group' у тренировочной выборки есть значения, которых нет в тестовой выборке. При заполнении без фолдов в тесте оказывается не так много \"неизвестных\" значений, а при использовании фолдов их количество увеличивается. Возможно, поможет увеличение количества фолдов (тогда \"неизвестных\" значений намного меньше). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.5 (1 балл)</b> Вернемся к задаче регрессии. Утверждается, что для задачи регрессии можно также сделать преобразование категориальных признаков в действительные числа. Для этого достаточно для каждого значения признака $f_j$ вычислить:\n",
    "\\begin{align}\n",
    "p_j(c) = g(T_i | f_j(x_i) = c),\n",
    "\\end{align}\n",
    "\n",
    "где $T_i$ - значения целевой переменной объекта $x_i$. Функция $g$ - среднее (mean) или среднеквадратичное отклонение (std).\n",
    "\n",
    "Закодируйте категориальные признаки обоими способами и найдите значение RMSE. Используйте евклидову метрику для поиска ближайших соседей. Для какой функции $g$ значение RMSE лучше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_j(x, y, g_func=np.mean):\n",
    "    x = x.values.reshape(-1)\n",
    "    y = y.values.reshape(-1)\n",
    "    return g_func((x[:, None] == x) * y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_j_for_test(x, x_tr, y, g_func=np.mean):\n",
    "    x = x.values.reshape(-1)\n",
    "    y = y.values\n",
    "    x_tr = x_tr.values.reshape(-1)\n",
    "    return g_func((x[:, None] == x_tr) * y, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_j_for_df(df_train_cat, df_test_cat, y, g_func=np.mean):\n",
    "    df_train_copy = df_train_cat.copy()\n",
    "    df_test_copy = df_test_cat.copy()\n",
    "    for column in df_train_copy.columns:\n",
    "        df_train_copy[column + '_p_j'] = calculate_p_j(df_train_copy[column], y, g_func=g_func)\n",
    "        df_test_copy[column + '_p_j'] = calculate_p_j_for_test(df_test_copy[column],\n",
    "                                                               df_train_copy[column],\n",
    "                                                               y,\n",
    "                                                               g_func=g_func\n",
    "                                                              )\n",
    "        df_train_copy.drop(column, axis=1, inplace=True)\n",
    "        df_test_copy.drop(column, axis=1, inplace=True)\n",
    "    return df_train_copy, df_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(data_cat.drop(columns=['price', 'target']),\n",
    "                                                                                  data_cat[['price']],\n",
    "                                                                                  test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посчитаем все $p_j$ с функцией $mean$ для тренировочной и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_cat_p_j, X_test_cat_p_j = calculate_p_j_for_df(X_train_cat, X_test_cat, y_train_cat['price'], np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем массив для логирования результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = np.zeros((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, weights: uniform, rmse: 256.9955092974038\n",
      "n_neighbors: 2, weights: uniform, rmse: 225.42715336866934\n",
      "n_neighbors: 3, weights: uniform, rmse: 218.1166870140802\n",
      "n_neighbors: 4, weights: uniform, rmse: 219.5907395782312\n",
      "n_neighbors: 5, weights: uniform, rmse: 217.1871295290689\n",
      "n_neighbors: 6, weights: uniform, rmse: 215.14252405305274\n",
      "n_neighbors: 7, weights: uniform, rmse: 223.20601888804407\n",
      "n_neighbors: 8, weights: uniform, rmse: 219.07736915691726\n",
      "n_neighbors: 9, weights: uniform, rmse: 215.8916293021102\n",
      "n_neighbors: 10, weights: uniform, rmse: 214.05440744727446\n",
      "n_neighbors: 11, weights: uniform, rmse: 213.163973702008\n",
      "n_neighbors: 12, weights: uniform, rmse: 213.1387156891674\n",
      "n_neighbors: 13, weights: uniform, rmse: 212.006511881363\n",
      "n_neighbors: 14, weights: uniform, rmse: 211.0541005183805\n"
     ]
    }
   ],
   "source": [
    "knn_regressor = KNNRegressor(15, metric='euclidean')\n",
    "weights_list = ['uniform']\n",
    "k_max = 15\n",
    "k_list = np.arange(k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for weights in weights_list:\n",
    "    knn_regressor = KNNRegressor(k_max, metric='euclidean', mode=weights, test_block_size=10000)\n",
    "    knn_regressor.fit(X_train_cat_p_j, y_train_cat)\n",
    "    knn_regressor.find_kneighbors(X_test_cat_p_j, return_distance=True)\n",
    "    for k in k_list[1:]:\n",
    "        knn_regressor.n_neighbors = k\n",
    "        pred = knn_regressor.predict(X_test_cat_p_j)\n",
    "        rmse_curr = rmse(pred, y_test_cat.values.reshape(-1))\n",
    "        print(f'n_neighbors: {k}, weights: {weights}, rmse: {rmse_curr}')\n",
    "        if best_score_param['score'] is None:\n",
    "            best_score_param['score'] = rmse_curr\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)            \n",
    "        elif best_score_param['score'] > rmse_curr:\n",
    "            best_score_param['score'] = rmse_curr\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)\n",
    "        logs = np.append(logs, \n",
    "                             np.array(['mean',\n",
    "                                        k,\n",
    "                                        weights,\n",
    "                                        rmse_curr])[None, :],\n",
    "                                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 211.0541005183805, 'param': 'uniform_14'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " лучший результат достигается при $k=14$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посчитаем все $p_j$ с функцией $std$ для тренировочной и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_cat_p_j, X_test_cat_p_j = calculate_p_j_for_df(X_train_cat, X_test_cat, y_train_cat['price'],\n",
    "                                                       np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, weights: uniform, rmse: 257.06013753417153\n",
      "n_neighbors: 2, weights: uniform, rmse: 225.45899483263952\n",
      "n_neighbors: 3, weights: uniform, rmse: 218.1486452763526\n",
      "n_neighbors: 4, weights: uniform, rmse: 242.98248169914015\n",
      "n_neighbors: 5, weights: uniform, rmse: 231.78584953277328\n",
      "n_neighbors: 6, weights: uniform, rmse: 224.5639471709267\n",
      "n_neighbors: 7, weights: uniform, rmse: 223.55743097103192\n",
      "n_neighbors: 8, weights: uniform, rmse: 219.23957591637205\n",
      "n_neighbors: 9, weights: uniform, rmse: 223.016634459386\n",
      "n_neighbors: 10, weights: uniform, rmse: 219.19152581574295\n",
      "n_neighbors: 11, weights: uniform, rmse: 216.856813040564\n",
      "n_neighbors: 12, weights: uniform, rmse: 215.19329847854564\n",
      "n_neighbors: 13, weights: uniform, rmse: 213.61807902111028\n",
      "n_neighbors: 14, weights: uniform, rmse: 212.82925240340748\n"
     ]
    }
   ],
   "source": [
    "knn_regressor = KNNRegressor(15, metric='euclidean')\n",
    "weights_list = ['uniform']\n",
    "k_max = 15\n",
    "k_list = np.arange(k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for weights in weights_list:\n",
    "    knn_regressor = KNNRegressor(k_max, metric='euclidean', mode=weights, test_block_size=10000)\n",
    "    knn_regressor.fit(X_train_cat_p_j, y_train_cat)\n",
    "    knn_regressor.find_kneighbors(X_test_cat_p_j, return_distance=True)\n",
    "    for k in k_list[1:]:\n",
    "        knn_regressor.n_neighbors = k\n",
    "        pred = knn_regressor.predict(X_test_cat_p_j)\n",
    "        rmse_curr = rmse(pred, y_test_cat.values.reshape(-1))\n",
    "        print(f'n_neighbors: {k}, weights: {weights}, rmse: {rmse_curr}')\n",
    "        if best_score_param['score'] is None:\n",
    "            best_score_param['score'] = rmse_curr\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)            \n",
    "        elif best_score_param['score'] > rmse_curr:\n",
    "            best_score_param['score'] = rmse_curr\n",
    "            best_score_param['param'] = str(weights) + '_' + str(k)\n",
    "        logs = np.append(logs, \n",
    "                         np.array(['std',\n",
    "                                    k,\n",
    "                                    weights,\n",
    "                                    rmse_curr])[None, :],\n",
    "                                    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 212.82925240340748, 'param': 'uniform_14'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат при $k=14$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим график зависимости метрики качества RMSE от типа заполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = pd.DataFrame(logs, columns=['Функция',\n",
    "                                        'Количество соседей',\n",
    "                                        'Веса',\n",
    "                                        'RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Функция</th>\n",
       "      <th>Количество соседей</th>\n",
       "      <th>Веса</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>256.9955092974038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>225.42715336866934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>218.1166870140802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>219.5907395782312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>217.1871295290689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Функция Количество соседей     Веса                RMSE\n",
       "1    mean                  1  uniform   256.9955092974038\n",
       "2    mean                  2  uniform  225.42715336866934\n",
       "3    mean                  3  uniform   218.1166870140802\n",
       "4    mean                  4  uniform   219.5907395782312\n",
       "5    mean                  5  uniform   217.1871295290689"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_data = logs_data.drop([0], axis=0) # так как первая строка - нули\n",
    "logs_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data['RMSE'] = logs_data['RMSE'].astype(float)\n",
    "logs_data['Количество соседей'] = logs_data['Количество соседей'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Количество соседей',\n",
    "            y='RMSE',\n",
    "            hue='Функция',\n",
    "            data=logs_data)\n",
    "plt.semilogy()\n",
    "plt.title('Зависимость метрики качества RMSE от типа заполнения.') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов функция $g = mean$ дает качество лучше, чем std. Предполагаю, что это связано с тем, что функция $std$ очень чувствительна к уникальным признакам. Допустим, что в признаке $p_j$ есть значение $c$, которое принимает всего один объект, тогда при преобразовании \n",
    "$p_j(c) = std(T_i | f_j(x_i) = c)$ значение признака изменится на 0, что является не очень информативным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Текстовые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.1 (2 балла)</b> Перейдем от категориальным признаков к текстовым. Рассмотрим 2 способа преобразования текста в действительные числа:\n",
    "- Мешок слов (Bag of Words)\n",
    "- TF-IDF\n",
    "\n",
    "[Здесь](https://scikit-learn.org/stable/modules/feature_extraction.html) вы можете прочитать про их применение в Питоне.\n",
    "\n",
    "Сравните оба способа на задаче регресси. Какую лучше метрику использовать: евклидову или косинусную меру? Постройте графики зависимости качества решения задачи от способа преобразования, метрики и количества соседей. Мера качества - RMSE.\n",
    "\n",
    "Объясните полученные результаты.\n",
    "\n",
    "Перед преобразованием не забудьте уменьшить размер словаря. Например, это можно сделать за счет приведения всех слов к одному регистру и удаления [стопслов](https://en.wikipedia.org/wiki/Stop_words) (артиклей, предлогов, союзов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим множество стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/paniquex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удалим пунктуацию и приведем все к одному регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data.copy()\n",
    "data_text['name'] = data_text['name'] + data_text['host_name']\n",
    "data_text['name'] = data_text['name'].str.lower()\n",
    "data_text['name'] = data_text['name'].str.split()\n",
    "data_text['name'] = data_text['name'].apply(lambda x: [elem for elem in x if elem not in list(string.punctuation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удалим стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['name'] = data_text['name'].apply(lambda x: [elem for elem in x if elem not in stopwords_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['name'] = data_text['name'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_text_features_bag = vectorizer.fit_transform(data_text['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_with_text, X_test_with_text, y_train_with_text, y_test_with_text = train_test_split(data_with_text_features_bag,\n",
    "                                                                                    data[['price']].values,\n",
    "                                                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = np.zeros((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_list = ['euclidean', 'cosine']\n",
    "weights_list = ['uniform', 'distance']\n",
    "k_max = 21\n",
    "k_list = np.arange(2, k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for metrics in metrics_list:\n",
    "    for weights in weights_list:\n",
    "        knn_regressor = KNNRegressor(k_max, metric=metrics, mode=weights, test_block_size=10000)\n",
    "        knn_regressor.fit(X_train_with_text, y_train_with_text.reshape(-1))\n",
    "        knn_regressor.find_kneighbors(X_test_with_text, return_distance=True)\n",
    "        for k in k_list[1:]:\n",
    "            knn_regressor.n_neighbors = k\n",
    "            pred = knn_regressor.predict_opt_regression(X_test_with_text)\n",
    "            rmse_score = rmse(pred, y_test_with_text.reshape(-1))\n",
    "            if best_score_param['score'] is None:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)           \n",
    "            elif best_score_param['score'] > rmse_score:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)\n",
    "            logs = np.append(logs, \n",
    "                             np.array(['BOW',\n",
    "                                        k,\n",
    "                                        weights,\n",
    "                                        metrics,\n",
    "                                        rmse_score])[None, :],\n",
    "                                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 205.92985072106913, 'param': 'distance_19_cosine'}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'score': 205.92741917266707, 'param': 'distance_19_cosine'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfid = TfidfVectorizer()\n",
    "data_with_text_features_tfidf = vectorizer_tfid.fit_transform(data_text['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_text, X_test_with_text, y_train_with_text, y_test_with_text = train_test_split(data_with_text_features_tfidf,\n",
    "                                                                                    data[['price']].values,\n",
    "                                                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_list = ['euclidean', 'cosine']\n",
    "weights_list = ['uniform', 'distance']\n",
    "k_max = 21\n",
    "k_list = np.arange(2, k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for metrics in metrics_list:\n",
    "    for weights in weights_list:\n",
    "        knn_regressor = KNNRegressor(k_max, metric=metrics, mode=weights, test_block_size=10000)\n",
    "        knn_regressor.fit(X_train_with_text, y_train_with_text.reshape(-1))\n",
    "        knn_regressor.find_kneighbors(X_test_with_text, return_distance=True)\n",
    "        for k in k_list[1:]:\n",
    "            knn_regressor.n_neighbors = k\n",
    "            pred = knn_regressor.predict_opt_regression(X_test_with_text)\n",
    "            rmse_score = rmse(pred, y_test_with_text.reshape(-1))\n",
    "#             print(f'n_neighbors: {k}, weights: {weights}, metric: {metrics}, rmse: {rmse_score}')\n",
    "            if best_score_param['score'] is None:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)            \n",
    "            elif best_score_param['score'] > rmse_score:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)\n",
    "            logs = np.append(logs, \n",
    "                             np.array(['TF-IDF',\n",
    "                                        k,\n",
    "                                        weights,\n",
    "                                        metrics,\n",
    "                                        rmse_score])[None, :],\n",
    "                                        axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 205.4247224752524, 'param': 'distance_20_cosine'}"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'score': 202.4183357193138, 'param': 'distance_16_cosine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data = pd.DataFrame(logs, columns=['preproc_type',\n",
    "                                        'n_neighbours',\n",
    "                                        'weights',\n",
    "                                        'metric',\n",
    "                                        'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc_type</th>\n",
       "      <th>n_neighbours</th>\n",
       "      <th>weights</th>\n",
       "      <th>metric</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOW</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>233.19957505097526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOW</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>226.5929988833603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOW</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>224.21548570879605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOW</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>220.07965060190054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOW</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>218.58022981740373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preproc_type n_neighbours  weights     metric                rmse\n",
       "1          BOW            3  uniform  euclidean  233.19957505097526\n",
       "2          BOW            4  uniform  euclidean   226.5929988833603\n",
       "3          BOW            5  uniform  euclidean  224.21548570879605\n",
       "4          BOW            6  uniform  euclidean  220.07965060190054\n",
       "5          BOW            7  uniform  euclidean  218.58022981740373"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_data = logs_data.drop([0], axis=0) # так как первая строка - нули\n",
    "logs_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим графики зависимости RMSE от способа преобразования, метрики и количества соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data.columns = ['Тип преобразования', 'Количество соседей', 'Веса', 'Метрика расстояния', 'RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_data['Количество соседей'] = logs_data['Количество соседей'].astype(int)\n",
    "logs_data['RMSE'] = logs_data['RMSE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_selection = (logs_data['Метрика расстояния'] == 'cosine') & (logs_data['Веса'] == 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Покажем зависимость RMSE от способа преобразования:\n",
    "В качества метрики расстояния взята косинусная мера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEWCAYAAAAXa4wFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdeZgU1dn38e/PAWV1VBaVxYDL4wMBGUARQ1hUYnDFJG48REVFQyIucUtUEpdo4hYXXo1GFI0RRY0CGlExKiLRCIKDQMCIBGUEA2IcUEG2+/3jnIam6Z7unmHomeH+XNdcU1116pxT3dV11zlVXUdmhnPOOedgp0JXwDnnnKspPCg655xzkQdF55xzLvKg6JxzzkUeFJ1zzrnIg6JzztVhCuoVuh61hQdF55yrYyQdLulFSR8DK4GTCl2n2qJWB0VJu0maJOk/ksolLZL0e0kNC10352oqSQ9LWivpS0mfS3pZ0v8mLR8iySTdnrLeiXH+w0nzzpE0X9Kq+D18XlLTNOUk/mZttw3dQUn6LvAEcDfQ3syamtnYAler1qjVQRFYC1wPtDGzYuAQoCswoqC1cq7mu8XMmgCtgU+AB1OWfwicmtLtdgbwr8QLSX2B3wKDzKwp0AF4Ml05SX9dtvWGuK3cAFxgZn81sw2FrkxtU6uDopl9bWZTzWxdYhawEfgMQNLukv4qabmk/8bpNon1JU2WtCaewS6TdGPSsocl3ZD0emI8S64XX+8h6SFJS2Le4+P8fpLKktY7Ja43NL5OnIX/PCnNMXFecnnnSloQz+SfldQqadm349n95/Hs/CpJhyWdja9LOUPfJ5Y7NZf3NY86HiepVNIXkt6UdFCcf3dS2Sbpqzj9QtL7/jtJ02ILf4KkPeKydinvc4/kctO8v7dIel1Sg/h6kaT+cbpJfH/Sbneasn4maa6kZvH1WZLmxVbQQkk/SVr3WkmPVvC6Z3xPvpA0S1K/pGWZ9p0v4vu0RtKGpPdwcFJdE/PmpOR5l6TFklZKmiGpdy6ftZmtJgSykpRFnwKzge8n6gx8B3g2Kc0hwFtm9m7M63Mz+5OZrcql7FSZ9nlJz8Vt/irlPbgvTR4Vps22f6Tsr1/G79HDScufkvRp3G+nSPp2BduTfHz5UtJqSYuSli+SdKWkf8b94KHEfhyXp/1+xWUdYv5fxH32hKSiewBHxXoukXSnpF3iev0klSkcMz6LdRiclO+xkt6N+9FiSdcmLdtP0vva3CuQfCwolvSIwrH2I0kjJO0Ulw1J2p9XSnpVUuu4LJdj9NCk1/3TvIcVfZ4nJtU5cTxql+kzg1oeFBMkjZH0JbAcWG5md8RFOwEPAd8C9gFWE7oUkg2PZ8zfBS6V1ClN/v2Ag1Jm/xloBHwbaAnckbIcSfWB3wBLUxYtAM5Mej0UmJe03hHA74BTgL2Bj4CxcVlT4G/Ai0ArYH/gFTN7K3E2DoxhyzP0j1PrloNsdewGjAZ+AjQD/gg8K2kXMxueVBeALvH10Un5nQGcHbdhPTAyQz1uIbRktiLpF0B/4HgzW5MmyeXAujTz0+V1GnAZ8H0zWxFnLwOOA3YFzgLuiNsN4eQr7fcnfuGfJ5yx7xHzfVpSi5gk7b5jZrvF92wYIdgkPr8xSdnvBjQlBLLbkuZPJwS2PYDHgKeSD7AVbHdjYBDh8071COFzAjgNmAB8k7T8beD7kq6T1Ctx4K2MivZ5Mzs+vi+JALRbfF+GpeaTT1oy7x9dkvbfW1KWvQAcQPjcZhK+axVJ/i4cn2b5YMKJx37A/xB7uSr6fsXjynPApFiPC4Axkg6MeTaM238Q0IUQJJN7z/YCmhN6Cc4E7k9a9yvCZ74bcCzwU0knxmXLgGMI34eewFBJneOy/wcUA/sCfWMeZyWV+VZ8D1oS9qHECXcux+hcpfs87wN+F3sydsslkzoRFM1sMOFA0QHoIOmSOH+FmT0dW5SrgBsJH1g69YANQHnyTEkifDF+nTRvb+BoYJiZ/dfM1pnZ62ny/AnhwPGvlPn/ARYptO5aEnaIaUnLBwOjzWymmX0DXAkcFs9wjgM+NbPfm9kaM1tlZm9X+AZVTrY6ngv80czeNrMNZvYnws7eM8f8/2xmc8zsK+BXwCmSipITSDqOsI/+LXXlePZ4GTDAzFamWb4ncA5we+qyNAYQug+PNrNNrVAze97MPrTgdcJBKNEC+xg4RFK6L9qPgYlmNtHMNprZy8A7wDF57DsVEVAEJII3ZvZo3N/Xm9nvgV2AAzNlAFwm6QtgFeGE8PQ0acYB/SQVEw5yjyQvNLM3gB8C3QgnASsk3Z7yOV4WWzOJvz9lqE9F+/w2l+f+sYmZjY7fuW+Aa4Eu8f2prLvNbLGZfU44Pg2K8yv6fvUEmgA3mdlaM3sV+GvSugDXm9kyM1sOXMfWn++vzOybuO89TzgZwcwmm9nsuN++BzxOPGbG7f7QwgOzRThGLImf96nAlTHNIuD3acqE8H3eibjv5nmMzijL51kvHsdzUieCIkA8cM0HbiKe3UpqJOmPsTm/EpgC7JbypR0ZDw5zCV/KxSlZn0L4AF9NmtcW+NzM/pupPrFFdwXhgJ/OA4TW1xBSDjaE1tNHSdv2ZaxD61j2h5nKzaJnPDB9rtAdc3CW9BXV8VuElvWmA16sWytyk/w+fwTUJ5y9JuxEaDlckWbdFoT39Wu27vZLuJZw9vp5DnV5AFhEypdR0tGS/hHfry8IZ8mJOo4FZgH/jst+mbTqt4CTU96b7xJaQFn3nSw+A74ELgZuTqrrpQpdveWxvGK2fD9T3WZmuwHtCGfnWwXQ2LX6PKGV0dzM/p4mzQtmdjyhhTqQsK8MTUpyW2wBJ/7OTM0jqmifrw7Xkvv+AYCkIkk3SfowHk8WxUUVvc/ZpH4PEt+fir5frYDFZrYxZd3Ee7WWpPcyJV+A/8aT0a2WSzpU0muxO7Oc0GuxafsULsWUE3oWphJOqpoDO6cpM/mz6xm34QugPfBwzC/nY3RcfzzpXUv6z3MI4bu5mnhZLZs6ExSTFBG6tgAuJXzZDzWzXYE+cX7yWcOF8eCwB/BdSclnW4nuz1+klLEY2CNDKyHhcuBJM/sow/IXgF6E7os/pyxbQvhShMqGLq5mhG7ExYSulsr4R9zWFsDLZO+mqKiOi4EbUw54jczs8Rzr0jZpeh9Ct0fyTjsEeN/M/pFm3Q2E1tZ5hK6fpinL/4fQJZWpSzbVIMKZ7o2S2gLErsCnCV2Ue8b3bSJx34mt9JPMbPe47Kak/BYTWsLJ701jM7uJ3PadijQ3s0aEAPS0pIYK1w9/QTiBS9SnnC3387QsdK1fBNyl9HdtP0L4HqV+/qn5bDSzVwgnj1tdgshBRfv8tpbv/pHwf4T3vT/hpKNdnJ9zKySN1O/Bkjhd0fdrCdBW8Zpd0rqJ9+pjkt7LlHwBdo/vb7rljxGuG7e1cPPifSRtn5l9HOe3JpxEnkP43q5LU2byZ5c49jQAHiUGRfI4Rsf1T2RrFX2eLxO+C6eT48lLrQ6KkjpKulybb4zoQDg4PBaTNCWcIXyhcKPANRVkt4Fwo06LpHmnA2/GboRNzGwpIWD8QeFCcX1JfZKSNCX0p99IBhbuCrsZeDR2nSR7DDhLUkk8OP8WeDt2S/wV2EvSxfH6QlNJh1awXZnKLifL55+ljqOAYfHMUpIaK1ykTw1Qmfw4fn6NCHcQ/8W2vFPuakIXWjqfm9k/zewl4BW2vu4zgtB9tDrHurxhZnMIX6o/xnk7E7oglwPrJR0NHJVjfo8Cx0v6fmxdNFC4waFNDvtOrjYQDsw7E/a39bGu9ST9mnDdJyexe3cJ4SQj1evA9whn4VuQNFDSaXE7JKkH4UCZ7kQmm4r2+W0t3/0joSmhC3MF4Zrwb7dBXc6X1CYen64i/JQCKv5+vU249ndF3H/6Ea5XJn528TgwQlILSc0Jl34eZUvXSdo5nlAdBzyVtI2fm9ma+Hn+X2KFpHpC2O+KgNXxe/sk4aSyqaRvAZekKRPCMXYDm4+z+RyjM6no87wUWGJmT6VZllatDoqEpng/oDQ2vZ8C7jGzxA0IdxIuOn9G+KK+mCaPuxVu0lkEzGfLW9N3J3P35+mEs6P5hAvQFyct2xUYma2LzMweMrPfpZn/Siz3acJNOvsRbnQg9rt/j/Al+BT4ADi8onKSHKJw51kZ4RrORdlWqKCO7xCue9wN/JfQnTIkx3pAaHk8TNiGBsCFKcv/amYf5JDPJcBxSroTk3DQSu3uzcXvgL0lnRnf5wsJX/b/Eg4Oz1a0ckLsgh9IOMgtJ5z1X87m71tF+042X8T99RHgJ2ZWDrxECLT/InRbrWHLbrlc3Eo4yG5xs0y8LPFKmpMiCO/LuYR9cCXhIHirbXlj0BXa8neKabuwKtrnq0Fl949HCO/vJ8A/qVzwT/UY4Vr1wvh3A1T8/TKztcAJhN6Sz4A/AGfEy0cQgvVMwt3Ds+P0pjtFCd+5/xJOhMYQrm8n1v0ZcL2kVYRgmvwTm87Au3HZm4Sek0QPwgWEQL2Q0K36GOFGoYTD4n5bTrgOPTzOz+UYnU3az1PSfoSg+LN8MpP5IMNuO5M0mdD6fKDQdXGuUBR+WjDUzLa6kaway+xH+O61yZZ2R1XbW4rOOefcNuNB0TnnnIu8+9Q555yLvKXonHPORT7GVhU1b97c2rVrV+hqOOdcrTFjxozPzKxF9pTbnwfFKmrXrh3vvPNOoavhnHO1hqRMDzUpOO8+dc455yIPis4551zkQdE555yL/Jqic67GWbduHWVlZaxZk26YTFdbNGjQgDZt2lC/fv1CVyVnHhSdczVOWVkZTZs2pV27dij3ofBcDWJmrFixgrKyMtq3b1/o6uTMu0+dczXOmjVraNasmQfEWkwSzZo1q3WtfQ+KzrkayQNi7VcbP0MPimlIOlHSKEkTJOU6hp5zzrlartquKcYRzB8B9gI2Aveb2V0Z0hYB7wCfmNlxcd4iYBVhQMr1ZnZwFeoymjCQ5jIz65Q0fwBwF2GwzAfiyOiY2XhgvKTdCSOvT6ps2ZX18fWdMy7b59ezt2NNnCusFStWcOSRRwLw6aefUlRURIsW4WEo06ZNY+eddy5k9bL6+OOPufrqq3n//ff5+uuvmTx5Ms2b5zQIvCuA6rzRZj1wqZnNjKNFz5D0spn9M03ai4B5bD1a+OFmlnZQUgBJLQkjP69Kmre/mS1ISfowYbDOR5LSFQH3EAbsLQOmS3o2pX4jYhrnXIE0a9aM0tJSAK699lqaNGnCZZddVuBa5WbNmjUMGjSIG2+8kb59+9bK7sQdTbV1n5rZUjObGadXEYJe69R0ktoAxwKVGXC2LzBBUoOY17nAyDR1mQKkjhzeA1hgZgvjSNZjCaOlo+Bm4IXENjjnapZFixbRqVPo+Fm3bh377rsvw4eHAd2HDBlC+/btKSkpoaSkhIYNG7Jo0aKt8igqKtqU5sADD6Rfv35ACL6nn346RxxxBAcccACjRo3atM6tt97KIYccwkEHHcQ111yzaf7tt99Op06d6NSpE3feeScAr776KqtXr2b48OF07tyZX/ziF5vSN2nShEsvvZRu3bpx5JFHsnz5cgBGjRrFIYccQpcuXfjRj37E119/DcBvf/tbunfvTocOHRg6dCgbN27EzLj88svp1KkTnTt35oknngBg8uTJFBcXU1JSwr777svtt9++6T3r3bs33bp1o1u3brz55pub0h933HGb6nbbbbdx7bXXAtCvX79Nj7IcMWIETZo02ZRu2LBhdOjQgZKSEoqKivL5+Gqs7XJNUVI7oCvwdprFdwJXELpYkxkwSdIMSeely9fMngJeBMZKGgycDZySY7VaA4uTXpexOWhfAPQHTpI0LN3Kko6XdH95eXmOxTnnqsv999+/xcEaQvAqLS2ltLSU/fbbL+16DRs23JRmzJgxWyx77733eP7553nrrbe4/vrrWbJkCZMmTeKDDz5g2rRplJaWMmPGDKZMmcKMGTN46KGHePvtt/nHP/7BqFGjePfdd1m+fDmffPIJr732GqWlpUyfPp3x48cD8NVXX9GtWzdmzpxJ3759ue666wD44Q9/yPTp05k1axYdOnTgwQcfBOCqq65ixowZlJaW8sorr/DBBx/wzDPPUFpayqxZs/jb3/7G5ZdfztKlSwHo3bs3paWlPPHEEzz66KMAtGzZkpdffpmZM2fyxBNPcOGFF+b8Hi9btoxXXnll0+vZs2fz5ptvMnfuXEpLS2nYsGHOedVk1R4UJTUBngYuNrOVKcsS1/lmpFm1l5l1A44GzpfUJ13+ZnYLsAa4FzjBzL7MtWrpsot5jjSz7mY2zMzuy1Duc2Z2XnFxcY7FOeeqw9dff81DDz3ET3/6022a78CBA2nYsCHNmzfn8MMPZ9q0aUyaNIlJkybRtWtXunXrxvz58/nggw+YOnUqP/jBD2jcuDFNmjThhz/8IW+88QZmxve//31atGhBvXr1GDx4MFOmTAFgp5124tRTTwXgxz/+MVOnTgVgzpw59O7dm86dOzNmzBjmzp27qU7Dhg2jZcuW9OvXjwMOOICpU6cyaNAgioqK2HPPPenbty/Tp08H4I033qCkpITDDz98U/Bbt24d5557Lp07d+bkk0/mn//cfLUokb6kpIQ77rhjq/fjN7/5DVddddWm10VFRaxdu5a1a9du0/e90Ko1KEqqTwiIY8zsmTRJegEnxJtqxgJHSHoUwMyWxP/LgHGE7s50ZfQGOsU016RLk0EZ0DbpdRtgSR7rO+dqgDvvvJPzzjtvm7dUUq//ScLMuPLKKze1LhcsWMA555xDpsHad9019TaJ7OUNGTKEu+++m9mzZ3PNNdds8Tu/++67j6VLl7Jw4UIWLVqUsVzY3FJctGjRpnzuuOMO9txzT2bNmsU777yzRUBLpC8tLeXnP//5FnktWrSIOXPmcPzxx2+a17FjR0455RRatmxJSUkJq1evznlba7JqC4oKn/CDwDwzuz1dGjO70szamFk74DTgVTP7saTG8eYcJDUGjgLmpCmjKzCKcC3wLGAPSTfkWMXpwAGS2kvaOZb/bF4b6ZwrqPLycsaPH8/ZZ5+9zfOeMGECa9asYcWKFUyePJlDDjmE73//+4wePZovvwwdUp988gnLli2jT58+jB8/nq+//pqvvvqKcePG0bt3b7p3786rr77KZ599xoYNG3j88cfp27cvABs3buQvf/kLAI899hjf/e53AVi1ahV7770369at26JL94svvgCgXr16fP3113z00Uf06dOHJ554gg0bNrB8+XKmTJlCjx5bth8aNWrE6tWr+eabbygvL2fvvfdmp5124s9//jMbNmzI6b247rrrNnXvJisuLuaiiy6qU92n1Xn3aS/gdGC2pNI47yozmyhpIjA00RpMY09gXDxzqgc8ZmYvpknXCDjZzD4EkHQmMCQ1kaTHgX5Ac0llwDVm9qCk4cBLhJ9kjDazuanrOudqrrKyMm677Tbq1dv2h7IePXpw7LHH8vHHH/OrX/2KVq1a0apVK+bNm8dhhx0GhJtlHn30Ubp168aQIUM2BaShQ4fStWtXINy006dPH4qKijj22GMZOHAgAI0bN2bu3Ll0796d4uLiTTfJ/OY3v+HQQw/lW9/6Fp07d2bVqnBzfSL4rF69miOPPJI+ffqw00478dZbb9GlSxckccstt7DXXnsxf/78Td2ha9as4ZJLLqG4uJif/exn/OhHP+Kpp57i8MMPp3Hjxjm9F23atKFPny2vYL355ptMmjSJiRMnVv3NrkFUUfPbZXfwwQdbdQwy7L9TdDuyefPm0aFDh4KVvz1++tGkSZNNLc66LN1nKWlGVX57Xp38iTbOOedc5KNkOOdcisRv9KrTjtBKrI28peicc85FHhSdc865yIOic845F3lQdM455yK/0cY5t8Prfvkj2RPlYcatZ2RNU1RUROfOnTEzioqKuPvuu/nOd74DwNy5c7ngggsoKyvDzDjjjDMYMWIEAC1atOCDDz5g9913Z+nSpbRq1Yo33nhj04//W7Rowfz582nWrNk23aYdhbcUnXOuABIPI581axa/+93vuPLKKwFYvXo1J5xwAr/85S/517/+xaxZs3jzzTf5wx/+gCQOPfRQ3nrrLSD8gL5r166bRrt4//33ad68uQfEKvCg6JxzBbZy5Up23313IDzyrVevXhx11FFAeEzb3XffzU033QRAr169NgXBN998k0suuWSLIJlobbrK8aDonHMFsHr1akpKSvjf//1fhg4dyq9+9SuATY9+S7bffvvx5ZdfsnLlSr7zne9sCorTpk3jxBNPZPHiMArem2++Sa9evbbvhtQxHhSdc64AEt2n8+fP58UXX+SMM87AzDCzrUboSJBEjx49ePfdd/nqq69Yt24dTZo0Yd9992XBggXeUtwGPCg651yBHXbYYXz22WcsX76cb3/726Q+T3nhwoU0adKEpk2b0qhRI/bff39Gjx5Nt27dAOjZsycTJ05k2bJlHHjggYXYhDrDg6JzzhXY/Pnz2bBhA82aNWPw4MFMnTqVv/3tb0DoZr3wwgu54oorNqXv1asXd95556bROg477DDuuusuevbsmbGV6XLjP8nIQNKJwLFAS+AeM5tU4Co556pJLj+h2NYS1xQBzIw//elPFBUV0bBhQyZMmMAFF1zA+eefz4YNGzj99NMZPnz4pnV79erFXXfdtSkoduvWjbKyMoYOHbrdt6OuKUhQlNQWeATYC9gI3G9md2VIWwS8A3xiZsdVoczRwHHAMjPrlDR/AHAXYUzFB8zsJgAzGw+Ml7Q7cBvgQdE5t81UNMBv586dmTx5csblJ598MsnD/u2yyy58880327J6O6xCdZ+uBy41sw5AT+B8SR0zpL0ImJdugaSWkpqmzNs/Qz4PAwNS0hYB9wBHAx2BQWnqMSKmcc45V8cVJCia2VIzmxmnVxGCXuvUdJLaELowH8iQVV9ggqQGMf25wMgMZU4BPk+Z3QNYYGYLzWwtMBYYGPOSpJuBFxJ1Tanb8ZLuLy8vz7q9zjnnaoeC32gjqR3QFXg7zeI7gSsIXaxbMbOngBeBsZIGA2cDp+RRfGtgcdLrMjYH5wuA/sBJkoalKfs5MzuvuLg4j+Kcc87VZAW90UZSE+Bp4GIzW5myLHH9b4akfpnyMLNbJI0F7gX2M7N8Ru5Md5uWxXxHkqHV6Zxzrm4qWEtRUn1CQBxjZs+kSdILOEHSIkK35hGSHk2TT2+gEzAOuCbPapQBbZNetwGW5JmHc865OqIgQVHhhzQPAvPM7PZ0aczsSjNrY2btgNOAV83sxyn5dAVGEa4DngXsIemGPKoyHThAUntJO8dyns17g5xzztUJheo+7QWcDsyWVBrnXWVmEyVNBIaaWS4ttkbAyWb2IYCkM4Eh6RJKehzoBzSXVAZcY2YPShoOvET4ScZoM5tbhe1yztVCH1/feZvmt8+vZ1e4fMWKFRx55JEAfPrppxQVFdGiRQsAZs2aRZcuXTalHT9+PO3atdti/SFDhnDcccdx0kkn0a9fP5YuXcouu+zC2rVr6d+/PzfccAO77bYbsHmIqoryc5sVJCia2VTSX8/DzI5JM28yMDnN/L+nvF5HaDmmy3dQhvkTgYnZ6uycc9tKs2bNKC0N7YFrr72WJk2acNlllwHQpEmTTctyNWbMGA4++GDWrl3LlVdeycCBA3n99deBzc9Ydbkp+N2nzjnnto2dd96ZW265hY8//phZs2YVujq1kgdF55yrQRKPfyspKeEHP/hB3usXFRXRpUsX5s+fv03y29H4s0+dc64G2RbdncmPgPPu0/x4S9E552q4s846i5KSEo45ZqtbLrayYcMGZs+eTYcOHbZDzeoebyk651wN99BDD+WUbt26dVx99dW0bduWgw46qJprVTd5UHTO7fCy/YSiphs8ePCmkTL69+/PhAkTCl2lWsuDonPOFdC11167xesvv8z+pMqHH35403RFQ0zlmp/bzK8pOuecc5EHReeccy7yoOicq5GSf1bgaqfa+Bl6UHTO1TgNGjRgxYoVtfKg6gIzY8WKFTRo0KDQVcmL32jjnKtx2rRpQ1lZGcuXLy90VVwVNGjQgDZt2hS6GnnxoOicq3Hq169P+/btC10NtwPy7lPnnHMu8qCYhqQTJY2SNEHSUYWuj3POue2j2oKipLaSXpM0T9JcSRelSdNA0jRJs2Ka65KWLZI0W1KppHeqWJfRkpZJmpMyf4Ck9yUtkPTLxHwzG29m5xIGLD61KmU755yrPaqzpbgeuNTMOgA9gfMldUxJ8w1whJl1AUqAAZJ6Ji0/3MxKzOzgdAVIaimpacq8/dMkfRgYkJKuCLgHOBroCAxKU78RMY1zzrkdQLUFRTNbamYz4/QqYB7QOiWNmVniGUT1418+92D3BSZIagAg6VxgZJq6TAE+T5ndA1hgZgvNbC0wFhgY85Gkm4EXEtuQStLxku4vLy/Po7rOOedqsu1yTVFSO6Ar8HaaZUWSSoFlwMtmlkhjwCRJMySdly5fM3sKeBEYK2kwcDZwSo7Vag0sTnpdxuagfQHQHzhJ0rAMZT9nZucVFxfnWJxzzrmartp/kiGpCfA0cLGZrUxdbmYbgBJJuwHjJHUyszlALzNbIqkl8LKk+bHFl7r+LZLGAvcC+yW1PLNWLc08i3mOJE2Lc1vrfvkjGZeNa5pxkXPOuWpSrS1FSfUJAXGMmT1TUVoz+wKYTLz2Z2ZL4v9lwDhCd2e6MnoDnWKaa/KoXhnQNul1G2BJHus755yrY6rz7lMBDwLzzOz2DGlaxBYikhoSuiznS2qcuIFGUmPgKGBOmvW7AqMI1wLPAvaQdEOOVZwOHCCpvaSdgdOAZ/PZRuecc3VLdbYUewGnA0fEn1WUSjoGQNJESa2AvYHXJL1HCFIvm9lfgT2BqZJmAdOA583sxTRlNAJONrMPzWwjcCbwUWoiSY8DbwEHSiqTdI6ZrQeGAy8RbgJ60szmbtu3wDnnXG1SbdcUzWwq6a/bYWbHxMklhBtwUpcvBLrkUMbfU16vI7QcU9MNyrD+RGBitnKccxDzD0gAAB1JSURBVM7tGPyJNs4551zkQdE555yLPCg655xzkQdF55xzLvKg6JxzzkUeFJ1zzrnIg6JzzjkXeVB0zjnnIg+KzjnnXORB0TnnnIuqfegoVzgfX98547J9fj17O9bEOedqB28pOuecc5EHReeccy7yoJiBpBMljZI0QdJRha6Pc8656leQoCipraTXJM2TNFfSRWnSNJA0TdKsmOa6KpY5WtIySXNS5g+Q9L6kBZJ+mZhvZuPN7FxgCHBqVcp2zjlXOxSqpbgeuNTMOgA9gfMldUxJ8w1whJl1AUqAAZJ6JieQ1FJS05R5+2co82FgQEraIuAe4GigIzAoTT1GxDTOOefquIIERTNbamYz4/Qqwsj3rVPSmJl9GV/Wj3+WklVfYIKkBgCSzgVGZihzCvB5yuwewAIzW2hma4GxwMCYlyTdDLyQqKtzzrm6reDXFCW1A7oCb6dZViSpFFgGvGxmW6Qxs6eAF4GxkgYDZwOn5FF8a2Bx0usyNgfnC4D+wEmShqWp2/GS7i8vL8+jOOecczVZQYOipCbA08DFZrYydbmZbTCzEqAN0ENSpzRpbgHWAPcCJyS1LnOqQpp5FvMdaWbdzWyYmd2XptznzOy84uLiPIpzzjlXkxUsKEqqTwiIY8zsmYrSmtkXwGRSrgnGfHoDnYBxwDV5VqMMaJv0ug2wJM88nHPO1RGFuvtUwIPAPDO7PUOaFpJ2i9MNCV2Z81PSdAVGEa4DngXsIemGPKoyHThAUntJOwOnAc/muz3OOefqhkK1FHsBpwNHSCqNf8cASJooqRWwN/CapPcIwetlM/trSj6NgJPN7EMz2wicCXyUrkBJjwNvAQdKKpN0jpmtB4YDLxFu9nnSzOZu+811zjlXGxTk2admNpX01/Mws2Pi5BLCDTgV5fP3lNfrCC3HdGkHZZg/EZiYpcrOOed2AAW/+9Q555yrKTwoOuecc5EHReeccy7yoOicc85FHhSdc865yIOic845F3lQdM455yIPis4551zkQdE555yLKgyKko5Imm6fsuyH1VUp55xzrhCytRRvS5p+OmXZiG1cF+ecc66gsgVFZZhO99o555yr1bIFRcswne61c845V6tlGyVjX0nPElqFiWni6/aZV3POOedqn2xBcWDS9G0py1JfO+ecc7VahUHRzF5Pfi2pPtAJ+MTMllVnxQpJ0onAsUBL4B4zm1TgKjnnnNsOKgyKku4D/p+ZzZVUTBi5fgOwh6TLzOzxCtZtCzwC7AVsBO43s7tyTSNpEbAqlrfezA6u3CaCpNHAccAyM+uUNH8AcBdQBDxgZjcBmNl4YLyk3Qkt4hobFLtf/kjGZeOabseKOOdcHZDtRpveZjY3Tp8F/MvMOgPdgSuyrLseuNTMOgA9gfMldcwzzeFmVpIpIEpqKalpyrz90yR9GBiQkq4IuAc4GugIDEpTvxExjXPOuR1AtqC4Nmn6e8B4ADP7NFvGZrbUzGbG6VXAPKB1vmmy6AtMkNQAQNK5wMg0dZkCfJ4yuwewwMwWmtlaYCzxGqqCm4EXEvVLJel4SfeXl5fnUV3nnHM1Wbag+IWk4yR1BXoBLwJIqgc0zLUQSe2ArsDbeaQxYJKkGZLOS7eOmT0V6zRW0mDgbOCUHKvVGlic9LqMzQH5AqA/cJKkYRnKfs7MzisuLs6xOOecczVdtrtPf0Joee0FXJzUQjwSeD6XAiQ1ITwN52IzW5lHml5mtkRSS+BlSfNji28LZnaLpLHAvcB+ZvZlLvUi/cMHLOY5kjQtTuecc3VbtrtP/0XKtbg4/yXgpWyZx7tVnwbGmNkz+aQxsyXx/zJJ4wjdnVsFRUm9CXfEjgOuAYZnq1dUBrRNet0GWJLjus455+qgbHefVthaMrMLK1hXwIPAPDO7PZ80khoDO5nZqjh9FHB9mvW7AqMIP5/4N/CopBvMLJfnsk4HDogPOv8EOA34vxzWc845V0dl6z4dBswBniS0ovJ53mkv4HRgtqTSOO8qM5soaSIwFNg3XRpgPjAuxEzqAY+Z2YtpymgEnGxmHwJIOhMYkppI0uNAP6C5pDLgGjN7UNJwQou3CBiddKetc865HVC2oLg3cDJwKuHnE08AT5vZf7NlbGZTyRBEzeyYOFlRoO2SQxl/T3m9jtByTE03KMP6E4GJ2cpxzjm3Y6jw7lMzW2Fm95nZ4YQW2G7AXEmnb4/KOeecc9tTtpYiAJK6AYMIv1V8AZhRnZVyzjnnCiHbjTbXER6PNo/w4/YrzWz99qiYc845t71layn+ClhIuL7XBfhtvPlFgJnZQdVbPeecc277yRYUfcxE55xzO4xsP97/KN38+DDt04C0y51zzrnaqMK7TyXtKulKSXdLOio+KPsCQpdqrs8Ydc4552qFbN2nfwb+SxhHcShwObAzMNDMSita0TnnnKttsgXFfeP4iUh6APgM2CcO8+Scc87VKdmGjlqXmDCzDcC/PSA655yrq7K1FLtISgzlJKBhfJ34Scau1Vo7V3AfX98547J9fj17O9bEOeeqX7a7T4u2V0Wcc865QsvWfeqcc87tMDwoOuecc5EHReeccy7yoJiBpBMljZI0QdJRha6Pc8656pfT0FHbmqS2wCPAXsBG4H4zuyvfNHmWOZow4scyM+uUNH8AcBdQBDxgZjcBmNl4YLyk3YHbgEmVLbum6375IxmXjWu6HSvinHMFVqiW4nrgUjPrAPQEzpfUMd80klpKapoyb/8MZT4MDEhJWwTcAxwNdAQGpanHiJjGOedcHVeQoGhmS81sZpxeRRivsXW+aYC+wARJDQAknQuMzFDmFODzlNk9gAVmttDM1hLGjBwY85Kkm4EXEvVIJul4SfeXl5fnseXOOedqsoJfU5TUDugKvJ1vGjN7CngRGCtpMHA2+T2ovDWwOOl1GZsD7wVAf+AkScNSVzSz58zsvOLi4jyKc845V5MV5JpigqQmwNPAxWa2sjJpzOwWSWOBe4H9zOzLfKqQZp7FfEeSodXpnHOubipYS1FSfUKwG2Nmz1QhTW+gEzAOuCbPapQBbZNetwGW5JmHc865OqIgQVGSgAeBeWZ2exXSdAVGEa4DngXsIemGPKoyHThAUntJOxMGTn42j/Wdc87VIYVqKfYCTgeOkFQa/44BkDRRUquK0iRpBJxsZh+a2UbgTOCjdAVKepwwLuSBksoknWNm64HhwEuEG3meNLO51bC9zjnnaoGCXFM0s6mkv56HmSUC35JMaZLS/j3l9TpCyzFd2kEZ5k8EJmapsnPOuR1Awe8+dc4552oKD4rOOedc5EHROeecizwoOuecc5EHReeccy7yoOicc85FBX3Mm9sxfHx954zL9vn17O1YE+ecq5i3FJ1zzrnIg6JzzjkXeVB0zjnnIg+KzjnnXORB0TnnnIs8KDrnnHORB0XnnHMu8qDonHPORR4U05B0oqRRkiZIOqrQ9XHOObd9VFtQlNRW0muS5kmaK+miDOlGS1omaU7K/EWSZksqlfROFeuSqYwBkt6XtEDSLxPzzWy8mZ0LDAFOrUrZzjnnao/qfMzbeuBSM5spqSkwQ9LLZvbPlHQPA3cDj6TJ43Az+yxTAZJaAqvNbFXSvP3NbEG2MiQVAfcA3wPKgOmSnk2p34iYxmXR/fJ0H18wrul2rIhzzlVBtbUUzWypmc2M06uAeUDrNOmmAJ9Xspi+wARJDQAknQuMzLGMHsACM1toZmuBscDAmI8k3Qy8kNiGVJKOl3R/eXl5JavunHOuptku1xQltQO6Am/nsZoBkyTNkHRe2gRmTwEvAmMlDQbOBk7JMf/WwOKk12VsDtoXAP2BkyQNy1D2c2Z2XnFxcY7FOeecq+mqfZQMSU2Ap4GLzWxlHqv2MrMlsYv0ZUnzY4tvC2Z2i6SxwL3Afmb2Za5VSzPPYp4jSdPidIXjI20457aHam0pSqpPCIhjzOyZfNY1syXx/zJgHKG7M10ZvYFOMc01eRRRBrRNet0GWJJPHZ1zztUt1Xn3qYAHgXlmdnue6zaON+cgqTFwFDAnTbquwCjCtcCzgD0k3ZBjMdOBAyS1l7QzcBrwbD71dM45V7dUZ0uxF3A6cET8WUWppGMAJE2U1CpOPw68BRwoqUzSOcCewFRJs4BpwPNm9mKaMhoBJ5vZh2a2ETgT+Cg1UboyzGw9MBx4iXAT0JNmNnfbvgXOOedqk2q7pmhmU0l/3Q4zOyZpelCGLLrkUMbfU16vI7QcU9OlLcPMJgITs5XjnHNux+BPtHHOOeciD4rOOedcVO0/yXAuV/5UHOdcoXlQdDsM/62jcy4b7z51zjnnIg+KzjnnXORB0TnnnIs8KDrnnHORB0XnnHMu8rtPXZ3iP+twzlWFtxSdc865yIOic845F3lQdM455yIPis4551zkQdE555yL/O5T51JUdAfrjFvP2I41cc5tbx4UM5B0InAs0BK4x8wmFbhKrgbwh4o7V7cVpPtUUltJr0maJ2mupIsypBstaZmkOdugzLR5SRog6X1JCyT9MjHfzMab2bnAEODUqpbvnHOu5ivUNcX1wKVm1gHoCZwvqWOadA8DAzJlIqmlpKYp8/bPkHyrvCQVAfcARwMdgUFp6jEipnHOOVfHFSQomtlSM5sZp1cB84DWadJNAT6vIKu+wARJDQAknQuMzFBmurx6AAvMbKGZrQXGAgNjXpJ0M/BCoq7JJB0v6f7y8vKKN9Y551ytUfC7TyW1A7oCb+e7rpk9BbwIjJU0GDgbOCWPLFoDi5Nel7E5OF8A9AdOkjQsTdnPmdl5xcXF+VbbOedcDVXQG20kNQGeBi42s5WVycPMbpE0FrgX2M/MvsynCumyjPmOJEOr0znnXN1UsKAoqT4hII4xs2eqkE9voBMwDrgGGJ7H6mVA26TXbYAlla2Lc8ky/bRjXNNbM67jd7A6V1iFuvtUwIPAPDO7vQr5dAVGEa4DngXsIemGPLKYDhwgqb2knYHTgGcrWx/nnHO1W6GuKfYCTgeOkFQa/44BkDRRUqs4/TjwFnCgpDJJ56Tk0wg42cw+NLONwJnAR+kKTJeXma0ntCxfItzs86SZzd32m+ucc642KEj3qZlNJf31PMzsmKTpQVny+XvK63WElmO6tGnzMrOJwMQsVXbOObcD8CfaOFeD+SPnnNu+Cv6TDOecc66m8Jaic7VUpuew+h2szlWetxSdc865yFuKzu3AvLXp3Ja8peicc85FHhSdc865yLtPnavjKvpZx7imGRflzAdednWJtxSdc865yFuKzrmsvLXpdhTeUnTOOecibyk657aLbdHarDgPH5LLVZ23FJ1zzrnIW4rOuR3Ktmht+oPa6y5vKTrnnHORtxSdc64AtkVrc1u1WDPlsyO2ej0oOufcNuQ/L6ndPCimIelE4FigJXCPmU0qcJWcczuQbRFYPThXTrUFRUltgUeAvYCNwP1mdleadAOAu4Ai4AEzuynOXwSsAjYA683s4CrUZTRwHLDMzDplK9vMxgPjJe0O3AZ4UHTO7XB2xMBanTfarAcuNbMOQE/gfEkdkxNIKgLuAY4GOgKDUtIcbmYlmQKipJaSmqbM2z9N0oeBAXmWDTAipnHOObcDqLagaGZLzWxmnF4FzANapyTrASwws4VmthYYCwzMo5i+wARJDQAknQuMTFOXKcDnuZat4GbghcQ2pJJ0vKT7y8vL86iuc865mmy7/CRDUjugK/B2yqLWwOKk12VsDpwGTJI0Q9J56fI1s6eAF4GxkgYDZwOn5Fitisq+AOgPnCRpWIaynzOz84qLi3MszjnnXE1X7TfaSGoCPA1cbGYrUxenWcXi/15mtkRSS+BlSfNji2/LxGa3SBoL3AvsZ2Zf5lq1TGWb2UjStDidc87VbdXaUpRUnxAQx5jZM2mSlAFtk163AZYAmFni/zJgHKG7M10ZvYFOMc01eVQvY9nOOed2TNUWFCUJeBCYZ2a3Z0g2HThAUntJOwOnAc9Kapy4gUZSY+AoYE6aMroCowjXAs8C9pB0Q45VTFt27lvonHOurqnOlmIv4HTgCEml8e8YAEkTJbUys/XAcOAlwo04T5rZXGBPYKqkWcA04HkzezFNGY2Ak83sQzPbCJwJfJSaSNLjwFvAgZLKJJ1TQdnOOed2UNV2TdHMppL+uh1mdkzS9ERgYsryhUCXHMr4e8rrdYSWY2q6QRnW36ps55xzOy5/ILhzzjkXycyyp3IZSVpOmi7bbaA58Jnn4XnUgrp4Hp5Hvr5lZi2qId8q86BYQ0l6pyqPtvM86nYeNakunofnUZd496lzzjkXeVB0zjnnIg+KNdf9nofnsR3y8Tw8j+rOo1bxa4rOOedc5C1F55xzLvKg6JxzzkUeFGsQSQ0kTZM0S9JcSddVIa8iSe9K+msV8lgkaXZ8RN87lcxjN0l/kTRf0jxJh+W5/oFJjwkslbRS0sWVqMfP43s6R9LjiTE488zjorj+3FzrIGm0pGWS5iTN20PSy5I+iP93r0QeJ8d6bJSU9Zb5DHncGj+X9ySNk7RbJfP5TcyjVNIkSa3yzSNp2WWSTFLzStTjWkmfpD5WMt96SLpA0vvx/b2lEvV4IqkOiySVViKPEkn/SHz3JKUdECFLHl0kvRW/w89J2jVLHm0lvRa/p3MlXRTn57W/1npm5n815I/wWLwmcbo+YfzJnpXM6xLgMeCvVajPIqB5FbfpT8DQOL0zsFsV8ioCPiX88Def9VoD/wYaxtdPAkPyzKMT4aH0jQiPR/wbcEAO6/UBugFzkubdAvwyTv8SuLkSeXQADgQmAwdXsh5HAfXi9M3Z6lFBPrsmTV8I3JdvHnF+W8KziD/Ktt9lqMe1wGV5fKbp8jg8fra7xNctK7MtSct/D/y6EvWYBBwdp48BJlcij+lA3zh9NvCbLHnsDXSL002BfwEd891fa/uftxRrEAsS40HWj3953wklqQ1wLPDANqxe3uKZaR/CaCmY2Voz+6IKWR4JfGhmlXmCUD2goaR6hMCW7zBhHYB/mNnXFh4m/zrwg2wrWRgD9POU2QMJJwvE/yfmm4eZzTOz93Ose6Y8JsVtAfgHYfi0yuSTPE5qY7LssxneE4A7gCuyrZ8lj5xlyOOnwE1m9k1Ms6yy9ZAkwqDnj1ciDwMSLbtisuyvGfI4EEiMQfsy8KMseSw1s5lxehVhoITW5Lm/1nYeFGuY2O1ZCiwDXjaztyuRzZ2Eg8vGKlbHgEmSZkg6rxLr7wssBx6KXbkPKAwFVlmnkeUAk46ZfQLcBnwMLAXKzWxSntnMAfpIaiapEeHsvW2WdTLZ08yWxrotBVpWMp9t6WzghcquLOlGSYuBwcCvK7H+CcAnZjarsnWIhseu3NGV7Ob7H6C3pLclvS7pkCrUpTfwHzP7oBLrXgzcGt/T24ArK5HHHOCEOH0yeeyvktoBXQm9VTVxf602HhRrGDPbYGYlhLP2HpI65bO+pOOAZWY2YxtUp5eZdQOOBs6X1CfP9esRunTuNbOuwFeE7pe8KYx5eQLwVCXW3Z1wttseaAU0lvTjfPIws3mELsaXgReBWcD6CleqJSRdTdiWMZXNw8yuNrO2MY/heZbfCLiaSgTTFPcC+wElhJOf31cij3rA7kBP4HLgydjiq4xBVOIkLvop8PP4nv6c2NuSp7MJ39sZhO7QtbmsJKkJYXD4i1N6AXYIHhRrqNjNOBkYkOeqvYATJC0CxhLGs3y0knVYEv8vA8YBFV7sT6MMKEtq7f6FECQr42hgppn9pxLr9gf+bWbLLQwv9gzwnXwzMbMHzaybmfUhdFVVpgUA8B9JewPE/xV20VUnSWcCxwGDLV40qqLHyNJNl8Z+hBOWWXG/bQPMlLRXPpmY2X/iSeVGwhBy+e6vEPbZZ+KljGmE3pYKb/pJJ3bT/xB4ohJ1gDA27DNx+ikqsS1mNt/MjjKz7oTg/GG2dSTVJwTEMWaWKL/G7K/bgwfFGkRSi8QdgJIaEg7m8/PJw8yuNLM2ZtaO0N34qpnl1SqK5TeW1DQxTbgpY6u7BbPU5VNgsaQD46wjgX/mW5eoKmfdHwM9JTWKZ/1HEq6X5EVSy/h/H8IBr7L1eZZw0CP+n1DJfKpE0gDgF8AJZvZ1FfI5IOnlCeS/z842s5Zm1i7ut2WEGz4+zbMeeye9/AF57q/ReOCImN//EG4Oq8woEf2B+WZWVol1IVxD7Bunj6ASJ2BJ++tOwAjgvizpRWiRzjOz25MW1Yj9dbsp9J0+/rf5DzgIeBd4j/CFrvCutRzy60cl7z4lXA+cFf/mAldXMp8S4J24TeOB3SuRRyNgBVBchffiOsLBeg7wZ+LdhXnm8QYhqM8CjsxxnccJXXnrCAf7c4BmwCuEA90rwB6VyOMHcfob4D/AS5XIYwGwGCiNfxXeNVpBPk/H9/U94Dmgdb55pCxfRPa7T9PV48/A7FiPZ4G9K5HHzsCjcXtmAkdUZluAh4FhVdhHvgvMiPva20D3SuRxEeEO0n8BNxGfYFZBHt8l3EfwXtI+cUy++2tt//PHvDnnnHORd58655xzkQdF55xzLvKg6JxzzkUeFJ1zzrnIg6JzzjkXeVB0DpD0ZdL03pI+lHR8Ieu0o5M0KD5ubaqkjoWuj9sx+E8ynCMERTNrEh9YMIXwaLr7C10v59z25S1F56L4iKtngGeTA2JsscxWGEvx5pR1NsQx7xYojl0p6WFJJ8XpoYrjA0rqp6TxLeNYe83j9I8VxtIslfRHSUVx/gBJMxXG2HxFUkNtHqtvrTaPd3lwLPffsZ7vJZ6bq81j8yXGTdzqQdmS9ozLZsW/78T5l8T85ihpDElJZ8T8Zkn6c5zXQtLTkqbHv15J6S+T9Gms6+dJ70/adRTGRrwsTh8Z38Os40Y6V1UeFJ3bbDTh0VqbHt+mMGDuzYRHbZUAh0g6MS4rAr6y8AD3oamZKQxkPIzNz4rcSBgzMzVdB+BUwgPYS4ANwGBJLQjP8PyRmXUBTjaz1WZWEtMtAQ6PrxODQF9uZp0Ird0j4rxHgF+Y2UGEJ75ck2bbRwKvx3K6AXMldQfOAg4lPCD7XEldJX2b8ADvI2L6i2IedwF3mNkhhOefJg9dVgT8Idb72aT5Fa2TcA3h6TvOVbt6ha6AczVEY2APYAhwD+H5qACHEAZ4XQ4gaQxhjMjxQENgTQV5nk8Yf+7S+LoM6CCpgZklr3ck0B2YHh4/SUNCIO0JTDGzfwOYWS7jB94q6XfALsChkooJAzu/Hpf/ifQjjRwBnBHL2QCUS/ouMM7Mvorb/gxhOCQD/mJmn6XUqz/QUZsHldhVUlMLY/M1ITyOLlXadRIvJP2IMFhu9xy23bkq85aic8E3wClm9hiwTtLgOL+iYYNakXnw110JDzH/Y2KGmS0kjCIxU2HMzFZJZfwp0QI0swPN7No4P9+L/peb2QHA9YTnvVZFpm3PVK+dgMOStqN1DIgQRsFI93DsitYpIowL+rsqbINzefGg6FywPtEiIowHeGNsZb0N9I3XBIsIgS7R6joF+HuG/H4OjDSzLcawM7MRZtYxqfsTwkOWT0oa1WAPSd8C3oplt0/Mz2N7VhIeql0O/FdS7zj/9KT6J3uFMIZfYqDrXQldsCcqjC7SmPAQ8jdi2lMkNUup1ySSxlKUVBL/70Z42PQracpNu070Y+D5RIvUue3Bu0+dS2FmCyQ9BPzWzM6XdCXwGqGFNNHMJki6kDB25ZkZshFhtIVcyvunpBHAJIVhftYB55vZPySdBzwT5y8Dvpclu1tjXsbm65xnAvcpDOa7kHCdMNVFwP2SziFc0/ypmb0l6WFgWkzzgJm9CyDpRuB1SRsII7sMAS4E7pH0HuHYMoVwTXUSYbT2N2I36T6Ea7d/qWAdgD2BO7Jsr3P/v307tgEQiGEAqN+MIZiIeRiCzUzjCkHHC4q7MlU6y5HyKi8ZwFRjjCPJcpntSdaPVoJHzqfAbNvNTAPklzRFAChNEQBKKAJACUUAKKEIACUUAaBO+O5+ki/4sHIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Количество соседей',\n",
    "            y='RMSE',\n",
    "            hue='Тип преобразования',\n",
    "            data=logs_data[best_selection])\n",
    "plt.semilogy()\n",
    "plt.title('Зависимость метрики качества RMSE от типа преобразования')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику можно заметить, что алгоритм с преобразованием текстовых признаков **TF-IDF** превосходит аналогичный алгоритм, но с преобразованием **Bag of words**. Это происходит из-за того, что **TF-IDF** дополнительно учитывает информацию об уникальности слов (В данном эксперименте на качество не влияет нормировка, которая входит в **TF-IDF**, так как используется косинусная метрика расстояния)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость RMSE от метрики:\n",
    "В данном эксперименте используется **Bag of words** в качетсве преобразования текстовых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Количество соседей',\n",
    "            y='RMSE',\n",
    "            hue='Метрика расстояния',\n",
    "            data=logs_data[logs_data['Тип преобразования'] == 'BOW'])\n",
    "plt.semilogy()\n",
    "plt.title('Зависимость метрики качества RMSE от метрики расстояния')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практически во всех случаях наилучшее качество дает косинусная метрика. Это объясняется тем, что при преобразовании **Bag of words** значения признаков не нормированы, а евклидова метрика чувствительна к масштабу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зависимость RMSE от количества соседей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x='Количество соседей',\n",
    "            y='RMSE',\n",
    "            data=logs_data[best_selection & (logs_data['Тип преобразования'] == 'TF-IDF')])\n",
    "plt.title('Зависимость метрики качества RMSE от соседей.')\n",
    "plt.xticks(logs_data['Количество соседей'].unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику видно, что ошибка убывает с ростом количества соседей. Это логично, так как предсказания усредняются по бОльшему числу похожих объектов. Но такое поведение графика не будет сохраняться при достаточно больших значениях $k$. Например, при $k = l$, где $l$ - количество объектов в тренировочной выборке модель выраждается в константный предсказатель (если рассматривается модель без весов), где предсказание для объекта из теста равно среднему значению целевой переменной по всей тренировочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.2 (1 балл)</b> Используя все доступные признаки, решите задачу регрессии. Для категориальных и текстовых признаков выберите лучшие преобразования. Повлияло ли добавление количественного признака на метрику качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Будем проверять на евклидовой метрике, используя лучшие преобразования для категориальных и текстовых признаков:\n",
    "    1) Добавим все признаки из 2.4 (без фолдинга)\n",
    "    2) Добавим признаки, использующие функцию g = mean.\n",
    "    3) Добавим все текстовые признаки, полученные с помощью TF-IDF\n",
    "    4) Все исходные числовые признаки (кроме тех, что являются неинформативными)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
    "numeric_columns = ['latitude',\n",
    "                   'longitude',\n",
    "                   'room_type',\n",
    "                   'minimum_nights',\n",
    "                   'number_of_reviews',\n",
    "                   'reviews_per_month',\n",
    "                   'calculated_host_listings_count',\n",
    "                   'availability_365'] \n",
    "text_columns = ['name', 'host_name']\n",
    "\n",
    "data_numerical = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закодируем категориальные призаки (из-за этого быстрее считаются статистики):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for column in cat_columns:\n",
    "    all_classes_in_col = data_numerical[column].unique()\n",
    "    le.fit(all_classes_in_col)\n",
    "    data_numerical.loc[:, column] = le.transform(data_numerical.loc[:, column]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем данные на тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_numerical.drop(columns=['price', 'target']),\n",
    "                                                    data_numerical[['price', 'target']],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сгенерируем признаки-счетчики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_features_train = counters(X_train[cat_columns], X_train[cat_columns], y_train['target'])\n",
    "counter_features_test = counters(X_test[cat_columns], X_train[cat_columns], y_train['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сгенерируем признаки из пункта 2.5 с помощью функции $mean$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_j_feature_train, p_j_feature_test = calculate_p_j_for_df(X_train[cat_columns],\n",
    "                                                           X_test[cat_columns],\n",
    "                                                           y_train['price'],\n",
    "                                                           np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим полученные признаки в тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, counter_features_train, p_j_feature_train], axis=1)\n",
    "X_test = pd.concat([X_test, counter_features_test, p_j_feature_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выкинем текстовые, категориальные и неинформативные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(text_columns + cat_columns + ['id', 'host_id', 'last_review', 'availability_365'], axis=1, inplace=True)\n",
    "X_test.drop(text_columns + cat_columns + ['id', 'host_id', 'last_review', 'availability_365'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['price']\n",
    "y_test = y_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_arr = X_train.iloc[:, 8:].to_numpy()\n",
    "X_train_with_text_arr = X_train_with_text.toarray()\n",
    "X_test_arr = X_test.iloc[:, 8:].to_numpy()\n",
    "X_test_with_text_arr = X_test_with_text.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединим преобразованные текстовые признаки с помощью TF-IDF с признаками, полученными выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = np.hstack([X_train_with_text_arr, X_train_arr])\n",
    "X_test_full = np.hstack([X_test_with_text_arr, X_test_arr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим качество при различных параметрах алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 3, weights: uniform, metric: euclidean, rmse: 233.06325586425268\n",
      "n_neighbors: 4, weights: uniform, metric: euclidean, rmse: 223.3549325392909\n",
      "n_neighbors: 5, weights: uniform, metric: euclidean, rmse: 217.6473586535891\n",
      "n_neighbors: 6, weights: uniform, metric: euclidean, rmse: 212.55445480402162\n",
      "n_neighbors: 7, weights: uniform, metric: euclidean, rmse: 209.7160474747572\n",
      "n_neighbors: 8, weights: uniform, metric: euclidean, rmse: 207.55790586693868\n",
      "n_neighbors: 9, weights: uniform, metric: euclidean, rmse: 206.62547444774023\n",
      "n_neighbors: 10, weights: uniform, metric: euclidean, rmse: 206.2216306937337\n",
      "n_neighbors: 11, weights: uniform, metric: euclidean, rmse: 205.8324225384652\n",
      "n_neighbors: 12, weights: uniform, metric: euclidean, rmse: 205.3943810685392\n",
      "n_neighbors: 13, weights: uniform, metric: euclidean, rmse: 204.76000803219557\n",
      "n_neighbors: 14, weights: uniform, metric: euclidean, rmse: 204.51733670976918\n",
      "n_neighbors: 15, weights: uniform, metric: euclidean, rmse: 204.5588026998038\n",
      "n_neighbors: 16, weights: uniform, metric: euclidean, rmse: 204.39435131029654\n",
      "n_neighbors: 17, weights: uniform, metric: euclidean, rmse: 204.40299183429823\n",
      "n_neighbors: 18, weights: uniform, metric: euclidean, rmse: 204.07337868142528\n",
      "n_neighbors: 19, weights: uniform, metric: euclidean, rmse: 204.08709233901948\n",
      "n_neighbors: 20, weights: uniform, metric: euclidean, rmse: 204.13312737767976\n",
      "n_neighbors: 21, weights: uniform, metric: euclidean, rmse: 204.14236349807808\n",
      "n_neighbors: 22, weights: uniform, metric: euclidean, rmse: 204.2246659381826\n",
      "n_neighbors: 23, weights: uniform, metric: euclidean, rmse: 204.29262944527818\n",
      "n_neighbors: 24, weights: uniform, metric: euclidean, rmse: 203.8462872372818\n",
      "n_neighbors: 25, weights: uniform, metric: euclidean, rmse: 203.83303767890604\n",
      "n_neighbors: 26, weights: uniform, metric: euclidean, rmse: 203.75761193023456\n",
      "n_neighbors: 27, weights: uniform, metric: euclidean, rmse: 203.76467508315804\n",
      "n_neighbors: 28, weights: uniform, metric: euclidean, rmse: 203.70678611360995\n",
      "n_neighbors: 29, weights: uniform, metric: euclidean, rmse: 203.74485902925773\n",
      "n_neighbors: 30, weights: uniform, metric: euclidean, rmse: 203.79857715678054\n",
      "n_neighbors: 31, weights: uniform, metric: euclidean, rmse: 203.95016973199918\n",
      "n_neighbors: 32, weights: uniform, metric: euclidean, rmse: 204.16330562300342\n",
      "n_neighbors: 33, weights: uniform, metric: euclidean, rmse: 204.32955397451192\n",
      "n_neighbors: 34, weights: uniform, metric: euclidean, rmse: 204.28358957225268\n",
      "n_neighbors: 35, weights: uniform, metric: euclidean, rmse: 204.28504740470635\n",
      "n_neighbors: 36, weights: uniform, metric: euclidean, rmse: 204.36978990474114\n",
      "n_neighbors: 37, weights: uniform, metric: euclidean, rmse: 204.39340717680187\n",
      "n_neighbors: 38, weights: uniform, metric: euclidean, rmse: 204.4547755386817\n",
      "n_neighbors: 39, weights: uniform, metric: euclidean, rmse: 204.46526461486877\n",
      "n_neighbors: 40, weights: uniform, metric: euclidean, rmse: 204.5776727934775\n",
      "n_neighbors: 41, weights: uniform, metric: euclidean, rmse: 204.63071312346375\n",
      "n_neighbors: 42, weights: uniform, metric: euclidean, rmse: 204.61895638613706\n",
      "n_neighbors: 43, weights: uniform, metric: euclidean, rmse: 204.65463552606482\n",
      "n_neighbors: 44, weights: uniform, metric: euclidean, rmse: 204.72532035148737\n",
      "n_neighbors: 45, weights: uniform, metric: euclidean, rmse: 204.68424661996394\n",
      "n_neighbors: 46, weights: uniform, metric: euclidean, rmse: 204.7159707114586\n",
      "n_neighbors: 47, weights: uniform, metric: euclidean, rmse: 204.71136960808784\n",
      "n_neighbors: 48, weights: uniform, metric: euclidean, rmse: 204.73928581923317\n",
      "n_neighbors: 49, weights: uniform, metric: euclidean, rmse: 204.75097309769916\n",
      "n_neighbors: 50, weights: uniform, metric: euclidean, rmse: 204.78909681612228\n",
      "n_neighbors: 51, weights: uniform, metric: euclidean, rmse: 204.81508697152023\n",
      "n_neighbors: 52, weights: uniform, metric: euclidean, rmse: 204.83422196731456\n",
      "n_neighbors: 53, weights: uniform, metric: euclidean, rmse: 204.86976425478278\n",
      "n_neighbors: 54, weights: uniform, metric: euclidean, rmse: 204.8583012490568\n",
      "n_neighbors: 55, weights: uniform, metric: euclidean, rmse: 204.82746574772366\n",
      "n_neighbors: 56, weights: uniform, metric: euclidean, rmse: 204.76694642331606\n",
      "n_neighbors: 57, weights: uniform, metric: euclidean, rmse: 204.78803853195402\n",
      "n_neighbors: 58, weights: uniform, metric: euclidean, rmse: 204.80669096217036\n",
      "n_neighbors: 59, weights: uniform, metric: euclidean, rmse: 204.8522572720368\n",
      "n_neighbors: 60, weights: uniform, metric: euclidean, rmse: 204.90269089364094\n",
      "n_neighbors: 61, weights: uniform, metric: euclidean, rmse: 204.91467108418226\n",
      "n_neighbors: 62, weights: uniform, metric: euclidean, rmse: 204.92689775779147\n",
      "n_neighbors: 63, weights: uniform, metric: euclidean, rmse: 204.9746060147675\n",
      "n_neighbors: 64, weights: uniform, metric: euclidean, rmse: 204.96554786831572\n",
      "n_neighbors: 65, weights: uniform, metric: euclidean, rmse: 205.0108473375083\n",
      "n_neighbors: 66, weights: uniform, metric: euclidean, rmse: 205.0511150196465\n",
      "n_neighbors: 67, weights: uniform, metric: euclidean, rmse: 205.05211539660706\n",
      "n_neighbors: 68, weights: uniform, metric: euclidean, rmse: 205.0409468461656\n",
      "n_neighbors: 69, weights: uniform, metric: euclidean, rmse: 205.11392911818334\n",
      "n_neighbors: 70, weights: uniform, metric: euclidean, rmse: 205.14541657659768\n",
      "n_neighbors: 71, weights: uniform, metric: euclidean, rmse: 205.1541923944491\n",
      "n_neighbors: 72, weights: uniform, metric: euclidean, rmse: 205.15174115289008\n",
      "n_neighbors: 73, weights: uniform, metric: euclidean, rmse: 205.1468844851374\n",
      "n_neighbors: 74, weights: uniform, metric: euclidean, rmse: 205.1388154180356\n",
      "n_neighbors: 75, weights: uniform, metric: euclidean, rmse: 205.0049808050561\n",
      "n_neighbors: 76, weights: uniform, metric: euclidean, rmse: 205.0019546947035\n",
      "n_neighbors: 77, weights: uniform, metric: euclidean, rmse: 205.0158064860949\n",
      "n_neighbors: 78, weights: uniform, metric: euclidean, rmse: 205.0363964365334\n",
      "n_neighbors: 79, weights: uniform, metric: euclidean, rmse: 205.01819242429914\n",
      "n_neighbors: 80, weights: uniform, metric: euclidean, rmse: 205.0487968027735\n",
      "n_neighbors: 81, weights: uniform, metric: euclidean, rmse: 205.08612304224033\n",
      "n_neighbors: 82, weights: uniform, metric: euclidean, rmse: 205.10789779516378\n",
      "n_neighbors: 83, weights: uniform, metric: euclidean, rmse: 205.092799190498\n",
      "n_neighbors: 84, weights: uniform, metric: euclidean, rmse: 205.10476816255553\n",
      "n_neighbors: 85, weights: uniform, metric: euclidean, rmse: 205.10451520109822\n",
      "n_neighbors: 86, weights: uniform, metric: euclidean, rmse: 205.1057890683811\n",
      "n_neighbors: 87, weights: uniform, metric: euclidean, rmse: 205.12762664196583\n",
      "n_neighbors: 88, weights: uniform, metric: euclidean, rmse: 205.1177464312438\n",
      "n_neighbors: 89, weights: uniform, metric: euclidean, rmse: 205.12986636549195\n",
      "n_neighbors: 90, weights: uniform, metric: euclidean, rmse: 205.08360527634775\n",
      "n_neighbors: 91, weights: uniform, metric: euclidean, rmse: 205.12045657851334\n",
      "n_neighbors: 92, weights: uniform, metric: euclidean, rmse: 205.14155871298306\n",
      "n_neighbors: 93, weights: uniform, metric: euclidean, rmse: 205.18664278936146\n",
      "n_neighbors: 94, weights: uniform, metric: euclidean, rmse: 205.1905526266955\n",
      "n_neighbors: 95, weights: uniform, metric: euclidean, rmse: 205.18442169741354\n",
      "n_neighbors: 96, weights: uniform, metric: euclidean, rmse: 205.21832019035335\n",
      "n_neighbors: 97, weights: uniform, metric: euclidean, rmse: 205.21920015390143\n",
      "n_neighbors: 98, weights: uniform, metric: euclidean, rmse: 205.2643905341088\n",
      "n_neighbors: 99, weights: uniform, metric: euclidean, rmse: 205.2578498992401\n",
      "n_neighbors: 100, weights: uniform, metric: euclidean, rmse: 205.27646223814386\n",
      "n_neighbors: 101, weights: uniform, metric: euclidean, rmse: 205.28110428713427\n",
      "n_neighbors: 102, weights: uniform, metric: euclidean, rmse: 205.3022667526864\n",
      "n_neighbors: 103, weights: uniform, metric: euclidean, rmse: 205.31195606825057\n",
      "n_neighbors: 104, weights: uniform, metric: euclidean, rmse: 205.32176110160233\n",
      "n_neighbors: 105, weights: uniform, metric: euclidean, rmse: 205.34582080824916\n",
      "n_neighbors: 106, weights: uniform, metric: euclidean, rmse: 205.37502009152942\n",
      "n_neighbors: 107, weights: uniform, metric: euclidean, rmse: 205.410610565454\n",
      "n_neighbors: 108, weights: uniform, metric: euclidean, rmse: 205.43384607329602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 109, weights: uniform, metric: euclidean, rmse: 205.4543725292271\n",
      "n_neighbors: 110, weights: uniform, metric: euclidean, rmse: 205.44352049359756\n",
      "n_neighbors: 111, weights: uniform, metric: euclidean, rmse: 205.46287731384743\n",
      "n_neighbors: 112, weights: uniform, metric: euclidean, rmse: 205.490766195821\n",
      "n_neighbors: 113, weights: uniform, metric: euclidean, rmse: 205.51447434980406\n",
      "n_neighbors: 114, weights: uniform, metric: euclidean, rmse: 205.54326291875964\n",
      "n_neighbors: 115, weights: uniform, metric: euclidean, rmse: 205.5729563148955\n",
      "n_neighbors: 116, weights: uniform, metric: euclidean, rmse: 205.60584838019125\n",
      "n_neighbors: 117, weights: uniform, metric: euclidean, rmse: 205.63869777321327\n",
      "n_neighbors: 118, weights: uniform, metric: euclidean, rmse: 205.6440202340814\n",
      "n_neighbors: 119, weights: uniform, metric: euclidean, rmse: 205.62615018761102\n",
      "n_neighbors: 120, weights: uniform, metric: euclidean, rmse: 205.64232206176086\n",
      "n_neighbors: 121, weights: uniform, metric: euclidean, rmse: 205.6528060697509\n",
      "n_neighbors: 122, weights: uniform, metric: euclidean, rmse: 205.64817148163235\n",
      "n_neighbors: 123, weights: uniform, metric: euclidean, rmse: 205.66214367391092\n",
      "n_neighbors: 124, weights: uniform, metric: euclidean, rmse: 205.66961003160662\n",
      "n_neighbors: 125, weights: uniform, metric: euclidean, rmse: 205.67316988677408\n",
      "n_neighbors: 126, weights: uniform, metric: euclidean, rmse: 205.66584645719604\n",
      "n_neighbors: 127, weights: uniform, metric: euclidean, rmse: 205.6508787986282\n",
      "n_neighbors: 128, weights: uniform, metric: euclidean, rmse: 205.65581027645058\n",
      "n_neighbors: 129, weights: uniform, metric: euclidean, rmse: 205.66762822186826\n",
      "n_neighbors: 130, weights: uniform, metric: euclidean, rmse: 205.6791399050174\n",
      "n_neighbors: 131, weights: uniform, metric: euclidean, rmse: 205.68146891831893\n",
      "n_neighbors: 132, weights: uniform, metric: euclidean, rmse: 205.7099632666763\n",
      "n_neighbors: 133, weights: uniform, metric: euclidean, rmse: 205.72370903023855\n",
      "n_neighbors: 134, weights: uniform, metric: euclidean, rmse: 205.74249258799603\n",
      "n_neighbors: 135, weights: uniform, metric: euclidean, rmse: 205.75604267226083\n",
      "n_neighbors: 136, weights: uniform, metric: euclidean, rmse: 205.7801774494785\n",
      "n_neighbors: 137, weights: uniform, metric: euclidean, rmse: 205.81378560107544\n",
      "n_neighbors: 138, weights: uniform, metric: euclidean, rmse: 205.8128994751681\n",
      "n_neighbors: 139, weights: uniform, metric: euclidean, rmse: 205.80117860124025\n",
      "n_neighbors: 140, weights: uniform, metric: euclidean, rmse: 205.82550485475278\n",
      "n_neighbors: 141, weights: uniform, metric: euclidean, rmse: 205.80413899619785\n",
      "n_neighbors: 142, weights: uniform, metric: euclidean, rmse: 205.82271878667223\n",
      "n_neighbors: 143, weights: uniform, metric: euclidean, rmse: 205.82076782754572\n",
      "n_neighbors: 144, weights: uniform, metric: euclidean, rmse: 205.8326090788979\n",
      "n_neighbors: 145, weights: uniform, metric: euclidean, rmse: 205.83454734192262\n",
      "n_neighbors: 146, weights: uniform, metric: euclidean, rmse: 205.8377753960147\n",
      "n_neighbors: 147, weights: uniform, metric: euclidean, rmse: 205.8333512370349\n",
      "n_neighbors: 148, weights: uniform, metric: euclidean, rmse: 205.84148770301928\n",
      "n_neighbors: 149, weights: uniform, metric: euclidean, rmse: 205.85853564906444\n",
      "n_neighbors: 150, weights: uniform, metric: euclidean, rmse: 205.88082467690185\n",
      "n_neighbors: 151, weights: uniform, metric: euclidean, rmse: 205.88923194116703\n",
      "n_neighbors: 152, weights: uniform, metric: euclidean, rmse: 205.8875431647547\n",
      "n_neighbors: 153, weights: uniform, metric: euclidean, rmse: 205.89690894461506\n",
      "n_neighbors: 154, weights: uniform, metric: euclidean, rmse: 205.80681020247042\n",
      "n_neighbors: 155, weights: uniform, metric: euclidean, rmse: 205.82014339606678\n",
      "n_neighbors: 156, weights: uniform, metric: euclidean, rmse: 205.83533900849636\n",
      "n_neighbors: 157, weights: uniform, metric: euclidean, rmse: 205.82679505874526\n",
      "n_neighbors: 158, weights: uniform, metric: euclidean, rmse: 205.8338974981366\n",
      "n_neighbors: 159, weights: uniform, metric: euclidean, rmse: 205.83922876095386\n",
      "n_neighbors: 160, weights: uniform, metric: euclidean, rmse: 205.8390364200176\n",
      "n_neighbors: 161, weights: uniform, metric: euclidean, rmse: 205.8402412487904\n",
      "n_neighbors: 162, weights: uniform, metric: euclidean, rmse: 205.8476473325787\n",
      "n_neighbors: 163, weights: uniform, metric: euclidean, rmse: 205.8626135068628\n",
      "n_neighbors: 164, weights: uniform, metric: euclidean, rmse: 205.88500178629235\n",
      "n_neighbors: 165, weights: uniform, metric: euclidean, rmse: 205.9035963858461\n",
      "n_neighbors: 166, weights: uniform, metric: euclidean, rmse: 205.9084140530408\n",
      "n_neighbors: 167, weights: uniform, metric: euclidean, rmse: 205.92242655201787\n",
      "n_neighbors: 168, weights: uniform, metric: euclidean, rmse: 205.91161324109547\n",
      "n_neighbors: 169, weights: uniform, metric: euclidean, rmse: 205.9198640377234\n",
      "n_neighbors: 170, weights: uniform, metric: euclidean, rmse: 205.94193285251535\n",
      "n_neighbors: 171, weights: uniform, metric: euclidean, rmse: 205.9683440314683\n",
      "n_neighbors: 172, weights: uniform, metric: euclidean, rmse: 205.9786830653194\n",
      "n_neighbors: 173, weights: uniform, metric: euclidean, rmse: 205.99489353826044\n",
      "n_neighbors: 174, weights: uniform, metric: euclidean, rmse: 206.00386366550302\n",
      "n_neighbors: 175, weights: uniform, metric: euclidean, rmse: 206.02755546540865\n",
      "n_neighbors: 176, weights: uniform, metric: euclidean, rmse: 206.03464832715142\n",
      "n_neighbors: 177, weights: uniform, metric: euclidean, rmse: 206.0289649292968\n",
      "n_neighbors: 178, weights: uniform, metric: euclidean, rmse: 206.0406451566721\n",
      "n_neighbors: 179, weights: uniform, metric: euclidean, rmse: 206.0489124585077\n",
      "n_neighbors: 180, weights: uniform, metric: euclidean, rmse: 206.0567531449508\n",
      "n_neighbors: 181, weights: uniform, metric: euclidean, rmse: 206.06311754691194\n",
      "n_neighbors: 182, weights: uniform, metric: euclidean, rmse: 206.08171892358445\n",
      "n_neighbors: 183, weights: uniform, metric: euclidean, rmse: 206.0808808927255\n",
      "n_neighbors: 184, weights: uniform, metric: euclidean, rmse: 206.0722573540716\n",
      "n_neighbors: 185, weights: uniform, metric: euclidean, rmse: 205.96461240073782\n",
      "n_neighbors: 186, weights: uniform, metric: euclidean, rmse: 205.97887740430093\n",
      "n_neighbors: 187, weights: uniform, metric: euclidean, rmse: 205.99328752745444\n",
      "n_neighbors: 188, weights: uniform, metric: euclidean, rmse: 205.99249343836163\n",
      "n_neighbors: 189, weights: uniform, metric: euclidean, rmse: 205.99042347271754\n",
      "n_neighbors: 190, weights: uniform, metric: euclidean, rmse: 205.99027470208478\n",
      "n_neighbors: 191, weights: uniform, metric: euclidean, rmse: 205.99053433296385\n",
      "n_neighbors: 192, weights: uniform, metric: euclidean, rmse: 206.00110780068925\n",
      "n_neighbors: 193, weights: uniform, metric: euclidean, rmse: 205.99278645362887\n",
      "n_neighbors: 194, weights: uniform, metric: euclidean, rmse: 205.98937287594552\n",
      "n_neighbors: 195, weights: uniform, metric: euclidean, rmse: 205.99057970811862\n",
      "n_neighbors: 196, weights: uniform, metric: euclidean, rmse: 206.0114245751509\n",
      "n_neighbors: 197, weights: uniform, metric: euclidean, rmse: 206.02520772626175\n",
      "n_neighbors: 198, weights: uniform, metric: euclidean, rmse: 205.99473928658315\n",
      "n_neighbors: 199, weights: uniform, metric: euclidean, rmse: 206.01607127710025\n",
      "n_neighbors: 3, weights: distance, metric: euclidean, rmse: 234.04498759728202\n",
      "n_neighbors: 4, weights: distance, metric: euclidean, rmse: 223.54327941104677\n",
      "n_neighbors: 5, weights: distance, metric: euclidean, rmse: 217.0762710998818\n",
      "n_neighbors: 6, weights: distance, metric: euclidean, rmse: 211.73784326225126\n",
      "n_neighbors: 7, weights: distance, metric: euclidean, rmse: 208.7052014283514\n",
      "n_neighbors: 8, weights: distance, metric: euclidean, rmse: 206.22938627355532\n",
      "n_neighbors: 9, weights: distance, metric: euclidean, rmse: 205.25635252280702\n",
      "n_neighbors: 10, weights: distance, metric: euclidean, rmse: 204.78021601615822\n",
      "n_neighbors: 11, weights: distance, metric: euclidean, rmse: 204.35511179033315\n",
      "n_neighbors: 12, weights: distance, metric: euclidean, rmse: 203.8558746607999\n",
      "n_neighbors: 13, weights: distance, metric: euclidean, rmse: 203.23654253436962\n",
      "n_neighbors: 14, weights: distance, metric: euclidean, rmse: 202.99189454151028\n",
      "n_neighbors: 15, weights: distance, metric: euclidean, rmse: 202.9525473504612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 16, weights: distance, metric: euclidean, rmse: 202.77508953794543\n",
      "n_neighbors: 17, weights: distance, metric: euclidean, rmse: 202.78732499935884\n",
      "n_neighbors: 18, weights: distance, metric: euclidean, rmse: 202.45203270006883\n",
      "n_neighbors: 19, weights: distance, metric: euclidean, rmse: 202.44671995388165\n",
      "n_neighbors: 20, weights: distance, metric: euclidean, rmse: 202.50370153770166\n",
      "n_neighbors: 21, weights: distance, metric: euclidean, rmse: 202.5188465098116\n",
      "n_neighbors: 22, weights: distance, metric: euclidean, rmse: 202.58416898876288\n",
      "n_neighbors: 23, weights: distance, metric: euclidean, rmse: 202.6552898737864\n",
      "n_neighbors: 24, weights: distance, metric: euclidean, rmse: 202.22807992273164\n",
      "n_neighbors: 25, weights: distance, metric: euclidean, rmse: 202.21892552021967\n",
      "n_neighbors: 26, weights: distance, metric: euclidean, rmse: 202.14432503512788\n",
      "n_neighbors: 27, weights: distance, metric: euclidean, rmse: 202.15382358665983\n",
      "n_neighbors: 28, weights: distance, metric: euclidean, rmse: 202.10289902236653\n",
      "n_neighbors: 29, weights: distance, metric: euclidean, rmse: 202.14110394092612\n",
      "n_neighbors: 30, weights: distance, metric: euclidean, rmse: 202.1968347360888\n",
      "n_neighbors: 31, weights: distance, metric: euclidean, rmse: 202.34464539437522\n",
      "n_neighbors: 32, weights: distance, metric: euclidean, rmse: 202.54774871087113\n",
      "n_neighbors: 33, weights: distance, metric: euclidean, rmse: 202.71593025740842\n",
      "n_neighbors: 34, weights: distance, metric: euclidean, rmse: 202.67526116376163\n",
      "n_neighbors: 35, weights: distance, metric: euclidean, rmse: 202.66893258100322\n",
      "n_neighbors: 36, weights: distance, metric: euclidean, rmse: 202.73952672294786\n",
      "n_neighbors: 37, weights: distance, metric: euclidean, rmse: 202.7430518506382\n",
      "n_neighbors: 38, weights: distance, metric: euclidean, rmse: 202.78754182309638\n",
      "n_neighbors: 39, weights: distance, metric: euclidean, rmse: 202.79314662420185\n",
      "n_neighbors: 40, weights: distance, metric: euclidean, rmse: 202.88899091858016\n",
      "n_neighbors: 41, weights: distance, metric: euclidean, rmse: 202.92786918670393\n",
      "n_neighbors: 42, weights: distance, metric: euclidean, rmse: 202.91371553655193\n",
      "n_neighbors: 43, weights: distance, metric: euclidean, rmse: 202.9329602865111\n",
      "n_neighbors: 44, weights: distance, metric: euclidean, rmse: 202.97049255148428\n",
      "n_neighbors: 45, weights: distance, metric: euclidean, rmse: 202.9260614240338\n",
      "n_neighbors: 46, weights: distance, metric: euclidean, rmse: 202.9534026674291\n",
      "n_neighbors: 47, weights: distance, metric: euclidean, rmse: 202.94258777089837\n",
      "n_neighbors: 48, weights: distance, metric: euclidean, rmse: 202.96795300170643\n",
      "n_neighbors: 49, weights: distance, metric: euclidean, rmse: 202.97548927475762\n",
      "n_neighbors: 50, weights: distance, metric: euclidean, rmse: 203.00302844502886\n",
      "n_neighbors: 51, weights: distance, metric: euclidean, rmse: 203.01079464571333\n",
      "n_neighbors: 52, weights: distance, metric: euclidean, rmse: 203.01678566839942\n",
      "n_neighbors: 53, weights: distance, metric: euclidean, rmse: 203.05935873659004\n",
      "n_neighbors: 54, weights: distance, metric: euclidean, rmse: 203.05432036633042\n",
      "n_neighbors: 55, weights: distance, metric: euclidean, rmse: 203.0219862056131\n",
      "n_neighbors: 56, weights: distance, metric: euclidean, rmse: 202.9766453447664\n",
      "n_neighbors: 57, weights: distance, metric: euclidean, rmse: 202.99687369478642\n",
      "n_neighbors: 58, weights: distance, metric: euclidean, rmse: 203.03370606606953\n",
      "n_neighbors: 59, weights: distance, metric: euclidean, rmse: 203.07353374265233\n",
      "n_neighbors: 60, weights: distance, metric: euclidean, rmse: 203.1190124614409\n",
      "n_neighbors: 61, weights: distance, metric: euclidean, rmse: 203.12599498199225\n",
      "n_neighbors: 62, weights: distance, metric: euclidean, rmse: 203.13062497120248\n",
      "n_neighbors: 63, weights: distance, metric: euclidean, rmse: 203.17193667264388\n",
      "n_neighbors: 64, weights: distance, metric: euclidean, rmse: 203.16699346953357\n",
      "n_neighbors: 65, weights: distance, metric: euclidean, rmse: 203.21002028728492\n",
      "n_neighbors: 66, weights: distance, metric: euclidean, rmse: 203.24399180335524\n",
      "n_neighbors: 67, weights: distance, metric: euclidean, rmse: 203.24597449064638\n",
      "n_neighbors: 68, weights: distance, metric: euclidean, rmse: 203.22874136998882\n",
      "n_neighbors: 69, weights: distance, metric: euclidean, rmse: 203.3002478491048\n",
      "n_neighbors: 70, weights: distance, metric: euclidean, rmse: 203.32937179254614\n",
      "n_neighbors: 71, weights: distance, metric: euclidean, rmse: 203.3313375858394\n",
      "n_neighbors: 72, weights: distance, metric: euclidean, rmse: 203.32807253456195\n",
      "n_neighbors: 73, weights: distance, metric: euclidean, rmse: 203.32843593535296\n",
      "n_neighbors: 74, weights: distance, metric: euclidean, rmse: 203.32849282342028\n",
      "n_neighbors: 75, weights: distance, metric: euclidean, rmse: 203.19089329098847\n",
      "n_neighbors: 76, weights: distance, metric: euclidean, rmse: 203.1897606406749\n",
      "n_neighbors: 77, weights: distance, metric: euclidean, rmse: 203.20654509791757\n",
      "n_neighbors: 78, weights: distance, metric: euclidean, rmse: 203.22808915443034\n",
      "n_neighbors: 79, weights: distance, metric: euclidean, rmse: 203.20856267568615\n",
      "n_neighbors: 80, weights: distance, metric: euclidean, rmse: 203.22436098723028\n",
      "n_neighbors: 81, weights: distance, metric: euclidean, rmse: 203.25863318666615\n",
      "n_neighbors: 82, weights: distance, metric: euclidean, rmse: 203.27778902176755\n",
      "n_neighbors: 83, weights: distance, metric: euclidean, rmse: 203.26243259481166\n",
      "n_neighbors: 84, weights: distance, metric: euclidean, rmse: 203.27118419486044\n",
      "n_neighbors: 85, weights: distance, metric: euclidean, rmse: 203.27776360813544\n",
      "n_neighbors: 86, weights: distance, metric: euclidean, rmse: 203.28095967629744\n",
      "n_neighbors: 87, weights: distance, metric: euclidean, rmse: 203.29348208380938\n",
      "n_neighbors: 88, weights: distance, metric: euclidean, rmse: 203.27949606060636\n",
      "n_neighbors: 89, weights: distance, metric: euclidean, rmse: 203.29156212206502\n",
      "n_neighbors: 90, weights: distance, metric: euclidean, rmse: 203.26949765887383\n",
      "n_neighbors: 91, weights: distance, metric: euclidean, rmse: 203.3067054689093\n",
      "n_neighbors: 92, weights: distance, metric: euclidean, rmse: 203.33040781700814\n",
      "n_neighbors: 93, weights: distance, metric: euclidean, rmse: 203.36832476949434\n",
      "n_neighbors: 94, weights: distance, metric: euclidean, rmse: 203.3741123782513\n",
      "n_neighbors: 95, weights: distance, metric: euclidean, rmse: 203.37906728114342\n",
      "n_neighbors: 96, weights: distance, metric: euclidean, rmse: 203.41516675480395\n",
      "n_neighbors: 97, weights: distance, metric: euclidean, rmse: 203.4165986912331\n",
      "n_neighbors: 98, weights: distance, metric: euclidean, rmse: 203.45695613787692\n",
      "n_neighbors: 99, weights: distance, metric: euclidean, rmse: 203.45360253832342\n",
      "n_neighbors: 100, weights: distance, metric: euclidean, rmse: 203.46350212294453\n",
      "n_neighbors: 101, weights: distance, metric: euclidean, rmse: 203.4638573016779\n",
      "n_neighbors: 102, weights: distance, metric: euclidean, rmse: 203.48824333626183\n",
      "n_neighbors: 103, weights: distance, metric: euclidean, rmse: 203.50019483547595\n",
      "n_neighbors: 104, weights: distance, metric: euclidean, rmse: 203.50781900841199\n",
      "n_neighbors: 105, weights: distance, metric: euclidean, rmse: 203.53216796578423\n",
      "n_neighbors: 106, weights: distance, metric: euclidean, rmse: 203.55175934317072\n",
      "n_neighbors: 107, weights: distance, metric: euclidean, rmse: 203.58214110629933\n",
      "n_neighbors: 108, weights: distance, metric: euclidean, rmse: 203.59408418460757\n",
      "n_neighbors: 109, weights: distance, metric: euclidean, rmse: 203.60382956175414\n",
      "n_neighbors: 110, weights: distance, metric: euclidean, rmse: 203.5981877491464\n",
      "n_neighbors: 111, weights: distance, metric: euclidean, rmse: 203.6124844408118\n",
      "n_neighbors: 112, weights: distance, metric: euclidean, rmse: 203.63615695271952\n",
      "n_neighbors: 113, weights: distance, metric: euclidean, rmse: 203.65984130996213\n",
      "n_neighbors: 114, weights: distance, metric: euclidean, rmse: 203.68555258119952\n",
      "n_neighbors: 115, weights: distance, metric: euclidean, rmse: 203.7137768780464\n",
      "n_neighbors: 116, weights: distance, metric: euclidean, rmse: 203.74176338537782\n",
      "n_neighbors: 117, weights: distance, metric: euclidean, rmse: 203.77162134827617\n",
      "n_neighbors: 118, weights: distance, metric: euclidean, rmse: 203.7732729682857\n",
      "n_neighbors: 119, weights: distance, metric: euclidean, rmse: 203.76245694423545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 120, weights: distance, metric: euclidean, rmse: 203.77687754033633\n",
      "n_neighbors: 121, weights: distance, metric: euclidean, rmse: 203.78157063876748\n",
      "n_neighbors: 122, weights: distance, metric: euclidean, rmse: 203.77059934974375\n",
      "n_neighbors: 123, weights: distance, metric: euclidean, rmse: 203.78543260424868\n",
      "n_neighbors: 124, weights: distance, metric: euclidean, rmse: 203.79502948888688\n",
      "n_neighbors: 125, weights: distance, metric: euclidean, rmse: 203.79837778171606\n",
      "n_neighbors: 126, weights: distance, metric: euclidean, rmse: 203.80121883116166\n",
      "n_neighbors: 127, weights: distance, metric: euclidean, rmse: 203.78502521990958\n",
      "n_neighbors: 128, weights: distance, metric: euclidean, rmse: 203.78624130786466\n",
      "n_neighbors: 129, weights: distance, metric: euclidean, rmse: 203.78921838268693\n",
      "n_neighbors: 130, weights: distance, metric: euclidean, rmse: 203.80354165210176\n",
      "n_neighbors: 131, weights: distance, metric: euclidean, rmse: 203.81704900616182\n",
      "n_neighbors: 132, weights: distance, metric: euclidean, rmse: 203.84015225443147\n",
      "n_neighbors: 133, weights: distance, metric: euclidean, rmse: 203.85583159432537\n",
      "n_neighbors: 134, weights: distance, metric: euclidean, rmse: 203.8725001117506\n",
      "n_neighbors: 135, weights: distance, metric: euclidean, rmse: 203.8807349229274\n",
      "n_neighbors: 136, weights: distance, metric: euclidean, rmse: 203.8971055054384\n",
      "n_neighbors: 137, weights: distance, metric: euclidean, rmse: 203.92442392390228\n",
      "n_neighbors: 138, weights: distance, metric: euclidean, rmse: 203.91877359493907\n",
      "n_neighbors: 139, weights: distance, metric: euclidean, rmse: 203.90328883813828\n",
      "n_neighbors: 140, weights: distance, metric: euclidean, rmse: 203.92324377784078\n",
      "n_neighbors: 141, weights: distance, metric: euclidean, rmse: 203.89825181222548\n",
      "n_neighbors: 142, weights: distance, metric: euclidean, rmse: 203.91362360567211\n",
      "n_neighbors: 143, weights: distance, metric: euclidean, rmse: 203.91240826083953\n",
      "n_neighbors: 144, weights: distance, metric: euclidean, rmse: 203.9264395041271\n",
      "n_neighbors: 145, weights: distance, metric: euclidean, rmse: 203.92353733143852\n",
      "n_neighbors: 146, weights: distance, metric: euclidean, rmse: 203.93384948130466\n",
      "n_neighbors: 147, weights: distance, metric: euclidean, rmse: 203.92717290404718\n",
      "n_neighbors: 148, weights: distance, metric: euclidean, rmse: 203.92978499308603\n",
      "n_neighbors: 149, weights: distance, metric: euclidean, rmse: 203.94685189855343\n",
      "n_neighbors: 150, weights: distance, metric: euclidean, rmse: 203.96727280290614\n",
      "n_neighbors: 151, weights: distance, metric: euclidean, rmse: 203.97156026577974\n",
      "n_neighbors: 152, weights: distance, metric: euclidean, rmse: 203.96947183805057\n",
      "n_neighbors: 153, weights: distance, metric: euclidean, rmse: 203.9776217355889\n",
      "n_neighbors: 154, weights: distance, metric: euclidean, rmse: 203.89781151183846\n",
      "n_neighbors: 155, weights: distance, metric: euclidean, rmse: 203.9082991358217\n",
      "n_neighbors: 156, weights: distance, metric: euclidean, rmse: 203.92010168125256\n",
      "n_neighbors: 157, weights: distance, metric: euclidean, rmse: 203.92422286119069\n",
      "n_neighbors: 158, weights: distance, metric: euclidean, rmse: 203.92418612873578\n",
      "n_neighbors: 159, weights: distance, metric: euclidean, rmse: 203.92662175200337\n",
      "n_neighbors: 160, weights: distance, metric: euclidean, rmse: 203.92506136534914\n",
      "n_neighbors: 161, weights: distance, metric: euclidean, rmse: 203.92575997153068\n",
      "n_neighbors: 162, weights: distance, metric: euclidean, rmse: 203.93885160844047\n",
      "n_neighbors: 163, weights: distance, metric: euclidean, rmse: 203.94816584837213\n",
      "n_neighbors: 164, weights: distance, metric: euclidean, rmse: 203.96307728118788\n",
      "n_neighbors: 165, weights: distance, metric: euclidean, rmse: 203.97665797984882\n",
      "n_neighbors: 166, weights: distance, metric: euclidean, rmse: 203.97571863871016\n",
      "n_neighbors: 167, weights: distance, metric: euclidean, rmse: 203.9832262897862\n",
      "n_neighbors: 168, weights: distance, metric: euclidean, rmse: 203.96707268552163\n",
      "n_neighbors: 169, weights: distance, metric: euclidean, rmse: 203.98195222036586\n",
      "n_neighbors: 170, weights: distance, metric: euclidean, rmse: 204.0022680069827\n",
      "n_neighbors: 171, weights: distance, metric: euclidean, rmse: 204.02085989792417\n",
      "n_neighbors: 172, weights: distance, metric: euclidean, rmse: 204.0321521791345\n",
      "n_neighbors: 173, weights: distance, metric: euclidean, rmse: 204.04182898078545\n",
      "n_neighbors: 174, weights: distance, metric: euclidean, rmse: 204.0438987472821\n",
      "n_neighbors: 175, weights: distance, metric: euclidean, rmse: 204.05902771078357\n",
      "n_neighbors: 176, weights: distance, metric: euclidean, rmse: 204.0525262733359\n",
      "n_neighbors: 177, weights: distance, metric: euclidean, rmse: 204.05589317054842\n",
      "n_neighbors: 178, weights: distance, metric: euclidean, rmse: 204.06929154896997\n",
      "n_neighbors: 179, weights: distance, metric: euclidean, rmse: 204.07325008438298\n",
      "n_neighbors: 180, weights: distance, metric: euclidean, rmse: 204.08385481304867\n",
      "n_neighbors: 181, weights: distance, metric: euclidean, rmse: 204.0859814932889\n",
      "n_neighbors: 182, weights: distance, metric: euclidean, rmse: 204.1010091133176\n",
      "n_neighbors: 183, weights: distance, metric: euclidean, rmse: 204.1022537682294\n",
      "n_neighbors: 184, weights: distance, metric: euclidean, rmse: 204.09239409033893\n",
      "n_neighbors: 185, weights: distance, metric: euclidean, rmse: 203.99932923903847\n",
      "n_neighbors: 186, weights: distance, metric: euclidean, rmse: 204.00939898107112\n",
      "n_neighbors: 187, weights: distance, metric: euclidean, rmse: 204.01340929775932\n",
      "n_neighbors: 188, weights: distance, metric: euclidean, rmse: 204.00813297051673\n",
      "n_neighbors: 189, weights: distance, metric: euclidean, rmse: 204.01008770101632\n",
      "n_neighbors: 190, weights: distance, metric: euclidean, rmse: 204.00585721256078\n",
      "n_neighbors: 191, weights: distance, metric: euclidean, rmse: 204.0042876574176\n",
      "n_neighbors: 192, weights: distance, metric: euclidean, rmse: 204.01334131527622\n",
      "n_neighbors: 193, weights: distance, metric: euclidean, rmse: 204.0159786629646\n",
      "n_neighbors: 194, weights: distance, metric: euclidean, rmse: 204.01801071282165\n",
      "n_neighbors: 195, weights: distance, metric: euclidean, rmse: 204.01616556369794\n",
      "n_neighbors: 196, weights: distance, metric: euclidean, rmse: 204.0352182166053\n",
      "n_neighbors: 197, weights: distance, metric: euclidean, rmse: 204.0462862288047\n",
      "n_neighbors: 198, weights: distance, metric: euclidean, rmse: 204.012318361222\n",
      "n_neighbors: 199, weights: distance, metric: euclidean, rmse: 204.02994282109546\n",
      "n_neighbors: 3, weights: uniform, metric: cosine, rmse: 234.98093510936152\n",
      "n_neighbors: 4, weights: uniform, metric: cosine, rmse: 224.37815049986423\n",
      "n_neighbors: 5, weights: uniform, metric: cosine, rmse: 218.51492049569967\n",
      "n_neighbors: 6, weights: uniform, metric: cosine, rmse: 213.39605787290978\n",
      "n_neighbors: 7, weights: uniform, metric: cosine, rmse: 210.24488995925847\n",
      "n_neighbors: 8, weights: uniform, metric: cosine, rmse: 208.5046942496933\n",
      "n_neighbors: 9, weights: uniform, metric: cosine, rmse: 207.4005432649763\n",
      "n_neighbors: 10, weights: uniform, metric: cosine, rmse: 206.847904272872\n",
      "n_neighbors: 11, weights: uniform, metric: cosine, rmse: 206.3490454236287\n",
      "n_neighbors: 12, weights: uniform, metric: cosine, rmse: 205.47374321185512\n",
      "n_neighbors: 13, weights: uniform, metric: cosine, rmse: 204.810321054871\n",
      "n_neighbors: 14, weights: uniform, metric: cosine, rmse: 204.6608707488477\n",
      "n_neighbors: 15, weights: uniform, metric: cosine, rmse: 204.52742657765916\n",
      "n_neighbors: 16, weights: uniform, metric: cosine, rmse: 204.3205361398895\n",
      "n_neighbors: 17, weights: uniform, metric: cosine, rmse: 203.83417292517623\n",
      "n_neighbors: 18, weights: uniform, metric: cosine, rmse: 204.06540934854436\n",
      "n_neighbors: 19, weights: uniform, metric: cosine, rmse: 204.0979294464488\n",
      "n_neighbors: 20, weights: uniform, metric: cosine, rmse: 204.10617919849125\n",
      "n_neighbors: 21, weights: uniform, metric: cosine, rmse: 204.20920550727934\n",
      "n_neighbors: 22, weights: uniform, metric: cosine, rmse: 204.28655295901643\n",
      "n_neighbors: 23, weights: uniform, metric: cosine, rmse: 204.2968285698249\n",
      "n_neighbors: 24, weights: uniform, metric: cosine, rmse: 203.8281529775897\n",
      "n_neighbors: 25, weights: uniform, metric: cosine, rmse: 203.58478851947123\n",
      "n_neighbors: 26, weights: uniform, metric: cosine, rmse: 203.47204892759524\n",
      "n_neighbors: 27, weights: uniform, metric: cosine, rmse: 203.48563684215688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 28, weights: uniform, metric: cosine, rmse: 203.49880006573534\n",
      "n_neighbors: 29, weights: uniform, metric: cosine, rmse: 203.61076793180175\n",
      "n_neighbors: 30, weights: uniform, metric: cosine, rmse: 203.67742308172274\n",
      "n_neighbors: 31, weights: uniform, metric: cosine, rmse: 203.84432824342662\n",
      "n_neighbors: 32, weights: uniform, metric: cosine, rmse: 203.9996046813358\n",
      "n_neighbors: 33, weights: uniform, metric: cosine, rmse: 204.140849532479\n",
      "n_neighbors: 34, weights: uniform, metric: cosine, rmse: 204.06807666046495\n",
      "n_neighbors: 35, weights: uniform, metric: cosine, rmse: 204.05640910603802\n",
      "n_neighbors: 36, weights: uniform, metric: cosine, rmse: 204.11245071240887\n",
      "n_neighbors: 37, weights: uniform, metric: cosine, rmse: 204.10022114757663\n",
      "n_neighbors: 38, weights: uniform, metric: cosine, rmse: 204.1481602466109\n",
      "n_neighbors: 39, weights: uniform, metric: cosine, rmse: 204.16092689859144\n",
      "n_neighbors: 40, weights: uniform, metric: cosine, rmse: 204.2379947007996\n",
      "n_neighbors: 41, weights: uniform, metric: cosine, rmse: 204.29883461984792\n",
      "n_neighbors: 42, weights: uniform, metric: cosine, rmse: 204.31738943590827\n",
      "n_neighbors: 43, weights: uniform, metric: cosine, rmse: 204.3642401142392\n",
      "n_neighbors: 44, weights: uniform, metric: cosine, rmse: 204.49778138578833\n",
      "n_neighbors: 45, weights: uniform, metric: cosine, rmse: 204.44978653612486\n",
      "n_neighbors: 46, weights: uniform, metric: cosine, rmse: 204.49826751988408\n",
      "n_neighbors: 47, weights: uniform, metric: cosine, rmse: 204.48763620245072\n",
      "n_neighbors: 48, weights: uniform, metric: cosine, rmse: 204.52709629980973\n",
      "n_neighbors: 49, weights: uniform, metric: cosine, rmse: 204.5479226162196\n",
      "n_neighbors: 50, weights: uniform, metric: cosine, rmse: 204.5834953181099\n",
      "n_neighbors: 51, weights: uniform, metric: cosine, rmse: 204.62262336031424\n",
      "n_neighbors: 52, weights: uniform, metric: cosine, rmse: 204.61688993238045\n",
      "n_neighbors: 53, weights: uniform, metric: cosine, rmse: 204.64372746916004\n",
      "n_neighbors: 54, weights: uniform, metric: cosine, rmse: 204.62448926076084\n",
      "n_neighbors: 55, weights: uniform, metric: cosine, rmse: 204.6177298567546\n",
      "n_neighbors: 56, weights: uniform, metric: cosine, rmse: 204.58906496501723\n",
      "n_neighbors: 57, weights: uniform, metric: cosine, rmse: 204.60249896786794\n",
      "n_neighbors: 58, weights: uniform, metric: cosine, rmse: 204.62088611556132\n",
      "n_neighbors: 59, weights: uniform, metric: cosine, rmse: 204.63598898101927\n",
      "n_neighbors: 60, weights: uniform, metric: cosine, rmse: 204.65972738888217\n",
      "n_neighbors: 61, weights: uniform, metric: cosine, rmse: 204.6729835189244\n",
      "n_neighbors: 62, weights: uniform, metric: cosine, rmse: 204.65177856276796\n",
      "n_neighbors: 63, weights: uniform, metric: cosine, rmse: 204.6883735339863\n",
      "n_neighbors: 64, weights: uniform, metric: cosine, rmse: 204.71628364967316\n",
      "n_neighbors: 65, weights: uniform, metric: cosine, rmse: 204.7589770630101\n",
      "n_neighbors: 66, weights: uniform, metric: cosine, rmse: 204.81384540524917\n",
      "n_neighbors: 67, weights: uniform, metric: cosine, rmse: 204.8236765872707\n",
      "n_neighbors: 68, weights: uniform, metric: cosine, rmse: 204.81012171693433\n",
      "n_neighbors: 69, weights: uniform, metric: cosine, rmse: 204.8994033946871\n",
      "n_neighbors: 70, weights: uniform, metric: cosine, rmse: 204.91745014376522\n",
      "n_neighbors: 71, weights: uniform, metric: cosine, rmse: 204.94679366272743\n",
      "n_neighbors: 72, weights: uniform, metric: cosine, rmse: 204.95423096403567\n",
      "n_neighbors: 73, weights: uniform, metric: cosine, rmse: 204.98631279125837\n",
      "n_neighbors: 74, weights: uniform, metric: cosine, rmse: 204.9822119459982\n",
      "n_neighbors: 75, weights: uniform, metric: cosine, rmse: 205.0092578093853\n",
      "n_neighbors: 76, weights: uniform, metric: cosine, rmse: 205.00261130210868\n",
      "n_neighbors: 77, weights: uniform, metric: cosine, rmse: 205.0474659828638\n",
      "n_neighbors: 78, weights: uniform, metric: cosine, rmse: 205.0868097324008\n",
      "n_neighbors: 79, weights: uniform, metric: cosine, rmse: 205.07417935677313\n",
      "n_neighbors: 80, weights: uniform, metric: cosine, rmse: 205.07635920309008\n",
      "n_neighbors: 81, weights: uniform, metric: cosine, rmse: 205.0044837794994\n",
      "n_neighbors: 82, weights: uniform, metric: cosine, rmse: 205.02660580639883\n",
      "n_neighbors: 83, weights: uniform, metric: cosine, rmse: 205.05154094315614\n",
      "n_neighbors: 84, weights: uniform, metric: cosine, rmse: 205.0850386965235\n",
      "n_neighbors: 85, weights: uniform, metric: cosine, rmse: 205.09737360223187\n",
      "n_neighbors: 86, weights: uniform, metric: cosine, rmse: 205.12688335056447\n",
      "n_neighbors: 87, weights: uniform, metric: cosine, rmse: 205.13830190069694\n",
      "n_neighbors: 88, weights: uniform, metric: cosine, rmse: 205.11417296464822\n",
      "n_neighbors: 89, weights: uniform, metric: cosine, rmse: 205.13523137053016\n",
      "n_neighbors: 90, weights: uniform, metric: cosine, rmse: 205.18341629680103\n",
      "n_neighbors: 91, weights: uniform, metric: cosine, rmse: 205.17670435490132\n",
      "n_neighbors: 92, weights: uniform, metric: cosine, rmse: 205.21114851824015\n",
      "n_neighbors: 93, weights: uniform, metric: cosine, rmse: 205.25699222269907\n",
      "n_neighbors: 94, weights: uniform, metric: cosine, rmse: 205.26371168470223\n",
      "n_neighbors: 95, weights: uniform, metric: cosine, rmse: 205.2837933770243\n",
      "n_neighbors: 96, weights: uniform, metric: cosine, rmse: 205.26918760563922\n",
      "n_neighbors: 97, weights: uniform, metric: cosine, rmse: 205.29561118355656\n",
      "n_neighbors: 98, weights: uniform, metric: cosine, rmse: 205.29938143919836\n",
      "n_neighbors: 99, weights: uniform, metric: cosine, rmse: 205.28593640448813\n",
      "n_neighbors: 100, weights: uniform, metric: cosine, rmse: 205.3019114767714\n",
      "n_neighbors: 101, weights: uniform, metric: cosine, rmse: 205.30863226114857\n",
      "n_neighbors: 102, weights: uniform, metric: cosine, rmse: 205.3243285560899\n",
      "n_neighbors: 103, weights: uniform, metric: cosine, rmse: 205.3460604211528\n",
      "n_neighbors: 104, weights: uniform, metric: cosine, rmse: 205.35644547438795\n",
      "n_neighbors: 105, weights: uniform, metric: cosine, rmse: 205.362497985042\n",
      "n_neighbors: 106, weights: uniform, metric: cosine, rmse: 205.40198039422316\n",
      "n_neighbors: 107, weights: uniform, metric: cosine, rmse: 205.42999435346758\n",
      "n_neighbors: 108, weights: uniform, metric: cosine, rmse: 205.4471054663371\n",
      "n_neighbors: 109, weights: uniform, metric: cosine, rmse: 205.47026730710863\n",
      "n_neighbors: 110, weights: uniform, metric: cosine, rmse: 205.47787958175314\n",
      "n_neighbors: 111, weights: uniform, metric: cosine, rmse: 205.46922408573508\n",
      "n_neighbors: 112, weights: uniform, metric: cosine, rmse: 205.50524030250617\n",
      "n_neighbors: 113, weights: uniform, metric: cosine, rmse: 205.53007011337056\n",
      "n_neighbors: 114, weights: uniform, metric: cosine, rmse: 205.55784121841717\n",
      "n_neighbors: 115, weights: uniform, metric: cosine, rmse: 205.55031635178753\n",
      "n_neighbors: 116, weights: uniform, metric: cosine, rmse: 205.56207036295402\n",
      "n_neighbors: 117, weights: uniform, metric: cosine, rmse: 205.57767993833556\n",
      "n_neighbors: 118, weights: uniform, metric: cosine, rmse: 205.59166992548307\n",
      "n_neighbors: 119, weights: uniform, metric: cosine, rmse: 205.60502809243516\n",
      "n_neighbors: 120, weights: uniform, metric: cosine, rmse: 205.63453436606707\n",
      "n_neighbors: 121, weights: uniform, metric: cosine, rmse: 205.65125866192136\n",
      "n_neighbors: 122, weights: uniform, metric: cosine, rmse: 205.64035640393956\n",
      "n_neighbors: 123, weights: uniform, metric: cosine, rmse: 205.65487825362217\n",
      "n_neighbors: 124, weights: uniform, metric: cosine, rmse: 205.6638128667147\n",
      "n_neighbors: 125, weights: uniform, metric: cosine, rmse: 205.67524104298866\n",
      "n_neighbors: 126, weights: uniform, metric: cosine, rmse: 205.68471417497645\n",
      "n_neighbors: 127, weights: uniform, metric: cosine, rmse: 205.68131821883316\n",
      "n_neighbors: 128, weights: uniform, metric: cosine, rmse: 205.70526199142716\n",
      "n_neighbors: 129, weights: uniform, metric: cosine, rmse: 205.72091040581574\n",
      "n_neighbors: 130, weights: uniform, metric: cosine, rmse: 205.7351109882323\n",
      "n_neighbors: 131, weights: uniform, metric: cosine, rmse: 205.74169691964542\n",
      "n_neighbors: 132, weights: uniform, metric: cosine, rmse: 205.74662978819924\n",
      "n_neighbors: 133, weights: uniform, metric: cosine, rmse: 205.75724049921774\n",
      "n_neighbors: 134, weights: uniform, metric: cosine, rmse: 205.77367135353305\n",
      "n_neighbors: 135, weights: uniform, metric: cosine, rmse: 205.79446623962255\n",
      "n_neighbors: 136, weights: uniform, metric: cosine, rmse: 205.81153662082136\n",
      "n_neighbors: 137, weights: uniform, metric: cosine, rmse: 205.8410357770781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 138, weights: uniform, metric: cosine, rmse: 205.8560529830467\n",
      "n_neighbors: 139, weights: uniform, metric: cosine, rmse: 205.83885857877053\n",
      "n_neighbors: 140, weights: uniform, metric: cosine, rmse: 205.86473846116644\n",
      "n_neighbors: 141, weights: uniform, metric: cosine, rmse: 205.85939976977764\n",
      "n_neighbors: 142, weights: uniform, metric: cosine, rmse: 205.86659125318963\n",
      "n_neighbors: 143, weights: uniform, metric: cosine, rmse: 205.8644083205735\n",
      "n_neighbors: 144, weights: uniform, metric: cosine, rmse: 205.8796202330738\n",
      "n_neighbors: 145, weights: uniform, metric: cosine, rmse: 205.88750440477588\n",
      "n_neighbors: 146, weights: uniform, metric: cosine, rmse: 205.88204416180426\n",
      "n_neighbors: 147, weights: uniform, metric: cosine, rmse: 205.88316239499392\n",
      "n_neighbors: 148, weights: uniform, metric: cosine, rmse: 205.892673865069\n",
      "n_neighbors: 149, weights: uniform, metric: cosine, rmse: 205.90996546740533\n",
      "n_neighbors: 150, weights: uniform, metric: cosine, rmse: 205.9166378095415\n",
      "n_neighbors: 151, weights: uniform, metric: cosine, rmse: 205.94047648697148\n",
      "n_neighbors: 152, weights: uniform, metric: cosine, rmse: 205.94656530551498\n",
      "n_neighbors: 153, weights: uniform, metric: cosine, rmse: 205.93977212739523\n",
      "n_neighbors: 154, weights: uniform, metric: cosine, rmse: 205.94482047737796\n",
      "n_neighbors: 155, weights: uniform, metric: cosine, rmse: 205.97265845336216\n",
      "n_neighbors: 156, weights: uniform, metric: cosine, rmse: 205.97920217764036\n",
      "n_neighbors: 157, weights: uniform, metric: cosine, rmse: 205.99196549796943\n",
      "n_neighbors: 158, weights: uniform, metric: cosine, rmse: 206.01033543555886\n",
      "n_neighbors: 159, weights: uniform, metric: cosine, rmse: 206.02430538673994\n",
      "n_neighbors: 160, weights: uniform, metric: cosine, rmse: 206.03929429715936\n",
      "n_neighbors: 161, weights: uniform, metric: cosine, rmse: 206.05555256517272\n",
      "n_neighbors: 162, weights: uniform, metric: cosine, rmse: 206.06666439472497\n",
      "n_neighbors: 163, weights: uniform, metric: cosine, rmse: 206.0959355946819\n",
      "n_neighbors: 164, weights: uniform, metric: cosine, rmse: 206.1029011620321\n",
      "n_neighbors: 165, weights: uniform, metric: cosine, rmse: 206.1284263287356\n",
      "n_neighbors: 166, weights: uniform, metric: cosine, rmse: 206.14183353689788\n",
      "n_neighbors: 167, weights: uniform, metric: cosine, rmse: 206.16018228884468\n",
      "n_neighbors: 168, weights: uniform, metric: cosine, rmse: 206.13363082267804\n",
      "n_neighbors: 169, weights: uniform, metric: cosine, rmse: 206.13488888671745\n",
      "n_neighbors: 170, weights: uniform, metric: cosine, rmse: 206.1431776203548\n",
      "n_neighbors: 171, weights: uniform, metric: cosine, rmse: 206.16397840853278\n",
      "n_neighbors: 172, weights: uniform, metric: cosine, rmse: 206.15826959265186\n",
      "n_neighbors: 173, weights: uniform, metric: cosine, rmse: 206.15689251187973\n",
      "n_neighbors: 174, weights: uniform, metric: cosine, rmse: 206.10635142020953\n",
      "n_neighbors: 175, weights: uniform, metric: cosine, rmse: 206.1031515558615\n",
      "n_neighbors: 176, weights: uniform, metric: cosine, rmse: 206.09976510691394\n",
      "n_neighbors: 177, weights: uniform, metric: cosine, rmse: 206.11643577670634\n",
      "n_neighbors: 178, weights: uniform, metric: cosine, rmse: 206.12684859083745\n",
      "n_neighbors: 179, weights: uniform, metric: cosine, rmse: 206.14485210380712\n",
      "n_neighbors: 180, weights: uniform, metric: cosine, rmse: 206.14294758938448\n",
      "n_neighbors: 181, weights: uniform, metric: cosine, rmse: 206.14097671063212\n",
      "n_neighbors: 182, weights: uniform, metric: cosine, rmse: 206.16588905984713\n",
      "n_neighbors: 183, weights: uniform, metric: cosine, rmse: 206.16618901276843\n",
      "n_neighbors: 184, weights: uniform, metric: cosine, rmse: 206.16579777225795\n",
      "n_neighbors: 185, weights: uniform, metric: cosine, rmse: 206.1428193969565\n",
      "n_neighbors: 186, weights: uniform, metric: cosine, rmse: 206.14329177556257\n",
      "n_neighbors: 187, weights: uniform, metric: cosine, rmse: 206.15271797204866\n",
      "n_neighbors: 188, weights: uniform, metric: cosine, rmse: 206.16475557799447\n",
      "n_neighbors: 189, weights: uniform, metric: cosine, rmse: 206.17541145048384\n",
      "n_neighbors: 190, weights: uniform, metric: cosine, rmse: 206.16334659644346\n",
      "n_neighbors: 191, weights: uniform, metric: cosine, rmse: 206.1783462310125\n",
      "n_neighbors: 192, weights: uniform, metric: cosine, rmse: 206.1898597702363\n",
      "n_neighbors: 193, weights: uniform, metric: cosine, rmse: 206.18792434551816\n",
      "n_neighbors: 194, weights: uniform, metric: cosine, rmse: 206.19293288350372\n",
      "n_neighbors: 195, weights: uniform, metric: cosine, rmse: 206.20004082490786\n",
      "n_neighbors: 196, weights: uniform, metric: cosine, rmse: 206.20810936631213\n",
      "n_neighbors: 197, weights: uniform, metric: cosine, rmse: 206.2207736471825\n",
      "n_neighbors: 198, weights: uniform, metric: cosine, rmse: 206.21619453610845\n",
      "n_neighbors: 199, weights: uniform, metric: cosine, rmse: 206.226590639119\n",
      "n_neighbors: 3, weights: distance, metric: cosine, rmse: 234.9891370029108\n",
      "n_neighbors: 4, weights: distance, metric: cosine, rmse: 224.42153546851128\n",
      "n_neighbors: 5, weights: distance, metric: cosine, rmse: 218.57737088189353\n",
      "n_neighbors: 6, weights: distance, metric: cosine, rmse: 213.46207674037896\n",
      "n_neighbors: 7, weights: distance, metric: cosine, rmse: 210.31813793481595\n",
      "n_neighbors: 8, weights: distance, metric: cosine, rmse: 208.57111524271872\n",
      "n_neighbors: 9, weights: distance, metric: cosine, rmse: 207.4686315509539\n",
      "n_neighbors: 10, weights: distance, metric: cosine, rmse: 206.9198747400251\n",
      "n_neighbors: 11, weights: distance, metric: cosine, rmse: 206.42503992091898\n",
      "n_neighbors: 12, weights: distance, metric: cosine, rmse: 205.54965540564817\n",
      "n_neighbors: 13, weights: distance, metric: cosine, rmse: 204.88867360533564\n",
      "n_neighbors: 14, weights: distance, metric: cosine, rmse: 204.73955332752098\n",
      "n_neighbors: 15, weights: distance, metric: cosine, rmse: 204.60698646341305\n",
      "n_neighbors: 16, weights: distance, metric: cosine, rmse: 204.3815458929026\n",
      "n_neighbors: 17, weights: distance, metric: cosine, rmse: 203.89304980888838\n",
      "n_neighbors: 18, weights: distance, metric: cosine, rmse: 204.12597840589146\n",
      "n_neighbors: 19, weights: distance, metric: cosine, rmse: 204.16161583331862\n",
      "n_neighbors: 20, weights: distance, metric: cosine, rmse: 204.17089481631626\n",
      "n_neighbors: 21, weights: distance, metric: cosine, rmse: 204.27540937712936\n",
      "n_neighbors: 22, weights: distance, metric: cosine, rmse: 204.35379568561842\n",
      "n_neighbors: 23, weights: distance, metric: cosine, rmse: 204.36574258381492\n",
      "n_neighbors: 24, weights: distance, metric: cosine, rmse: 203.89553054047275\n",
      "n_neighbors: 25, weights: distance, metric: cosine, rmse: 203.6520752823341\n",
      "n_neighbors: 26, weights: distance, metric: cosine, rmse: 203.53751107412316\n",
      "n_neighbors: 27, weights: distance, metric: cosine, rmse: 203.54945941245435\n",
      "n_neighbors: 28, weights: distance, metric: cosine, rmse: 203.5614160065901\n",
      "n_neighbors: 29, weights: distance, metric: cosine, rmse: 203.67164836476687\n",
      "n_neighbors: 30, weights: distance, metric: cosine, rmse: 203.73775646026846\n",
      "n_neighbors: 31, weights: distance, metric: cosine, rmse: 203.9070966491497\n",
      "n_neighbors: 32, weights: distance, metric: cosine, rmse: 204.06347669331979\n",
      "n_neighbors: 33, weights: distance, metric: cosine, rmse: 204.20405491991355\n",
      "n_neighbors: 34, weights: distance, metric: cosine, rmse: 204.13100546075194\n",
      "n_neighbors: 35, weights: distance, metric: cosine, rmse: 204.11807599318337\n",
      "n_neighbors: 36, weights: distance, metric: cosine, rmse: 204.1744777881006\n",
      "n_neighbors: 37, weights: distance, metric: cosine, rmse: 204.16149875044954\n",
      "n_neighbors: 38, weights: distance, metric: cosine, rmse: 204.20980077989063\n",
      "n_neighbors: 39, weights: distance, metric: cosine, rmse: 204.22057506136352\n",
      "n_neighbors: 40, weights: distance, metric: cosine, rmse: 204.29852200781465\n",
      "n_neighbors: 41, weights: distance, metric: cosine, rmse: 204.35878347375711\n",
      "n_neighbors: 42, weights: distance, metric: cosine, rmse: 204.37848934303628\n",
      "n_neighbors: 43, weights: distance, metric: cosine, rmse: 204.42458316112706\n",
      "n_neighbors: 44, weights: distance, metric: cosine, rmse: 204.5570617267938\n",
      "n_neighbors: 45, weights: distance, metric: cosine, rmse: 204.50854936987307\n",
      "n_neighbors: 46, weights: distance, metric: cosine, rmse: 204.55676926890797\n",
      "n_neighbors: 47, weights: distance, metric: cosine, rmse: 204.54660191248047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 48, weights: distance, metric: cosine, rmse: 204.5860339167648\n",
      "n_neighbors: 49, weights: distance, metric: cosine, rmse: 204.60560393272627\n",
      "n_neighbors: 50, weights: distance, metric: cosine, rmse: 204.62323972196407\n",
      "n_neighbors: 51, weights: distance, metric: cosine, rmse: 204.66288264119314\n",
      "n_neighbors: 52, weights: distance, metric: cosine, rmse: 204.65757519128837\n",
      "n_neighbors: 53, weights: distance, metric: cosine, rmse: 204.68504657680413\n",
      "n_neighbors: 54, weights: distance, metric: cosine, rmse: 204.6670080629756\n",
      "n_neighbors: 55, weights: distance, metric: cosine, rmse: 204.66168896070036\n",
      "n_neighbors: 56, weights: distance, metric: cosine, rmse: 204.63465386923124\n",
      "n_neighbors: 57, weights: distance, metric: cosine, rmse: 204.6517368139215\n",
      "n_neighbors: 58, weights: distance, metric: cosine, rmse: 204.6715454784315\n",
      "n_neighbors: 59, weights: distance, metric: cosine, rmse: 204.68667642831295\n",
      "n_neighbors: 60, weights: distance, metric: cosine, rmse: 204.7114054322847\n",
      "n_neighbors: 61, weights: distance, metric: cosine, rmse: 204.72455491356146\n",
      "n_neighbors: 62, weights: distance, metric: cosine, rmse: 204.70386358147886\n",
      "n_neighbors: 63, weights: distance, metric: cosine, rmse: 204.7404992362262\n",
      "n_neighbors: 64, weights: distance, metric: cosine, rmse: 204.76859975924953\n",
      "n_neighbors: 65, weights: distance, metric: cosine, rmse: 204.81107555629248\n",
      "n_neighbors: 66, weights: distance, metric: cosine, rmse: 204.86571455868443\n",
      "n_neighbors: 67, weights: distance, metric: cosine, rmse: 204.87504637701903\n",
      "n_neighbors: 68, weights: distance, metric: cosine, rmse: 204.8613516139871\n",
      "n_neighbors: 69, weights: distance, metric: cosine, rmse: 204.95128948830495\n",
      "n_neighbors: 70, weights: distance, metric: cosine, rmse: 204.96834173677806\n",
      "n_neighbors: 71, weights: distance, metric: cosine, rmse: 204.99699945448683\n",
      "n_neighbors: 72, weights: distance, metric: cosine, rmse: 205.0049518096805\n",
      "n_neighbors: 73, weights: distance, metric: cosine, rmse: 205.03725037676938\n",
      "n_neighbors: 74, weights: distance, metric: cosine, rmse: 205.03296415940943\n",
      "n_neighbors: 75, weights: distance, metric: cosine, rmse: 205.05992035762358\n",
      "n_neighbors: 76, weights: distance, metric: cosine, rmse: 205.0532850082047\n",
      "n_neighbors: 77, weights: distance, metric: cosine, rmse: 205.09787833211095\n",
      "n_neighbors: 78, weights: distance, metric: cosine, rmse: 205.13817556130033\n",
      "n_neighbors: 79, weights: distance, metric: cosine, rmse: 205.12527585091402\n",
      "n_neighbors: 80, weights: distance, metric: cosine, rmse: 205.1271302683246\n",
      "n_neighbors: 81, weights: distance, metric: cosine, rmse: 205.05587174759344\n",
      "n_neighbors: 82, weights: distance, metric: cosine, rmse: 205.07851561233986\n",
      "n_neighbors: 83, weights: distance, metric: cosine, rmse: 205.10231709289363\n",
      "n_neighbors: 84, weights: distance, metric: cosine, rmse: 205.13611988147318\n",
      "n_neighbors: 85, weights: distance, metric: cosine, rmse: 205.14834905923774\n",
      "n_neighbors: 86, weights: distance, metric: cosine, rmse: 205.17878345612377\n",
      "n_neighbors: 87, weights: distance, metric: cosine, rmse: 205.1903325676275\n",
      "n_neighbors: 88, weights: distance, metric: cosine, rmse: 205.1660074652783\n",
      "n_neighbors: 89, weights: distance, metric: cosine, rmse: 205.18743071871114\n",
      "n_neighbors: 90, weights: distance, metric: cosine, rmse: 205.23455070999586\n",
      "n_neighbors: 91, weights: distance, metric: cosine, rmse: 205.2280449504973\n",
      "n_neighbors: 92, weights: distance, metric: cosine, rmse: 205.26258886944242\n",
      "n_neighbors: 93, weights: distance, metric: cosine, rmse: 205.3081098428312\n",
      "n_neighbors: 94, weights: distance, metric: cosine, rmse: 205.3148793019099\n",
      "n_neighbors: 95, weights: distance, metric: cosine, rmse: 205.3344710369431\n",
      "n_neighbors: 96, weights: distance, metric: cosine, rmse: 205.32130336609444\n",
      "n_neighbors: 97, weights: distance, metric: cosine, rmse: 205.34888004854574\n",
      "n_neighbors: 98, weights: distance, metric: cosine, rmse: 205.35294590543498\n",
      "n_neighbors: 99, weights: distance, metric: cosine, rmse: 205.3399406976142\n",
      "n_neighbors: 100, weights: distance, metric: cosine, rmse: 205.3546136983566\n",
      "n_neighbors: 101, weights: distance, metric: cosine, rmse: 205.35956423269974\n",
      "n_neighbors: 102, weights: distance, metric: cosine, rmse: 205.37509435175048\n",
      "n_neighbors: 103, weights: distance, metric: cosine, rmse: 205.3967315646657\n",
      "n_neighbors: 104, weights: distance, metric: cosine, rmse: 205.4064562108073\n",
      "n_neighbors: 105, weights: distance, metric: cosine, rmse: 205.4114976544411\n",
      "n_neighbors: 106, weights: distance, metric: cosine, rmse: 205.44962387617903\n",
      "n_neighbors: 107, weights: distance, metric: cosine, rmse: 205.47740929682476\n",
      "n_neighbors: 108, weights: distance, metric: cosine, rmse: 205.49171022873483\n",
      "n_neighbors: 109, weights: distance, metric: cosine, rmse: 205.51315358247263\n",
      "n_neighbors: 110, weights: distance, metric: cosine, rmse: 205.51944770685202\n",
      "n_neighbors: 111, weights: distance, metric: cosine, rmse: 205.51024348239426\n",
      "n_neighbors: 112, weights: distance, metric: cosine, rmse: 205.54490882124523\n",
      "n_neighbors: 113, weights: distance, metric: cosine, rmse: 205.5716911817075\n",
      "n_neighbors: 114, weights: distance, metric: cosine, rmse: 205.59843032133665\n",
      "n_neighbors: 115, weights: distance, metric: cosine, rmse: 205.59113082264827\n",
      "n_neighbors: 116, weights: distance, metric: cosine, rmse: 205.60245613577285\n",
      "n_neighbors: 117, weights: distance, metric: cosine, rmse: 205.61712025290075\n",
      "n_neighbors: 118, weights: distance, metric: cosine, rmse: 205.62990225791955\n",
      "n_neighbors: 119, weights: distance, metric: cosine, rmse: 205.64199598727473\n",
      "n_neighbors: 120, weights: distance, metric: cosine, rmse: 205.66936482614406\n",
      "n_neighbors: 121, weights: distance, metric: cosine, rmse: 205.68433076286155\n",
      "n_neighbors: 122, weights: distance, metric: cosine, rmse: 205.6724227552478\n",
      "n_neighbors: 123, weights: distance, metric: cosine, rmse: 205.68712653038318\n",
      "n_neighbors: 124, weights: distance, metric: cosine, rmse: 205.69436446117396\n",
      "n_neighbors: 125, weights: distance, metric: cosine, rmse: 205.70491754533103\n",
      "n_neighbors: 126, weights: distance, metric: cosine, rmse: 205.71324777112233\n",
      "n_neighbors: 127, weights: distance, metric: cosine, rmse: 205.70948981034337\n",
      "n_neighbors: 128, weights: distance, metric: cosine, rmse: 205.73231680209133\n",
      "n_neighbors: 129, weights: distance, metric: cosine, rmse: 205.74737230119143\n",
      "n_neighbors: 130, weights: distance, metric: cosine, rmse: 205.75989166304\n",
      "n_neighbors: 131, weights: distance, metric: cosine, rmse: 205.7654365177402\n",
      "n_neighbors: 132, weights: distance, metric: cosine, rmse: 205.77089252201023\n",
      "n_neighbors: 133, weights: distance, metric: cosine, rmse: 205.78152775967914\n",
      "n_neighbors: 134, weights: distance, metric: cosine, rmse: 205.7957149100921\n",
      "n_neighbors: 135, weights: distance, metric: cosine, rmse: 205.8145353124239\n",
      "n_neighbors: 136, weights: distance, metric: cosine, rmse: 205.83047172062226\n",
      "n_neighbors: 137, weights: distance, metric: cosine, rmse: 205.85719437065876\n",
      "n_neighbors: 138, weights: distance, metric: cosine, rmse: 205.87295474412818\n",
      "n_neighbors: 139, weights: distance, metric: cosine, rmse: 205.85374174106454\n",
      "n_neighbors: 140, weights: distance, metric: cosine, rmse: 205.87895226813853\n",
      "n_neighbors: 141, weights: distance, metric: cosine, rmse: 205.87119695567256\n",
      "n_neighbors: 142, weights: distance, metric: cosine, rmse: 205.8768910278163\n",
      "n_neighbors: 143, weights: distance, metric: cosine, rmse: 205.87254211938884\n",
      "n_neighbors: 144, weights: distance, metric: cosine, rmse: 205.8836577218834\n",
      "n_neighbors: 145, weights: distance, metric: cosine, rmse: 205.89540671875486\n",
      "n_neighbors: 146, weights: distance, metric: cosine, rmse: 205.88931803641285\n",
      "n_neighbors: 147, weights: distance, metric: cosine, rmse: 205.89024439379912\n",
      "n_neighbors: 148, weights: distance, metric: cosine, rmse: 205.89950573834344\n",
      "n_neighbors: 149, weights: distance, metric: cosine, rmse: 205.91486932106847\n",
      "n_neighbors: 150, weights: distance, metric: cosine, rmse: 205.92081196194286\n",
      "n_neighbors: 151, weights: distance, metric: cosine, rmse: 205.94331125838937\n",
      "n_neighbors: 152, weights: distance, metric: cosine, rmse: 205.94872035651306\n",
      "n_neighbors: 153, weights: distance, metric: cosine, rmse: 205.9414527431771\n",
      "n_neighbors: 154, weights: distance, metric: cosine, rmse: 205.9469356766969\n",
      "n_neighbors: 155, weights: distance, metric: cosine, rmse: 205.9731622030082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 156, weights: distance, metric: cosine, rmse: 205.97855608404652\n",
      "n_neighbors: 157, weights: distance, metric: cosine, rmse: 205.99055069333974\n",
      "n_neighbors: 158, weights: distance, metric: cosine, rmse: 206.00889326682537\n",
      "n_neighbors: 159, weights: distance, metric: cosine, rmse: 206.02123683626428\n",
      "n_neighbors: 160, weights: distance, metric: cosine, rmse: 206.03529680083412\n",
      "n_neighbors: 161, weights: distance, metric: cosine, rmse: 206.05033892578032\n",
      "n_neighbors: 162, weights: distance, metric: cosine, rmse: 206.0605862210217\n",
      "n_neighbors: 163, weights: distance, metric: cosine, rmse: 206.08862002864862\n",
      "n_neighbors: 164, weights: distance, metric: cosine, rmse: 206.0948754025547\n",
      "n_neighbors: 165, weights: distance, metric: cosine, rmse: 206.1196386063516\n",
      "n_neighbors: 166, weights: distance, metric: cosine, rmse: 206.13181373682477\n",
      "n_neighbors: 167, weights: distance, metric: cosine, rmse: 206.1498627033918\n",
      "n_neighbors: 168, weights: distance, metric: cosine, rmse: 206.1255397497211\n",
      "n_neighbors: 169, weights: distance, metric: cosine, rmse: 206.12684913077857\n",
      "n_neighbors: 170, weights: distance, metric: cosine, rmse: 206.13401565066627\n",
      "n_neighbors: 171, weights: distance, metric: cosine, rmse: 206.1549621793796\n",
      "n_neighbors: 172, weights: distance, metric: cosine, rmse: 206.14966630795732\n",
      "n_neighbors: 173, weights: distance, metric: cosine, rmse: 206.1482586946124\n",
      "n_neighbors: 174, weights: distance, metric: cosine, rmse: 206.09692039205515\n",
      "n_neighbors: 175, weights: distance, metric: cosine, rmse: 206.093025881699\n",
      "n_neighbors: 176, weights: distance, metric: cosine, rmse: 206.0884353011143\n",
      "n_neighbors: 177, weights: distance, metric: cosine, rmse: 206.10389573509826\n",
      "n_neighbors: 178, weights: distance, metric: cosine, rmse: 206.1138953527713\n",
      "n_neighbors: 179, weights: distance, metric: cosine, rmse: 206.13143904113673\n",
      "n_neighbors: 180, weights: distance, metric: cosine, rmse: 206.12886516770527\n",
      "n_neighbors: 181, weights: distance, metric: cosine, rmse: 206.12635022451056\n",
      "n_neighbors: 182, weights: distance, metric: cosine, rmse: 206.14972488117925\n",
      "n_neighbors: 183, weights: distance, metric: cosine, rmse: 206.14925793498492\n",
      "n_neighbors: 184, weights: distance, metric: cosine, rmse: 206.1480436970887\n",
      "n_neighbors: 185, weights: distance, metric: cosine, rmse: 206.1247206291577\n",
      "n_neighbors: 186, weights: distance, metric: cosine, rmse: 206.12461927803702\n",
      "n_neighbors: 187, weights: distance, metric: cosine, rmse: 206.13280562265174\n",
      "n_neighbors: 188, weights: distance, metric: cosine, rmse: 206.14338896263442\n",
      "n_neighbors: 189, weights: distance, metric: cosine, rmse: 206.15354941209011\n",
      "n_neighbors: 190, weights: distance, metric: cosine, rmse: 206.14105232291584\n",
      "n_neighbors: 191, weights: distance, metric: cosine, rmse: 206.15550652738358\n",
      "n_neighbors: 192, weights: distance, metric: cosine, rmse: 206.16688304239915\n",
      "n_neighbors: 193, weights: distance, metric: cosine, rmse: 206.16474336804734\n",
      "n_neighbors: 194, weights: distance, metric: cosine, rmse: 206.1696711542056\n",
      "n_neighbors: 195, weights: distance, metric: cosine, rmse: 206.1766952577116\n",
      "n_neighbors: 196, weights: distance, metric: cosine, rmse: 206.1857385891035\n",
      "n_neighbors: 197, weights: distance, metric: cosine, rmse: 206.19810779245765\n",
      "n_neighbors: 198, weights: distance, metric: cosine, rmse: 206.19451919856277\n",
      "n_neighbors: 199, weights: distance, metric: cosine, rmse: 206.20509497811747\n"
     ]
    }
   ],
   "source": [
    "best_score_param = {'score' : 1000, 'param': ''}\n",
    "\n",
    "metrics_list = ['euclidean', 'cosine']\n",
    "weights_list = ['uniform', 'distance']\n",
    "k_max = 200\n",
    "k_list = np.arange(2, k_max)\n",
    "best_score_param = {'score': None, 'param': None}\n",
    "for metrics in metrics_list:\n",
    "    for weights in weights_list:\n",
    "        knn_regressor = KNNRegressor(k_max, metric=metrics, mode=weights, test_block_size=10000)\n",
    "        knn_regressor.fit(X_train_full, y_train.values.reshape(-1))\n",
    "        knn_regressor.find_kneighbors(X_test_full, return_distance=True)\n",
    "        for k in k_list[1:]:\n",
    "            knn_regressor.n_neighbors = k\n",
    "            pred = knn_regressor.predict_opt_regression(X_test_with_text)\n",
    "            rmse_score = rmse(pred, y_test.values.reshape(-1))\n",
    "            print(f'n_neighbors: {k}, weights: {weights}, metric: {metrics}, rmse: {rmse_score}')\n",
    "            if best_score_param['score'] is None:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)            \n",
    "            elif best_score_param['score'] > rmse_score:\n",
    "                best_score_param['score'] = rmse_score\n",
    "                best_score_param['param'] = str(weights) + '_' + str(k) + '_' + str(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 202.10289902236653, 'param': 'distance_28_euclidean'}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем пронормировать все признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer(copy=True, norm='l2')\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_full_scaled = scaler.transform(X_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_final = KNNRegressor(28, metric='euclidean', mode='distance', test_block_size=10000)\n",
    "knn_final.fit(X_train_full_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 34min 29s, sys: 8.09 s, total: 1h 34min 37s\n",
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = knn_final.predict(X_test_full_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0637452140629\n"
     ]
    }
   ],
   "source": [
    "rmse_score = rmse(preds, y_test.values.reshape(-1))\n",
    "rmse_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью добавления дополнительных признаков и их нормировки удалось превзойти качество, полученное только при преобразовании текстовых признаков. Лучший результат - **202.064**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4: Выводы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆ (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆ (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆ (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆ (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе были проведены эксперименты с методом $k$ ближайших соседей для задачи регрессии (и немного для задачи классификации).\n",
    "\n",
    "Были изучены и реализованы метрики расстояния между категориальными признаками:\n",
    "\n",
    "1. Индикатор совпадения ($overlap$)\n",
    "2. Сглаженный индикатор совпадения ($flattened \\space overlap$)\n",
    "3. Логарифмический индикатор совпадения ($log \\space overlap$)\n",
    "\n",
    "При $k = 10$ лучшей метрикой расстояния является **сглаженный индикатор совпадения**.\n",
    "Если же найти оптимальное значение $k$ для каждой из метрик, то лучшей метрикой расстояния становится **логарифмический индикатор совпадения**.\n",
    "\n",
    "Были рассмотрены преобразования категориальных признаков с фолдингом и без:\n",
    "\n",
    "1. Число $counts$ объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число $successes$ объектов первого класса $(y = 1)$ в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: \n",
    "\\begin{align}\n",
    "p_j(c) = \\frac{successes_j(c) + a}{counts_j(c) + b},\n",
    "\\end{align}\n",
    "\n",
    "Интересно, что метод заполнения признаков без фолдинга дал качество лучше, чем с фолдингом.\n",
    "\n",
    "Были рассмотрены преобразования текстовых признаков в вещественные для использования их со стандартными метриками расстояния: $cosine$, $euclidean$:\n",
    "1. Мешок слов (Bag of words)\n",
    "2. TF-IDF\n",
    "\n",
    "В этом случае лучшим оказалось **TF-IDF**.\n",
    "\n",
    "Преобразованные категориальные и текстовые признаки были объединены с вещественными, далее все признаки пронормировали. Для них было найдено оптимальное значение $k = 30$, на котором получилось наименьшее значение $\\textbf{RMSE} = 202.06$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆(ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
