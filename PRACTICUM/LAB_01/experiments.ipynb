{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 280 ms, total: 17.3 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_data = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate full_data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'data': full_data['data'][:train_size], 'target': full_data['target'][:train_size]}\n",
    "test_data = {'data': full_data['data'][train_size:], 'target': full_data['target'][train_size:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize first 10 digits from train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits_to_show = 10\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i in range(digits_to_show):\n",
    "    ax = fig.add_subplot(1, digits_to_show + 1, i+1)\n",
    "    ax.imshow(train_data['data'][i].reshape(28, 28), cmap=plt.get_cmap('Greys_r'))\n",
    "    ax.set_title('Class target: ' + train_data['target'][i])\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing my KNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['target'] = train_data['target'].astype(int)\n",
    "test_data['target'] = test_data['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nearest_neighbors import KNNClassifier\n",
    "\n",
    "\n",
    "def kfold(n, n_folds=5):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * n - objects amount in sample\n",
    "        * n_folds - folds amount\n",
    "    return values:\n",
    "        * list with size n_folds, where every element is tuple of two 1D numpy array:\n",
    "            * first array contains indices of train samples\n",
    "            * second array contains indices of validation samples\n",
    "    \"\"\"\n",
    "\n",
    "    indices = np.arange(n)\n",
    "    folds = np.array_split(indices, n_folds)\n",
    "    train_test_idx_list = []\n",
    "    for fold in folds:\n",
    "        test_idx = fold\n",
    "        train_idx = list(set(folds) - set(fold))\n",
    "        train_test_idx_list.append((train_idx, test_idx))\n",
    "    return train_test_idx_list\n",
    "\n",
    "\n",
    "def accuracy(y_valid, y_true):\n",
    "    return np.sum(y_valid == y_true, axis=0) / len(y_valid) * 100\n",
    "\n",
    "\n",
    "def knn_cross_val_score(X, y, k_list, score='accuracy', cv=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :param X: train samples\n",
    "    :param y: targets for train\n",
    "    :param k_list: list of values of neighbors amount, in ascending order\n",
    "    :param score: metric name( accuracy' must have)\n",
    "    :param cv: list of tuples, which contains indices of train and valid samples\n",
    "    :param kwargs: parameters for __init__ from KNNClassifier\n",
    "    :return: dict, where keys is neigbors amount from k_list, values - numpy array of size len(cv)\n",
    "    with accuracy on each fold\n",
    "    \"\"\"\n",
    "\n",
    "    if cv is None:\n",
    "        cv = kfold(X.shape[0])\n",
    "    knn = KNNClassifier(**kwargs)\n",
    "    knn.k = np.max(k_list)\n",
    "    knn.fit(X, y)\n",
    "    knn.find_kneighbors(X, return_distance=True)\n",
    "    accuracy_per_k = {k: np.empty(0) for k in k_list}\n",
    "    for k in k_list:\n",
    "        knn.k = k\n",
    "        for fold in cv:\n",
    "            y_valid = knn.predict(X[fold[1]])\n",
    "            accuracy_per_k[k] = np.append(accuracy_per_k[k],\n",
    "                                          accuracy(y_valid,\n",
    "                                                   y[fold[1]]))\n",
    "    return accuracy_per_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from distances import euclidean_distance, cosine_distance\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self,\n",
    "                 k=10,\n",
    "                 strategy='my_own',\n",
    "                 metric='euclidean',\n",
    "                 weights=False,\n",
    "                 test_block_size=100\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            * k - amount of nearest neighbours(nn)\n",
    "            * strategy - nn searching algorithm. Possible values:\n",
    "                - 'my_own' - self-realization\n",
    "                - 'brute' - from sklearn.neighbors.NearestNeighbors(algorithm='brute')\n",
    "                - 'kd_tree' - from sklearn.neighbors.NearestNeighbors(algorithm='kd_tree')\n",
    "                - 'ball_tree' - from sklearn.neighbors.NearestNeighbors(algorithm='ball_tree')\n",
    "            * metric:\n",
    "                - 'euclidean' - euclidean metric\n",
    "                - 'cosine' - cosine metric\n",
    "            * weights - bool variable.\n",
    "                - True - weighted KNN(with distance)\n",
    "                - False - simple KNN\n",
    "            * test_block_size - size of test block\n",
    "        \"\"\"\n",
    "\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.distances = None\n",
    "        self.neigh_idxs = None\n",
    "        self.model = None\n",
    "        self.k = k\n",
    "        self.strategy = strategy\n",
    "        self.metric = metric\n",
    "        self.eps = 1e-5\n",
    "        self.weights = weights\n",
    "        if self.strategy == 'brute':\n",
    "            self.model = NearestNeighbors(n_neighbors=self.k, algorithm=self.strategy, metric=self.metric)\n",
    "        elif self.strategy != 'my_own':\n",
    "            self.model = NearestNeighbors(n_neighbors=self.k, algorithm=self.strategy)\n",
    "        else:\n",
    "            self.model = None\n",
    "        self.test_block_size = test_block_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            * X - train data\n",
    "            * y - targets for train data\n",
    "        \"\"\"\n",
    "\n",
    "        self.y_train = y.astype(int)\n",
    "        self.k = np.min([self.y_train.shape[0], self.k])\n",
    "        if self.strategy != 'my_own':\n",
    "            self.model.fit(X, self.y_train)\n",
    "        else:\n",
    "            self.X_train = X\n",
    "\n",
    "    def find_kneighbors(self, X, return_distance):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            * X - objects sample\n",
    "            * return_distance - bool variable\n",
    "\n",
    "        return values:\n",
    "            * If return_distance == True:\n",
    "                * tuple with two numpy array with size (X.shape[0], k), where:\n",
    "                  [i, j] elem of first array must be the distance between\n",
    "                  i-th object and his j-th nearest neighbour\n",
    "                  [i, j] elem of second array must be the index of j-th nearest neighbour to i-th object\n",
    "            * If return_distance == False:\n",
    "                * only second array\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.strategy != 'my_own':\n",
    "            distances, \\\n",
    "            neigh_idxs = self.model.kneighbors(X, n_neighbors=self.k)\n",
    "        else:\n",
    "            if self.metric == 'euclidean':\n",
    "                distances = euclidean_distance(X, self.X_train)\n",
    "                neigh_idxs = np.argsort(distances,\n",
    "                                             axis=1)[:, :self.k]\n",
    "                if return_distance:\n",
    "                    distances = np.sort(distances,\n",
    "                                             axis=1)[:, :self.k]\n",
    "\n",
    "            elif self.metric == 'cosine':\n",
    "                distances = cosine_distance(X, self.X_train)\n",
    "                neigh_idxs = np.argsort(distances,\n",
    "                                             axis=1)[:, :self.k]\n",
    "                if return_distance:\n",
    "                    distances = np.sort(distances,\n",
    "                                        axis=1)[:, :self.k]\n",
    "        if return_distance:\n",
    "            return distances, neigh_idxs\n",
    "        return neigh_idxs\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            * X - test objects\n",
    "\n",
    "        return values:\n",
    "            * numpy array with size X.shape[0] of predictions for test objects from X\n",
    "        \"\"\"\n",
    "\n",
    "        if self.test_block_size > X.shape[0]:\n",
    "            self.test_block_size = X.shape[0]\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        split_size = X.shape[0] // self.test_block_size + \\\n",
    "                     int(X.shape[0] % self.test_block_size != 0)\n",
    "        classes = np.array(np.unique(self.y_train))\n",
    "        last_idx = 0\n",
    "        for i, split in enumerate(np.array_split(X, split_size)):\n",
    "            distances, neigh_idxs = self.find_kneighbors(split, True)\n",
    "            for j, idx in enumerate(neigh_idxs):\n",
    "                counts = np.zeros(len(classes))\n",
    "                for c in classes:\n",
    "                    if self.weights:\n",
    "                        weights = 1 / (distances[j] + self.eps)\n",
    "                        counts[c] = np.sum((self.y_train[idx] == c) * weights)\n",
    "                    else:\n",
    "                        counts[c] = np.sum(self.y_train[idx] == c)\n",
    "                preds[j + i * split.shape[0]] = np.argmax(counts)\n",
    "        distances, neigh_idxs = self.find_kneighbors(X[last_idx:], True)\n",
    "        for j, idx in enumerate(neigh_idxs):\n",
    "            counts = np.zeros(len(classes))\n",
    "            for c in classes:\n",
    "                if self.weights:\n",
    "                    weights = 1 / (distances[j] + self.eps)\n",
    "                    counts[c] = np.sum((self.y_train[idx] == c) * weights)\n",
    "                else:\n",
    "                    counts[c] = np.sum(self.y_train[idx] == c)\n",
    "                preds[last_idx+j] = np.argmax(counts)\n",
    "        return preds\n",
    "\n",
    "\n",
    "n_test_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNNClassifier(5, strategy='my_own', metric='euclidean', weights=False, test_block_size=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 µs, sys: 0 ns, total: 225 µs\n",
      "Wall time: 148 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KNN_model.fit(X=train_data['data'][:5000], y=train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# KNN_model.find_kneighbors(test_data['data'][:n_test_samples], False)\n",
    "#14.4 - True # 500 samples\n",
    "#9.56 - False # 500 samples\n",
    "\n",
    "#2min 48s - True # 10k samples\n",
    "#2min 11s - False # 10k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[53843, 38620, 16186, 27059, 47003],\n",
    "#        [28882, 49160, 24612, 31634, 16902],\n",
    "#        [58741, 46512, 15224, 47333, 44038],\n",
    "#        ...,\n",
    "#        [46124, 13852, 17844, 18510, 33708],\n",
    "#        [29034, 43258, 56724, 43706, 19908],\n",
    "#        [49436, 41800, 50670, 11132, 55520]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 168 ms, total: 11.6 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds1 = KNN_model.predict(test_data['data'][:n_test_samples])\n",
    "#12.5 s - True # 500 samples\n",
    "#9.47 s - False # 500 samples\n",
    "\n",
    "# 6min 53s - True # 10k samples\n",
    "# 6min 16s - False # 10k samples\n",
    "#(1, 5, 60000)\n",
    "#(100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr_my = KNN_model.find_kneighbors(test_data['data'][:n_test_samples], return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds1.astype(int) - test_data['target'][:n_test_samples].astype(int) == 0) / test_data['target'][:n_test_samples].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(5, algorithm='brute', metric='euclidean', weights='distance')\n",
    "knn.fit(X=train_data['data'], y=train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = knn.predict(test_data['data'][:n_test_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds1.astype(int) - test_data['target'][:n_test_samples].astype(int) == 0) / test_data['target'][:n_test_samples].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 784)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from distances import euclidean_distance, cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[2, 3], [-1, 6], [10, 22]])\n",
    "y = np.array([[1, 1], [-1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# def cosine_distance(X, Y):\n",
    "#     \"\"\"\n",
    "#     params:\n",
    "#         * X - np.array with size N x D\n",
    "#         * Y - np.array with size M x D\n",
    "#     return values:\n",
    "#         * np.array with size N x M, where [i, j] - cosine distance between i-th vector from X and\n",
    "#                                                                               j-th vector from Y\n",
    "#     \"\"\"\n",
    "    \n",
    "#     X = X[None, :, :]\n",
    "#     Y = Y[:, None, :]\n",
    "#     result = np.sum(X * Y, axis=2)\n",
    "#     result /= np.sqrt(np.sum(X ** 2, axis=2))\n",
    "#     result /= np.sqrt(np.sum(Y ** 2, axis=2))\n",
    "#     return 1 - result\n",
    "\n",
    "def euclidean_distance(X, Y):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * X - np.array with size N x D\n",
    "        * Y - np.array with size M x D\n",
    "    return values:\n",
    "        * np.array with size N x M, where [i, j] - euclidean distance between i-th vector from X and\n",
    "                                                                              j-th vector from Y\n",
    "    \"\"\"\n",
    "\n",
    "    X_sqr = np.sum(X ** 2, axis=1)[:, None]\n",
    "    print(X_sqr.shape)\n",
    "    Y_sqr = np.sum(Y ** 2, axis=1)\n",
    "    print(Y_sqr.shape)\n",
    "    return np.sqrt(X_sqr - 2 * np.dot(X, Y.T) + Y_sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1, 10000)\n",
    "np.sum(X[[1, 2, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%memit\n",
    "print(euclidean_distance(np.ones((2000, 1000)) * 5, np.ones((500, 1000))))\n",
    "#2.22 s - new on 200x500\n",
    "\n",
    "#763 ms - old on 200x500\n",
    "#7725.48 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X[None, ...] - Y[:, None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "std_norm = np.linalg.norm(X, axis=1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "my_norm = np.sqrt(np.sum(X ** 2, axis=1))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(std_norm != my_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nearest_neighbors import KNNClassifier\n",
    "\n",
    "\n",
    "def kfold(n, n_folds=5):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * n - objects amount in sample\n",
    "        * n_folds - folds amount\n",
    "    return values:\n",
    "        * list with size n_folds, where every element is tuple of two 1D numpy array:\n",
    "            * first array contains indices of train samples\n",
    "            * second array contains indices of validation samples\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    size_of_one_fold = int(n / n_folds)\n",
    "    size_with_folds = size_of_one_fold * n_folds\n",
    "    out_elemnts_amount = len(indices) - size_with_folds\n",
    "    train_test_idx_list = []\n",
    "    for i in range(n_folds):\n",
    "        test_idx = indices[i * size_of_one_fold:(i + 1) * size_of_one_fold]\n",
    "        if out_elemnts_amount > 0:\n",
    "            test_idx = np.append(test_idx, n - out_elemnts_amount)\n",
    "            out_elemnts_amount -= 1\n",
    "        train_idx = np.array(list((set(indices) - set(test_idx))))\n",
    "        train_test_idx_list.append((train_idx, test_idx))\n",
    "    return train_test_idx_list\n",
    "    \n",
    "def accuracy(y_valid, y_true):\n",
    "    return np.sum(y_valid == y_true, axis=0) / len(y_valid) * 100\n",
    "\n",
    "\n",
    "def knn_cross_val_score(X, y, k_list=[2, 3, 5, 10, 15], score='accuracy', cv=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :param X: train samples\n",
    "    :param y: targets for train\n",
    "    :param k_list: list of values of neighbors amount, in ascending order\n",
    "    :param score: metric name( accuracy' must have)\n",
    "    :param cv: list of tuples, which contains indices of train and valid samples\n",
    "    :param kwargs: parameters for __init__ from KNNClassifier\n",
    "    :return: dict, where keys is neigbors amount from k_list, values - numpy array of size len(cv)\n",
    "    with accuracy on each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    if cv is None:\n",
    "        cv = kfold(X.shape[0])\n",
    "    knn = KNNClassifier(**kwargs)\n",
    "    knn.k = np.max(k_list)\n",
    "    knn.fit(X, y)\n",
    "    knn.find_kneighbors(X, return_distance=True)\n",
    "    accuracy_per_k = {k: np.empty(0) for k in k_list}\n",
    "    for k in k_list:\n",
    "        knn.k = k\n",
    "        for fold in cv:\n",
    "            y_valid = knn.predict(X[fold[1]])\n",
    "            accuracy_per_k[k] = np.append(accuracy_per_k[k],\n",
    "                      accuracy(y_valid,\n",
    "                               y[fold[1]]))\n",
    "    return accuracy_per_k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nearest_neighbors import KNNClassifier\n",
    "\n",
    "\n",
    "def kfold(n, n_folds=5):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        * n - objects amount in sample\n",
    "        * n_folds - folds amount\n",
    "    return values:\n",
    "        * list with size n_folds, where every element is tuple of two 1D numpy array:\n",
    "            * first array contains indices of train samples\n",
    "            * second array contains indices of validation samples\n",
    "    \"\"\"\n",
    "\n",
    "    indices = np.arange(n)\n",
    "    folds = np.array_split(indices, n_folds)\n",
    "    train_test_idx_list = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        test_idx = fold\n",
    "        train_idx = folds[:i] + folds[i + 1:]\n",
    "        train_test_idx_list.append((train_idx, test_idx))\n",
    "    return train_test_idx_list\n",
    "\n",
    "\n",
    "def accuracy(y_valid, y_true):\n",
    "    return np.sum(y_valid == y_true, axis=0) / len(y_valid) * 100\n",
    "\n",
    "\n",
    "def knn_cross_val_score(X, y, k_list, score='accuracy', cv=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :param X: train samples\n",
    "    :param y: targets for train\n",
    "    :param k_list: list of values of neighbors amount, in ascending order\n",
    "    :param score: metric name( accuracy' must have)\n",
    "    :param cv: list of tuples, which contains indices of train and valid samples\n",
    "    :param kwargs: parameters for __init__ from KNNClassifier\n",
    "    :return: dict, where keys is neigbors amount from k_list, values - numpy array of size len(cv)\n",
    "    with accuracy on each fold\n",
    "    \"\"\"\n",
    "\n",
    "    if cv is None:\n",
    "        cv = kfold(X.shape[0])\n",
    "    knn = KNNClassifier(**kwargs)\n",
    "    knn.k = np.max(k_list)\n",
    "    knn.fit(X, y)\n",
    "    knn.find_kneighbors(X, return_distance=True)\n",
    "    accuracy_per_k = {k: np.empty(0) for k in k_list}\n",
    "    for k in k_list:\n",
    "        knn.k = k\n",
    "        for fold in cv:\n",
    "            y_valid = knn.predict(X[fold[1]])\n",
    "            accuracy_per_k[k] = np.append(accuracy_per_k[k],\n",
    "                                          accuracy(y_valid,\n",
    "                                                   y[fold[1]]))\n",
    "    return accuracy_per_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cross_val_score(train_data['data'][:1000],\n",
    "                    train_data['target'][:1000],\n",
    "                    k_list=[3, 4, 10, 50, 200],\n",
    "                    score='accuracy',\n",
    "                    cv=None,\n",
    "                    k=10,\n",
    "                    strategy='my_own',\n",
    "                    metric='euclidean',\n",
    "                    weights=False,\n",
    "                    test_block_size=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold(50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: array([94.5, 92.5, 92.5, 89.5, 93.5]),\n",
    "#  4: array([93.5, 91.5, 91. , 89.5, 93. ]),\n",
    "#  10: array([90.5, 88.5, 88.5, 84. , 90. ]),\n",
    "#  50: array([78. , 83. , 79. , 76. , 83.5]),\n",
    "#  200: array([60. , 68. , 54.5, 58.5, 57. ])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list1 = [1, 2, 3, 4, 5, 10]\n",
    "accuracy_per_k = {k: np.empty(0) for k in k_list1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_k[1] = np.append(accuracy_per_k[1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list1.index(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
